<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<head>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<meta content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=no" name="viewport"/>
<meta content="zh-cn" http-equiv="content-language"/>
<meta content="38 矩阵（下）：如何使用矩阵操作进行协同过滤推荐？" name="description"/>
<link href="/static/favicon.png" rel="icon"/>
<title>38 矩阵（下）：如何使用矩阵操作进行协同过滤推荐？ </title>
<link href="/static/index.css" rel="stylesheet"/>
<link href="/static/highlight.min.css" rel="stylesheet"/>
<script src="/static/highlight.min.js"></script>
<meta content="Hexo 4.2.0" name="generator"/>
<script data-website-id="83e5d5db-9d06-40e3-b780-cbae722fdf8c" defer="" src="https://umami.lianglianglee.com/script.js"></script>
</head>
<body>
<div class="book-container">
<div class="book-sidebar">
<div class="book-brand">
<a href="/">
<img src="/static/favicon.png"/>
<span>技术文章摘抄</span>
</a>
</div>
<div class="book-menu uncollapsible">
<ul class="uncollapsible">
<li><a class="current-tab" href="/">首页</a></li>
<li><a href="../">上一级</a></li>
</ul>
<ul class="uncollapsible">
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/01%20%e4%ba%8c%e8%bf%9b%e5%88%b6%ef%bc%9a%e4%b8%8d%e4%ba%86%e8%a7%a3%e8%ae%a1%e7%ae%97%e6%9c%ba%e7%9a%84%e6%ba%90%e5%a4%b4%ef%bc%8c%e4%bd%a0%e5%ad%a6%e4%bb%80%e4%b9%88%e7%bc%96%e7%a8%8b.md.html" id="01 二进制：不了解计算机的源头，你学什么编程.md.html">01 二进制：不了解计算机的源头，你学什么编程.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/02%20%e4%bd%99%e6%95%b0%ef%bc%9a%e5%8e%9f%e6%9d%a5%e5%8f%96%e4%bd%99%e6%93%8d%e4%bd%9c%e6%9c%ac%e8%ba%ab%e5%b0%b1%e6%98%af%e4%b8%aa%e5%93%88%e5%b8%8c%e5%87%bd%e6%95%b0.md.html" id="02 余数：原来取余操作本身就是个哈希函数.md.html">02 余数：原来取余操作本身就是个哈希函数.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/03%20%e8%bf%ad%e4%bb%a3%e6%b3%95%ef%bc%9a%e4%b8%8d%e7%94%a8%e7%bc%96%e7%a8%8b%e8%af%ad%e8%a8%80%e7%9a%84%e8%87%aa%e5%b8%a6%e5%87%bd%e6%95%b0%ef%bc%8c%e4%bd%a0%e4%bc%9a%e5%a6%82%e4%bd%95%e8%ae%a1%e7%ae%97%e5%b9%b3%e6%96%b9%e6%a0%b9%ef%bc%9f.md.html" id="03 迭代法：不用编程语言的自带函数，你会如何计算平方根？.md.html">03 迭代法：不用编程语言的自带函数，你会如何计算平方根？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/04%20%e6%95%b0%e5%ad%a6%e5%bd%92%e7%ba%b3%e6%b3%95%ef%bc%9a%e5%a6%82%e4%bd%95%e7%94%a8%e6%95%b0%e5%ad%a6%e5%bd%92%e7%ba%b3%e6%8f%90%e5%8d%87%e4%bb%a3%e7%a0%81%e7%9a%84%e8%bf%90%e8%a1%8c%e6%95%88%e7%8e%87%ef%bc%9f.md.html" id="04 数学归纳法：如何用数学归纳提升代码的运行效率？.md.html">04 数学归纳法：如何用数学归纳提升代码的运行效率？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/05%20%e9%80%92%e5%bd%92%ef%bc%88%e4%b8%8a%ef%bc%89%ef%bc%9a%e6%b3%9b%e5%8c%96%e6%95%b0%e5%ad%a6%e5%bd%92%e7%ba%b3%ef%bc%8c%e5%a6%82%e4%bd%95%e5%b0%86%e5%a4%8d%e6%9d%82%e9%97%ae%e9%a2%98%e7%ae%80%e5%8d%95%e5%8c%96%ef%bc%9f.md.html" id="05 递归（上）：泛化数学归纳，如何将复杂问题简单化？.md.html">05 递归（上）：泛化数学归纳，如何将复杂问题简单化？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/06%20%e9%80%92%e5%bd%92%ef%bc%88%e4%b8%8b%ef%bc%89%ef%bc%9a%e5%88%86%e8%80%8c%e6%b2%bb%e4%b9%8b%ef%bc%8c%e4%bb%8e%e5%bd%92%e5%b9%b6%e6%8e%92%e5%ba%8f%e5%88%b0MapReduce.md.html" id="06 递归（下）：分而治之，从归并排序到MapReduce.md.html">06 递归（下）：分而治之，从归并排序到MapReduce.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/07%20%e6%8e%92%e5%88%97%ef%bc%9a%e5%a6%82%e4%bd%95%e8%ae%a9%e8%ae%a1%e7%ae%97%e6%9c%ba%e5%ad%a6%e4%bc%9a%e2%80%9c%e7%94%b0%e5%bf%8c%e8%b5%9b%e9%a9%ac%e2%80%9d%ef%bc%9f.md.html" id="07 排列：如何让计算机学会“田忌赛马”？.md.html">07 排列：如何让计算机学会“田忌赛马”？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/08%20%e7%bb%84%e5%90%88%ef%bc%9a%e5%a6%82%e4%bd%95%e8%ae%a9%e8%ae%a1%e7%ae%97%e6%9c%ba%e5%ae%89%e6%8e%92%e4%b8%96%e7%95%8c%e6%9d%af%e7%9a%84%e8%b5%9b%e7%a8%8b%ef%bc%9f.md.html" id="08 组合：如何让计算机安排世界杯的赛程？.md.html">08 组合：如何让计算机安排世界杯的赛程？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/09%20%e5%8a%a8%e6%80%81%e8%a7%84%e5%88%92%ef%bc%88%e4%b8%8a%ef%bc%89%ef%bc%9a%e5%a6%82%e4%bd%95%e5%ae%9e%e7%8e%b0%e5%9f%ba%e4%ba%8e%e7%bc%96%e8%be%91%e8%b7%9d%e7%a6%bb%e7%9a%84%e6%9f%a5%e8%af%a2%e6%8e%a8%e8%8d%90%ef%bc%9f.md.html" id="09 动态规划（上）：如何实现基于编辑距离的查询推荐？.md.html">09 动态规划（上）：如何实现基于编辑距离的查询推荐？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/10%20%e5%8a%a8%e6%80%81%e8%a7%84%e5%88%92%ef%bc%88%e4%b8%8b%ef%bc%89%ef%bc%9a%e5%a6%82%e4%bd%95%e6%b1%82%e5%be%97%e7%8a%b6%e6%80%81%e8%bd%ac%e7%a7%bb%e6%96%b9%e7%a8%8b%e5%b9%b6%e8%bf%9b%e8%a1%8c%e7%bc%96%e7%a8%8b%e5%ae%9e%e7%8e%b0%ef%bc%9f.md.html" id="10 动态规划（下）：如何求得状态转移方程并进行编程实现？.md.html">10 动态规划（下）：如何求得状态转移方程并进行编程实现？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/11%20%e6%a0%91%e7%9a%84%e6%b7%b1%e5%ba%a6%e4%bc%98%e5%85%88%e6%90%9c%e7%b4%a2%ef%bc%88%e4%b8%8a%ef%bc%89%ef%bc%9a%e5%a6%82%e4%bd%95%e6%89%8d%e8%83%bd%e9%ab%98%e6%95%88%e7%8e%87%e5%9c%b0%e6%9f%a5%e5%ad%97%e5%85%b8%ef%bc%9f.md.html" id="11 树的深度优先搜索（上）：如何才能高效率地查字典？.md.html">11 树的深度优先搜索（上）：如何才能高效率地查字典？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/12%20%e6%a0%91%e7%9a%84%e6%b7%b1%e5%ba%a6%e4%bc%98%e5%85%88%e6%90%9c%e7%b4%a2%ef%bc%88%e4%b8%8b%ef%bc%89%ef%bc%9a%e5%a6%82%e4%bd%95%e6%89%8d%e8%83%bd%e9%ab%98%e6%95%88%e7%8e%87%e5%9c%b0%e6%9f%a5%e5%ad%97%e5%85%b8%ef%bc%9f.md.html" id="12 树的深度优先搜索（下）：如何才能高效率地查字典？.md.html">12 树的深度优先搜索（下）：如何才能高效率地查字典？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/13%20%e6%a0%91%e7%9a%84%e5%b9%bf%e5%ba%a6%e4%bc%98%e5%85%88%e6%90%9c%e7%b4%a2%ef%bc%88%e4%b8%8a%ef%bc%89%ef%bc%9a%e4%ba%ba%e9%99%85%e5%85%b3%e7%b3%bb%e7%9a%84%e5%85%ad%e5%ba%a6%e7%90%86%e8%ae%ba%e6%98%af%e7%9c%9f%e7%9a%84%e5%90%97%ef%bc%9f.md.html" id="13 树的广度优先搜索（上）：人际关系的六度理论是真的吗？.md.html">13 树的广度优先搜索（上）：人际关系的六度理论是真的吗？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/14%20%e6%a0%91%e7%9a%84%e5%b9%bf%e5%ba%a6%e4%bc%98%e5%85%88%e6%90%9c%e7%b4%a2%ef%bc%88%e4%b8%8b%ef%bc%89%ef%bc%9a%e4%b8%ba%e4%bb%80%e4%b9%88%e5%8f%8c%e5%90%91%e5%b9%bf%e5%ba%a6%e4%bc%98%e5%85%88%e6%90%9c%e7%b4%a2%e7%9a%84%e6%95%88%e7%8e%87%e6%9b%b4%e9%ab%98%ef%bc%9f.md.html" id="14 树的广度优先搜索（下）：为什么双向广度优先搜索的效率更高？.md.html">14 树的广度优先搜索（下）：为什么双向广度优先搜索的效率更高？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/15%20%e4%bb%8e%e6%a0%91%e5%88%b0%e5%9b%be%ef%bc%9a%e5%a6%82%e4%bd%95%e8%ae%a9%e8%ae%a1%e7%ae%97%e6%9c%ba%e5%ad%a6%e4%bc%9a%e7%9c%8b%e5%9c%b0%e5%9b%be%ef%bc%9f.md.html" id="15 从树到图：如何让计算机学会看地图？.md.html">15 从树到图：如何让计算机学会看地图？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/16%20%e6%97%b6%e9%97%b4%e5%92%8c%e7%a9%ba%e9%97%b4%e5%a4%8d%e6%9d%82%e5%ba%a6%ef%bc%88%e4%b8%8a%ef%bc%89%ef%bc%9a%e4%bc%98%e5%8c%96%e6%80%a7%e8%83%bd%e6%98%af%e5%90%a6%e5%8f%aa%e6%98%af%e2%80%9c%e7%ba%b8%e4%b8%8a%e8%b0%88%e5%85%b5%e2%80%9d%ef%bc%9f.md.html" id="16 时间和空间复杂度（上）：优化性能是否只是“纸上谈兵”？.md.html">16 时间和空间复杂度（上）：优化性能是否只是“纸上谈兵”？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/17%20%e6%97%b6%e9%97%b4%e5%92%8c%e7%a9%ba%e9%97%b4%e5%a4%8d%e6%9d%82%e5%ba%a6%ef%bc%88%e4%b8%8b%ef%bc%89%ef%bc%9a%e5%a6%82%e4%bd%95%e4%bd%bf%e7%94%a8%e5%85%ad%e4%b8%aa%e6%b3%95%e5%88%99%e8%bf%9b%e8%a1%8c%e5%a4%8d%e6%9d%82%e5%ba%a6%e5%88%86%e6%9e%90%ef%bc%9f.md.html" id="17 时间和空间复杂度（下）：如何使用六个法则进行复杂度分析？.md.html">17 时间和空间复杂度（下）：如何使用六个法则进行复杂度分析？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/18%20%e6%80%bb%e7%bb%93%e8%af%be%ef%bc%9a%e6%95%b0%e6%8d%ae%e7%bb%93%e6%9e%84%e3%80%81%e7%bc%96%e7%a8%8b%e8%af%ad%e5%8f%a5%e5%92%8c%e5%9f%ba%e7%a1%80%e7%ae%97%e6%b3%95%e4%bd%93%e7%8e%b0%e4%ba%86%e5%93%aa%e4%ba%9b%e6%95%b0%e5%ad%a6%e6%80%9d%e6%83%b3%ef%bc%9f.md.html" id="18 总结课：数据结构、编程语句和基础算法体现了哪些数学思想？.md.html">18 总结课：数据结构、编程语句和基础算法体现了哪些数学思想？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/19%20%e6%a6%82%e7%8e%87%e5%92%8c%e7%bb%9f%e8%ae%a1%ef%bc%9a%e7%bc%96%e7%a8%8b%e4%b8%ba%e4%bb%80%e4%b9%88%e9%9c%80%e8%a6%81%e6%a6%82%e7%8e%87%e5%92%8c%e7%bb%9f%e8%ae%a1%ef%bc%9f.md.html" id="19 概率和统计：编程为什么需要概率和统计？.md.html">19 概率和统计：编程为什么需要概率和统计？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/20%20%e6%a6%82%e7%8e%87%e5%9f%ba%e7%a1%80%ef%bc%88%e4%b8%8a%ef%bc%89%ef%bc%9a%e4%b8%80%e7%af%87%e6%96%87%e7%ab%a0%e5%b8%ae%e4%bd%a0%e7%90%86%e8%a7%a3%e9%9a%8f%e6%9c%ba%e5%8f%98%e9%87%8f%e3%80%81%e6%a6%82%e7%8e%87%e5%88%86%e5%b8%83%e5%92%8c%e6%9c%9f%e6%9c%9b%e5%80%bc.md.html" id="20 概率基础（上）：一篇文章帮你理解随机变量、概率分布和期望值.md.html">20 概率基础（上）：一篇文章帮你理解随机变量、概率分布和期望值.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/21%20%e6%a6%82%e7%8e%87%e5%9f%ba%e7%a1%80%ef%bc%88%e4%b8%8b%ef%bc%89%ef%bc%9a%e8%81%94%e5%90%88%e6%a6%82%e7%8e%87%e3%80%81%e6%9d%a1%e4%bb%b6%e6%a6%82%e7%8e%87%e5%92%8c%e8%b4%9d%e5%8f%b6%e6%96%af%e6%b3%95%e5%88%99%ef%bc%8c%e8%bf%99%e4%ba%9b%e6%a6%82%e7%8e%87%e5%85%ac%e5%bc%8f%e7%a9%b6%e7%ab%9f%e8%83%bd%e5%81%9a%e4%bb%80%e4%b9%88%ef%bc%9f.md.html" id="21 概率基础（下）：联合概率、条件概率和贝叶斯法则，这些概率公式究竟能做什么？.md.html">21 概率基础（下）：联合概率、条件概率和贝叶斯法则，这些概率公式究竟能做什么？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/22%20%e6%9c%b4%e7%b4%a0%e8%b4%9d%e5%8f%b6%e6%96%af%ef%bc%9a%e5%a6%82%e4%bd%95%e8%ae%a9%e8%ae%a1%e7%ae%97%e6%9c%ba%e5%ad%a6%e4%bc%9a%e8%87%aa%e5%8a%a8%e5%88%86%e7%b1%bb%ef%bc%9f.md.html" id="22 朴素贝叶斯：如何让计算机学会自动分类？.md.html">22 朴素贝叶斯：如何让计算机学会自动分类？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/23%20%e6%96%87%e6%9c%ac%e5%88%86%e7%b1%bb%ef%bc%9a%e5%a6%82%e4%bd%95%e5%8c%ba%e5%88%86%e7%89%b9%e5%ae%9a%e7%b1%bb%e5%9e%8b%e7%9a%84%e6%96%b0%e9%97%bb%ef%bc%9f.md.html" id="23 文本分类：如何区分特定类型的新闻？.md.html">23 文本分类：如何区分特定类型的新闻？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/24%20%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b%ef%bc%9a%e5%a6%82%e4%bd%95%e4%bd%bf%e7%94%a8%e9%93%be%e5%bc%8f%e6%b3%95%e5%88%99%e5%92%8c%e9%a9%ac%e5%b0%94%e7%a7%91%e5%a4%ab%e5%81%87%e8%ae%be%e7%ae%80%e5%8c%96%e6%a6%82%e7%8e%87%e6%a8%a1%e5%9e%8b%ef%bc%9f.md.html" id="24 语言模型：如何使用链式法则和马尔科夫假设简化概率模型？.md.html">24 语言模型：如何使用链式法则和马尔科夫假设简化概率模型？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/25%20%e9%a9%ac%e5%b0%94%e7%a7%91%e5%a4%ab%e6%a8%a1%e5%9e%8b%ef%bc%9a%e4%bb%8ePageRank%e5%88%b0%e8%af%ad%e9%9f%b3%e8%af%86%e5%88%ab%ef%bc%8c%e8%83%8c%e5%90%8e%e6%98%af%e4%bb%80%e4%b9%88%e6%a8%a1%e5%9e%8b%e5%9c%a8%e6%94%af%e6%92%91%ef%bc%9f.md.html" id="25 马尔科夫模型：从PageRank到语音识别，背后是什么模型在支撑？.md.html">25 马尔科夫模型：从PageRank到语音识别，背后是什么模型在支撑？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/26%20%e4%bf%a1%e6%81%af%e7%86%b5%ef%bc%9a%e5%a6%82%e4%bd%95%e9%80%9a%e8%bf%87%e5%87%a0%e4%b8%aa%e9%97%ae%e9%a2%98%ef%bc%8c%e6%b5%8b%e5%87%ba%e4%bd%a0%e5%af%b9%e5%ba%94%e7%9a%84%e6%ad%a6%e4%be%a0%e4%ba%ba%e7%89%a9%ef%bc%9f.md.html" id="26 信息熵：如何通过几个问题，测出你对应的武侠人物？.md.html">26 信息熵：如何通过几个问题，测出你对应的武侠人物？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/27%20%e5%86%b3%e7%ad%96%e6%a0%91%ef%bc%9a%e4%bf%a1%e6%81%af%e5%a2%9e%e7%9b%8a%e3%80%81%e5%a2%9e%e7%9b%8a%e6%af%94%e7%8e%87%e5%92%8c%e5%9f%ba%e5%b0%bc%e6%8c%87%e6%95%b0%e7%9a%84%e8%bf%90%e7%94%a8.md.html" id="27 决策树：信息增益、增益比率和基尼指数的运用.md.html">27 决策树：信息增益、增益比率和基尼指数的运用.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/28%20%e7%86%b5%e3%80%81%e4%bf%a1%e6%81%af%e5%a2%9e%e7%9b%8a%e5%92%8c%e5%8d%a1%e6%96%b9%ef%bc%9a%e5%a6%82%e4%bd%95%e5%af%bb%e6%89%be%e5%85%b3%e9%94%ae%e7%89%b9%e5%be%81%ef%bc%9f.md.html" id="28 熵、信息增益和卡方：如何寻找关键特征？.md.html">28 熵、信息增益和卡方：如何寻找关键特征？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/29%20%e5%bd%92%e4%b8%80%e5%8c%96%e5%92%8c%e6%a0%87%e5%87%86%e5%8c%96%ef%bc%9a%e5%90%84%e7%a7%8d%e7%89%b9%e5%be%81%e5%a6%82%e4%bd%95%e7%bb%bc%e5%90%88%e6%89%8d%e6%98%af%e6%9c%80%e5%90%88%e7%90%86%e7%9a%84%ef%bc%9f.md.html" id="29 归一化和标准化：各种特征如何综合才是最合理的？.md.html">29 归一化和标准化：各种特征如何综合才是最合理的？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/30%20%e7%bb%9f%e8%ae%a1%e6%84%8f%e4%b9%89%ef%bc%88%e4%b8%8a%ef%bc%89%ef%bc%9a%e5%a6%82%e4%bd%95%e9%80%9a%e8%bf%87%e6%98%be%e8%91%97%e6%80%a7%e6%a3%80%e9%aa%8c%ef%bc%8c%e5%88%a4%e6%96%ad%e4%bd%a0%e7%9a%84A_B%e6%b5%8b%e8%af%95%e7%bb%93%e6%9e%9c%e6%98%af%e4%b8%8d%e6%98%af%e5%b7%a7%e5%90%88%ef%bc%9f.md.html" id="30 统计意义（上）：如何通过显著性检验，判断你的A_B测试结果是不是巧合？.md.html">30 统计意义（上）：如何通过显著性检验，判断你的A_B测试结果是不是巧合？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/31%20%e7%bb%9f%e8%ae%a1%e6%84%8f%e4%b9%89%ef%bc%88%e4%b8%8b%ef%bc%89%ef%bc%9a%e5%a6%82%e4%bd%95%e9%80%9a%e8%bf%87%e6%98%be%e8%91%97%e6%80%a7%e6%a3%80%e9%aa%8c%ef%bc%8c%e5%88%a4%e6%96%ad%e4%bd%a0%e7%9a%84A_B%e6%b5%8b%e8%af%95%e7%bb%93%e6%9e%9c%e6%98%af%e4%b8%8d%e6%98%af%e5%b7%a7%e5%90%88%ef%bc%9f.md.html" id="31 统计意义（下）：如何通过显著性检验，判断你的A_B测试结果是不是巧合？.md.html">31 统计意义（下）：如何通过显著性检验，判断你的A_B测试结果是不是巧合？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/32%20%e6%a6%82%e7%8e%87%e7%bb%9f%e8%ae%a1%e7%af%87%e7%ad%94%e7%96%91%e5%92%8c%e6%80%bb%e7%bb%93%ef%bc%9a%e4%b8%ba%e4%bb%80%e4%b9%88%e4%bc%9a%e6%9c%89%e6%ac%a0%e6%8b%9f%e5%90%88%e5%92%8c%e8%bf%87%e6%8b%9f%e5%90%88%ef%bc%9f.md.html" id="32 概率统计篇答疑和总结：为什么会有欠拟合和过拟合？.md.html">32 概率统计篇答疑和总结：为什么会有欠拟合和过拟合？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/33%20%e7%ba%bf%e6%80%a7%e4%bb%a3%e6%95%b0%ef%bc%9a%e7%ba%bf%e6%80%a7%e4%bb%a3%e6%95%b0%e5%88%b0%e5%ba%95%e9%83%bd%e8%ae%b2%e4%ba%86%e4%ba%9b%e4%bb%80%e4%b9%88%ef%bc%9f.md.html" id="33 线性代数：线性代数到底都讲了些什么？.md.html">33 线性代数：线性代数到底都讲了些什么？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/34%20%e5%90%91%e9%87%8f%e7%a9%ba%e9%97%b4%e6%a8%a1%e5%9e%8b%ef%bc%9a%e5%a6%82%e4%bd%95%e8%ae%a9%e8%ae%a1%e7%ae%97%e6%9c%ba%e7%90%86%e8%a7%a3%e7%8e%b0%e5%ae%9e%e4%ba%8b%e7%89%a9%e4%b9%8b%e9%97%b4%e7%9a%84%e5%85%b3%e7%b3%bb%ef%bc%9f.md.html" id="34 向量空间模型：如何让计算机理解现实事物之间的关系？.md.html">34 向量空间模型：如何让计算机理解现实事物之间的关系？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/35%20%e6%96%87%e6%9c%ac%e6%a3%80%e7%b4%a2%ef%bc%9a%e5%a6%82%e4%bd%95%e8%ae%a9%e8%ae%a1%e7%ae%97%e6%9c%ba%e5%a4%84%e7%90%86%e8%87%aa%e7%84%b6%e8%af%ad%e8%a8%80%ef%bc%9f.md.html" id="35 文本检索：如何让计算机处理自然语言？.md.html">35 文本检索：如何让计算机处理自然语言？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/36%20%e6%96%87%e6%9c%ac%e8%81%9a%e7%b1%bb%ef%bc%9a%e5%a6%82%e4%bd%95%e8%bf%87%e6%bb%a4%e5%86%97%e4%bd%99%e7%9a%84%e6%96%b0%e9%97%bb%ef%bc%9f.md.html" id="36 文本聚类：如何过滤冗余的新闻？.md.html">36 文本聚类：如何过滤冗余的新闻？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/37%20%e7%9f%a9%e9%98%b5%ef%bc%88%e4%b8%8a%ef%bc%89%ef%bc%9a%e5%a6%82%e4%bd%95%e4%bd%bf%e7%94%a8%e7%9f%a9%e9%98%b5%e6%93%8d%e4%bd%9c%e8%bf%9b%e8%a1%8cPageRank%e8%ae%a1%e7%ae%97%ef%bc%9f.md.html" id="37 矩阵（上）：如何使用矩阵操作进行PageRank计算？.md.html">37 矩阵（上）：如何使用矩阵操作进行PageRank计算？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/38%20%e7%9f%a9%e9%98%b5%ef%bc%88%e4%b8%8b%ef%bc%89%ef%bc%9a%e5%a6%82%e4%bd%95%e4%bd%bf%e7%94%a8%e7%9f%a9%e9%98%b5%e6%93%8d%e4%bd%9c%e8%bf%9b%e8%a1%8c%e5%8d%8f%e5%90%8c%e8%bf%87%e6%bb%a4%e6%8e%a8%e8%8d%90%ef%bc%9f.md.html" id="38 矩阵（下）：如何使用矩阵操作进行协同过滤推荐？.md.html">38 矩阵（下）：如何使用矩阵操作进行协同过滤推荐？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/39%20%e7%ba%bf%e6%80%a7%e5%9b%9e%e5%bd%92%ef%bc%88%e4%b8%8a%ef%bc%89%ef%bc%9a%e5%a6%82%e4%bd%95%e4%bd%bf%e7%94%a8%e9%ab%98%e6%96%af%e6%b6%88%e5%85%83%e6%b1%82%e8%a7%a3%e7%ba%bf%e6%80%a7%e6%96%b9%e7%a8%8b%e7%bb%84%ef%bc%9f.md.html" id="39 线性回归（上）：如何使用高斯消元求解线性方程组？.md.html">39 线性回归（上）：如何使用高斯消元求解线性方程组？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/40%20%e7%ba%bf%e6%80%a7%e5%9b%9e%e5%bd%92%ef%bc%88%e4%b8%ad%ef%bc%89%ef%bc%9a%e5%a6%82%e4%bd%95%e4%bd%bf%e7%94%a8%e6%9c%80%e5%b0%8f%e4%ba%8c%e4%b9%98%e6%b3%95%e8%bf%9b%e8%a1%8c%e7%9b%b4%e7%ba%bf%e6%8b%9f%e5%90%88%ef%bc%9f.md.html" id="40 线性回归（中）：如何使用最小二乘法进行直线拟合？.md.html">40 线性回归（中）：如何使用最小二乘法进行直线拟合？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/41%20%e7%ba%bf%e6%80%a7%e5%9b%9e%e5%bd%92%ef%bc%88%e4%b8%8b%ef%bc%89%ef%bc%9a%e5%a6%82%e4%bd%95%e4%bd%bf%e7%94%a8%e6%9c%80%e5%b0%8f%e4%ba%8c%e4%b9%98%e6%b3%95%e8%bf%9b%e8%a1%8c%e6%95%88%e6%9e%9c%e9%aa%8c%e8%af%81%ef%bc%9f.md.html" id="41 线性回归（下）：如何使用最小二乘法进行效果验证？.md.html">41 线性回归（下）：如何使用最小二乘法进行效果验证？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/42%20PCA%e4%b8%bb%e6%88%90%e5%88%86%e5%88%86%e6%9e%90%ef%bc%88%e4%b8%8a%ef%bc%89%ef%bc%9a%e5%a6%82%e4%bd%95%e5%88%a9%e7%94%a8%e5%8d%8f%e6%96%b9%e5%b7%ae%e7%9f%a9%e9%98%b5%e6%9d%a5%e9%99%8d%e7%bb%b4%ef%bc%9f.md.html" id="42 PCA主成分分析（上）：如何利用协方差矩阵来降维？.md.html">42 PCA主成分分析（上）：如何利用协方差矩阵来降维？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/43%20PCA%e4%b8%bb%e6%88%90%e5%88%86%e5%88%86%e6%9e%90%ef%bc%88%e4%b8%8b%ef%bc%89%ef%bc%9a%e4%b8%ba%e4%bb%80%e4%b9%88%e8%a6%81%e8%ae%a1%e7%ae%97%e5%8d%8f%e6%96%b9%e5%b7%ae%e7%9f%a9%e9%98%b5%e7%9a%84%e7%89%b9%e5%be%81%e5%80%bc%e5%92%8c%e7%89%b9%e5%be%81%e5%90%91%e9%87%8f%ef%bc%9f.md.html" id="43 PCA主成分分析（下）：为什么要计算协方差矩阵的特征值和特征向量？.md.html">43 PCA主成分分析（下）：为什么要计算协方差矩阵的特征值和特征向量？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/44%20%e5%a5%87%e5%bc%82%e5%80%bc%e5%88%86%e8%a7%a3%ef%bc%9a%e5%a6%82%e4%bd%95%e6%8c%96%e6%8e%98%e6%bd%9c%e5%9c%a8%e7%9a%84%e8%af%ad%e4%b9%89%e5%85%b3%e7%b3%bb%ef%bc%9f.md.html" id="44 奇异值分解：如何挖掘潜在的语义关系？.md.html">44 奇异值分解：如何挖掘潜在的语义关系？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/45%20%e7%ba%bf%e6%80%a7%e4%bb%a3%e6%95%b0%e7%af%87%e7%ad%94%e7%96%91%e5%92%8c%e6%80%bb%e7%bb%93%ef%bc%9a%e7%9f%a9%e9%98%b5%e4%b9%98%e6%b3%95%e7%9a%84%e5%87%a0%e4%bd%95%e6%84%8f%e4%b9%89%e6%98%af%e4%bb%80%e4%b9%88%ef%bc%9f.md.html" id="45 线性代数篇答疑和总结：矩阵乘法的几何意义是什么？.md.html">45 线性代数篇答疑和总结：矩阵乘法的几何意义是什么？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/46%20%e7%bc%93%e5%ad%98%e7%b3%bb%e7%bb%9f%ef%bc%9a%e5%a6%82%e4%bd%95%e9%80%9a%e8%bf%87%e5%93%88%e5%b8%8c%e8%a1%a8%e5%92%8c%e9%98%9f%e5%88%97%e5%ae%9e%e7%8e%b0%e9%ab%98%e6%95%88%e8%ae%bf%e9%97%ae%ef%bc%9f.md.html" id="46 缓存系统：如何通过哈希表和队列实现高效访问？.md.html">46 缓存系统：如何通过哈希表和队列实现高效访问？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/47%20%e6%90%9c%e7%b4%a2%e5%bc%95%e6%93%8e%ef%bc%88%e4%b8%8a%ef%bc%89%ef%bc%9a%e5%a6%82%e4%bd%95%e9%80%9a%e8%bf%87%e5%80%92%e6%8e%92%e7%b4%a2%e5%bc%95%e5%92%8c%e5%90%91%e9%87%8f%e7%a9%ba%e9%97%b4%e6%a8%a1%e5%9e%8b%ef%bc%8c%e6%89%93%e9%80%a0%e4%b8%80%e4%b8%aa%e7%ae%80%e5%8d%95%e7%9a%84%e6%90%9c%e7%b4%a2%e5%bc%95%e6%93%8e%ef%bc%9f.md.html" id="47 搜索引擎（上）：如何通过倒排索引和向量空间模型，打造一个简单的搜索引擎？.md.html">47 搜索引擎（上）：如何通过倒排索引和向量空间模型，打造一个简单的搜索引擎？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/48%20%e6%90%9c%e7%b4%a2%e5%bc%95%e6%93%8e%ef%bc%88%e4%b8%8b%ef%bc%89%ef%bc%9a%e5%a6%82%e4%bd%95%e9%80%9a%e8%bf%87%e6%9f%a5%e8%af%a2%e7%9a%84%e5%88%86%e7%b1%bb%ef%bc%8c%e8%ae%a9%e7%94%b5%e5%95%86%e5%b9%b3%e5%8f%b0%e7%9a%84%e6%90%9c%e7%b4%a2%e7%bb%93%e6%9e%9c%e6%9b%b4%e7%9b%b8%e5%85%b3%ef%bc%9f.md.html" id="48 搜索引擎（下）：如何通过查询的分类，让电商平台的搜索结果更相关？.md.html">48 搜索引擎（下）：如何通过查询的分类，让电商平台的搜索结果更相关？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/49%20%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%ef%bc%88%e4%b8%8a%ef%bc%89%ef%bc%9a%e5%a6%82%e4%bd%95%e5%ae%9e%e7%8e%b0%e5%9f%ba%e4%ba%8e%e7%9b%b8%e4%bc%bc%e5%ba%a6%e7%9a%84%e5%8d%8f%e5%90%8c%e8%bf%87%e6%bb%a4%ef%bc%9f.md.html" id="49 推荐系统（上）：如何实现基于相似度的协同过滤？.md.html">49 推荐系统（上）：如何实现基于相似度的协同过滤？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/50%20%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%ef%bc%88%e4%b8%8b%ef%bc%89%ef%bc%9a%e5%a6%82%e4%bd%95%e9%80%9a%e8%bf%87SVD%e5%88%86%e6%9e%90%e7%94%a8%e6%88%b7%e5%92%8c%e7%89%a9%e5%93%81%e7%9a%84%e7%9f%a9%e9%98%b5%ef%bc%9f.md.html" id="50 推荐系统（下）：如何通过SVD分析用户和物品的矩阵？.md.html">50 推荐系统（下）：如何通过SVD分析用户和物品的矩阵？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/51%20%e7%bb%bc%e5%90%88%e5%ba%94%e7%94%a8%e7%af%87%e7%ad%94%e7%96%91%e5%92%8c%e6%80%bb%e7%bb%93%ef%bc%9a%e5%a6%82%e4%bd%95%e8%bf%9b%e8%a1%8c%e4%b8%aa%e6%80%a7%e5%8c%96%e7%94%a8%e6%88%b7%e7%94%bb%e5%83%8f%e7%9a%84%e8%ae%be%e8%ae%a1%ef%bc%9f.md.html" id="51 综合应用篇答疑和总结：如何进行个性化用户画像的设计？.md.html">51 综合应用篇答疑和总结：如何进行个性化用户画像的设计？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/%e5%af%bc%e8%af%bb%ef%bc%9a%e7%a8%8b%e5%ba%8f%e5%91%98%e5%ba%94%e8%af%a5%e6%80%8e%e4%b9%88%e5%ad%a6%e6%95%b0%e5%ad%a6%ef%bc%9f.md.html" id="导读：程序员应该怎么学数学？.md.html">导读：程序员应该怎么学数学？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/%e5%bc%80%e7%af%87%e8%af%8d%20%e4%bd%9c%e4%b8%ba%e7%a8%8b%e5%ba%8f%e5%91%98%ef%bc%8c%e4%b8%ba%e4%bb%80%e4%b9%88%e4%bd%a0%e5%ba%94%e8%af%a5%e5%ad%a6%e5%a5%bd%e6%95%b0%e5%ad%a6%ef%bc%9f.md.html" id="开篇词 作为程序员，为什么你应该学好数学？.md.html">开篇词 作为程序员，为什么你应该学好数学？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/%e6%95%b0%e5%ad%a6%e4%b8%93%e6%a0%8f%e8%af%be%e5%a4%96%e5%8a%a0%e9%a4%90%ef%bc%88%e4%b8%80%ef%bc%89%20%e6%88%91%e4%bb%ac%e4%b8%ba%e4%bb%80%e4%b9%88%e9%9c%80%e8%a6%81%e5%8f%8d%e7%a0%81%e5%92%8c%e8%a1%a5%e7%a0%81%ef%bc%9f.md.html" id="数学专栏课外加餐（一） 我们为什么需要反码和补码？.md.html">数学专栏课外加餐（一） 我们为什么需要反码和补码？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/%e6%95%b0%e5%ad%a6%e4%b8%93%e6%a0%8f%e8%af%be%e5%a4%96%e5%8a%a0%e9%a4%90%ef%bc%88%e4%b8%89%ef%bc%89%ef%bc%9a%e7%a8%8b%e5%ba%8f%e5%91%98%e9%9c%80%e8%a6%81%e8%af%bb%e5%93%aa%e4%ba%9b%e6%95%b0%e5%ad%a6%e4%b9%a6%ef%bc%9f.md.html" id="数学专栏课外加餐（三）：程序员需要读哪些数学书？.md.html">数学专栏课外加餐（三）：程序员需要读哪些数学书？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/%e6%95%b0%e5%ad%a6%e4%b8%93%e6%a0%8f%e8%af%be%e5%a4%96%e5%8a%a0%e9%a4%90%ef%bc%88%e4%ba%8c%ef%bc%89%20%e4%bd%8d%e6%93%8d%e4%bd%9c%e7%9a%84%e4%b8%89%e4%b8%aa%e5%ba%94%e7%94%a8%e5%ae%9e%e4%be%8b.md.html" id="数学专栏课外加餐（二） 位操作的三个应用实例.md.html">数学专栏课外加餐（二） 位操作的三个应用实例.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e8%af%be/%e7%bb%93%e6%9d%9f%e8%af%ad%20%e4%bb%8e%e6%95%b0%e5%ad%a6%e5%88%b0%e7%bc%96%e7%a8%8b%ef%bc%8c%e6%9c%ac%e8%ba%ab%e5%b0%b1%e6%98%af%e4%b8%80%e4%b8%aa%e5%be%88%e9%95%bf%e7%9a%84%e9%93%be%e6%9d%a1.md.html" id="结束语 从数学到编程，本身就是一个很长的链条.md.html">结束语 从数学到编程，本身就是一个很长的链条.md.html</a>
</li>
<li><a href="/assets/捐赠.md.html">捐赠</a></li>
</ul>
</div>
</div>
<div class="sidebar-toggle" onclick="sidebar_toggle()" onmouseleave="remove_inner()" onmouseover="add_inner()">
<div class="sidebar-toggle-inner"></div>
</div>
<div class="off-canvas-content">
<div class="columns">
<div class="column col-12 col-lg-12">
<div class="book-navbar">
<header class="navbar">
<section class="navbar-section">
<a onclick="open_sidebar()">
<i class="icon icon-menu"></i>
</a>
</section>
</header>
</div>
<div class="book-content" style="max-width: 960px; margin: 0 auto;
    overflow-x: auto;
    overflow-y: hidden;">
<div class="book-post">
<div align="center">因收到Google相关通知，网站将会择期关闭。<a href="https://lumendatabase.org/notices/44265620" target="_blank">相关通知内容</a><hr/></div>
<p align="center" id="tip"></p>
<h1 class="title" data-id="38 矩阵（下）：如何使用矩阵操作进行协同过滤推荐？" id="title">38 矩阵（下）：如何使用矩阵操作进行协同过滤推荐？</h1>
<div><p>你好，我是黄申。今天我们来聊聊矩阵操作和推荐算法的关系。</p>
<p>我这里说的推荐，是指为用户提供可靠的建议、并协助用户挑选物品的一种技术。一个好的推荐系统需要建立在海量数据挖掘基础之上，并根据用户所处的情景和兴趣特点，向用户推荐可能感兴趣的信息和商品。</p>
<p>协同过滤（Collaborative Filtering）是经典的推荐算法之一，它充分利用了用户和物品之间已知的关系，为用户提供新的推荐内容。我会从这种二元关系出发，给你讲讲如何使用矩阵计算，来实现协同过滤推荐算法。</p>
<h2 id="用矩阵实现推荐系统的核心思想">用矩阵实现推荐系统的核心思想</h2>
<p>矩阵中的二维关系，除了可以表达图的邻接关系，还可以表达推荐系统中用户和物品的关系。如果你不懂推荐系统，不用急，我这里先给你简单讲讲它的核心思想。</p>
<p>简单地理解就是，推荐系统会根据用户所处的场景和个人喜好，推荐他们可能感兴趣的信息和商品。比如，你在阅读一部电影的影评时，系统给你推荐了其他“你可能也感兴趣的电影”。可以看出来，推荐系统中至少有2个重要的角色：用户和物品。用户是系统的使用者，物品就是将要被推荐的候选对象。</p>
<p>例如，亚马逊网站的顾客就是用户，网站所销售的商品就是物品。需要注意的是，除了用户角色都是现实中的自然人，某些场景下被推荐的物品可能也是现实中的自然人。例如，一个招聘网站会给企业雇主推荐合适的人才，这时候应聘者承担的是物品角色。</p>
<p>而一个好的推荐算法，需要充分挖掘用户和物品之间的关系。我们可以通过矩阵来表示这种二元关系。我这里有一个例子，我们用矩阵<span class="math inline">\(X\)</span>来表示用户对物品喜好程度。</p>
<p><img alt="" src="assets/60799b9b594a4fc2b55354d8d99583d1.jpg"/></p>
<p>其中第<span class="math inline">\(i\)</span>行是第<span class="math inline">\(i\)</span>个用户的数据，而第j列是用户对第j个物品的喜好程度。我们用<span class="math inline">\(x\_{i,j}\)</span>表示这个数值。这里的喜好程度可以是用户购买商品的次数、对书籍的评分等等。</p>
<p>假设我们用一个0到1之间的小数表示。有了这种矩阵，我们就可以通过矩阵的操作，充分挖掘用户和物品之间的关系。下面，我会使用经典的协同过滤算法，来讲解矩阵在其中的运用。</p>
<p>在此之前，我们先来看什么是协同过滤。你可以把它理解为最直观的“口口相传”。假设我们愿意接受他人的建议，尤其是很多人都向你建议的时候。其主要思路就是利用已有用户群过去的行为或意见，预测当前用户最可能喜欢哪些东西。根据推荐依据和传播的路径，又可以进一步细分为基于用户的过滤和基于物品的过滤。</p>
<h2 id="基于用户的过滤">基于用户的过滤</h2>
<p>首先，我们来看基于用户的协同过滤。它是指给定一个用户访问（我们假设有访问就表示有兴趣）物品的数据集合，找出和当前用户历史行为有相似偏好的其他用户，将这些用户组成“近邻”，对于当前用户没有访问过的物品，利用其近邻的访问记录来预测。我画了一张图方便你理解。</p>
<p><img alt="" src="assets/5d51a887663942a9b7911434ce49d179.jpg"/></p>
<p>根据这张图的访问关系来看，用户A访问了物品A和C，用户B访问了物品B，用户C访问了物品A，C和D。我们计算出来，用户C是A的近邻，而B不是。因此系统会更多地向用户A推荐用户C访问的物品D。</p>
<p>理解了这个算法的基本概念，我们来看看如何使用公式来表述它。假设有m个用户，n个物品，那么我们就能使用一个m×n维的矩阵<span class="math inline">\(X\)</span>来表示用户对物品喜好的二元关系。基于这个二元关系，我们可以列出下面这两个公式：</p>
<p><img alt="" src="assets/4dfc77352fc94d278b0f5be28c0a60ed.jpg"/></p>
<p>其中，第一个公式比较容易理解，它的核心思想是计算用户和用户之间的相似度。完成了这一步我们就能找到给定用户的“近邻”。</p>
<p>我们可以使用向量空间模型中的距离或者是夹角余弦来处理，在这里我使用了夹角余弦，其中<span class="math inline">\(us\_{i1}\)</span>,<span class="math inline">\(i2\)</span>表示用户<span class="math inline">\(i1\)</span>和<span class="math inline">\(i2\)</span>的相似度，而<span class="math inline">\(X\_{i1}\)</span>,表示矩阵中第<span class="math inline">\(i1\)</span>行的行向量，<span class="math inline">\(X\_{i2}\)</span>,表示矩阵中第<span class="math inline">\(i2\)</span>行的行向量。分子是两个表示用户的行向量之点乘，而分母是这两个行向量<span class="math inline">\(L2\)</span>范数的乘积。</p>
<p>第二个公式利用第一个公式所计算的用户间相似度，以及用户对物品的喜好度，预测任一个用户对任一个物品的喜好度。其中<span class="math inline">\(p\_{i,j}\)</span>表示第<span class="math inline">\(i\)</span>用户对第<span class="math inline">\(j\)</span>个物品的喜好度，<span class="math inline">\(us\_{i,k}\)</span>表示用户<span class="math inline">\(i\)</span>和<span class="math inline">\(k\)</span>之间的相似度，<span class="math inline">\(x\_{k,j}\)</span>表示用户<span class="math inline">\(k\)</span>对物品<span class="math inline">\(j\)</span>的喜好度。注意这里最终需要除以<span class="math inline">\(Σus\_{i,k}\)</span>，是为了进行归一化。</p>
<p>从这个公式可以看出，如果<span class="math inline">\(us\_{i,k}\)</span>越大，<span class="math inline">\(x\_{k,j}\)</span>对最终<span class="math inline">\(p\_{i,j}\)</span>的影响越大，反之如果<span class="math inline">\(us\_{i,k}\)</span>越小，<span class="math inline">\(x\_{k,j}\)</span>对最终<span class="math inline">\(p\_{i,j}\)</span>的影响越小，充分体现了“基于相似用户”的推荐。</p>
<p>如果你无法理解如何把这两个公式对应为矩阵操作，没关系，我下面会通过之前介绍的喜好度矩阵<span class="math inline">\(X\)</span>的示例，把这两个公式逐步拆解，并对应到矩阵上的操作，你一看就能明白了。</p>
<p>首先，我们来看第一个关于夹角余弦的公式。</p>
<p><img alt="" src="assets/d115641e8e3947c2a1f0ce549c84cd36.jpg"/></p>
<p>在介绍向量空间模型的时候，我提到夹角余弦可以通过向量的点乘来实现。这对矩阵同样适用，我们可以采用矩阵点乘自身的转置来实现，也就是<span class="math inline">\(XX’\)</span>。矩阵<span class="math inline">\(X\)</span>的每一行是某个用户的行向量，每个分量表示用户对某个物品的喜好程度。而矩阵<span class="math inline">\(X’\)</span>的每一列是某个用户的列向量，每个分量表示用户对某个物品的喜好程度。</p>
<p>我们假设<span class="math inline">\(XX’\)</span>的结果为矩阵<span class="math inline">\(Y\)</span>，那么<span class="math inline">\(y\_{i,j}\)</span>就表示用户<span class="math inline">\(i\)</span>和用户<span class="math inline">\(j\)</span>这两者喜好度向量的点乘结果，它就是夹角余弦公式中的分子。如果<span class="math inline">\(i\)</span>等于<span class="math inline">\(j\)</span>，那么这个计算值也是夹角余弦公式分母的一部分。从矩阵的角度来看，<span class="math inline">\(Y\)</span>中任何一个元素都可能用于夹角余弦公式的分子，而对角线上的值会用于夹角余弦公式的分母。这里我们仍然使用之前的喜好度矩阵示例，来计算矩阵<span class="math inline">\(Y\)</span>和矩阵<span class="math inline">\(US\)</span>。</p>
<p>首先我们来看<span class="math inline">\(Y\)</span>的计算。</p>
<p><img alt="" src="assets/f2ab87d809e646d781cf3f024fc973e3.jpg"/></p>
<p>然后我们使用<span class="math inline">\(Y\)</span>来计算<span class="math inline">\(US\)</span>。我用下面这张图表示矩阵中的元素和夹角余弦计算的对应关系。</p>
<p><img alt="" src="assets/89fca91e9218447f974ebab7dfe4d91b.jpg"/></p>
<p>明白了上面这个对应关系，我们就可以利用矩阵<span class="math inline">\(Y\)</span>，获得任意两个用户之间的相似度，并得到一个m×m维的相似度矩阵<span class="math inline">\(US\)</span>。矩阵<span class="math inline">\(US\)</span>中<span class="math inline">\(us\_{i,j}\)</span>的取值为第<span class="math inline">\(i\)</span>个用户与第<span class="math inline">\(j\)</span>个用户的相似度。这个矩阵是一个沿对角线对称的矩阵。根据夹角余弦的定义，<span class="math inline">\(us\_{i,j}\)</span>和<span class="math inline">\(us\_{j,i}\)</span>是相等的。通过示例的矩阵<span class="math inline">\(Y\)</span>，我们可以计算矩阵<span class="math inline">\(US\)</span>。我把相应的结果列在了下方。</p>
<p><img alt="" src="assets/bd4630bba3384c0c9b5c36ccb8f99f16.jpg"/></p>
<p>接下来，我们再来看第二个公式。</p>
<p><img alt="" src="assets/e7c49770f51746029beb0bfd9d9ce8cd.jpg"/></p>
<p>从矩阵的角度来看，现在我们已经得到用户相似度矩阵<span class="math inline">\(US\)</span>，再加上用户对物品的喜好度矩阵<span class="math inline">\(X\)</span>，现在需要计算任意用户对任意物品的喜好度推荐矩阵<span class="math inline">\(P\)</span>。</p>
<p>为了实现上面这个公式的分子部分，我们可以使用<span class="math inline">\(US\)</span>和<span class="math inline">\(X\)</span>的点乘。我们假设点乘后的结果矩阵为<span class="math inline">\(USP\)</span>。这里我列出了根据示例计算得到的矩阵<span class="math inline">\(USP\)</span>。</p>
<p><img alt="" src="assets/aa16501e19394210ae7112da26734de9.jpg"/></p>
<p>分母部分可以使用<span class="math inline">\(US\)</span>矩阵的按行求和来实现。我们假设按行求和的矩阵为<span class="math inline">\(USR\)</span>。根据示例计算就可以得到<span class="math inline">\(USR\)</span>。</p>
<p><img alt="" src="assets/7b0bb8eee4f74efa9e2cc3a3cd77fdbe.jpg"/></p>
<p>最终，我们使用<span class="math inline">\(USP\)</span>和*<span class="math inline">\(USR\)</span>的元素对应除法，就可以求得矩阵<span class="math inline">\(P\)</span>。</p>
<p><img alt="" src="assets/ff3a2187857946668fc052478149c051.jpg"/></p>
<p>既然已经有<span class="math inline">\(X\)</span>这个喜好度矩阵了，为什么还要计算<span class="math inline">\(P\)</span>这个喜好度矩阵呢？实际上，<span class="math inline">\(X\)</span>是已知的、有限的喜好度。例如用户已经看过的、购买过的、或评过分的物品。而<span class="math inline">\(P\)</span>是我们使用推荐算法预测出来的喜好度。</p>
<p>即使一个用户对某个物品从未看过、买过、或评过分，我们依然可以通过矩阵<span class="math inline">\(P\)</span>，知道这位用户对这个物品大致的喜好程度，从而根据这个预估的分数进行物品的推荐，这也是协同过滤的基本思想。从根据示例计算的结果也可以看出这点，在原始矩阵<span class="math inline">\(X\)</span>中第1个用户对第3个物品的喜好度为0。可是在最终的喜好度推荐矩阵P中，第1个用户对第3个物品的喜好度为0.278，已经明显大于0了，因此我们就可以把物品3推荐给用户1。</p>
<p>上面这种基于用户的协同过滤有个问题，那就是没有考虑到用户的喜好程度是不是具有可比性。假设用户的喜好是根据对商品的评分来决定的，有些用户比较宽容，给所有的商品都打了很高的分，而有些用户比较严苛，给所有商品的打分都很低。分数没有可比性，这就会影响相似用户查找的效果，最终影响推荐结果。这个时候我们可以采用之前介绍的特征值变化，对于原始的喜好度矩阵，按照用户的维度对用户所有的喜好度进行归一化或者标准化处理，然后再进行基于用户的协同过滤。</p>
<h2 id="基于物品的过滤">基于物品的过滤</h2>
<p>基于物品的协同过滤是指利用物品相似度，而不是用户间的相似度来计算预测值。我同样用图来帮助你理解。</p>
<p><img alt="" src="assets/0ba91992c32742cb9b65490af53d8628.jpg"/></p>
<p>在这张图中，物品A和C因为都被用户A和B同时访问，因此它们被认为相似度更高。当用户C访问过物品A后，系统会更多地向用户推荐物品C，而不是其他物品。</p>
<p>基于物品的协同过滤同样有两个公式，你可以看一下。</p>
<p><img alt="" src="assets/48e41f293a40484482a61ba93d238da0.jpg"/></p>
<p>如果你弄明白了基于用户的过滤，那么这两个公式也就不难理解了。第一个公式的核心思想是计算物品和物品之间的相似度，在这里我仍然使用夹角余弦。其中<span class="math inline">\(is\_{j1}\)</span>,<span class="math inline">\(j2\)</span>表示物品<span class="math inline">\(j1\)</span>和<span class="math inline">\(j2\)</span>的相似度，而<span class="math inline">\(X\_{j1}\)</span>表示了<span class="math inline">\(X\)</span>中第<span class="math inline">\(j1\)</span>列的列向量，而<span class="math inline">\(X\_{j2}\)</span>表示了<span class="math inline">\(X\)</span>中第<span class="math inline">\(j2\)</span>列的列向量。分子是两个表示物品的列向量之点乘，而分母是这两个列向量<span class="math inline">\(L2\)</span>范数的乘积。</p>
<p>第二个公式利用第一个公式所计算的物品间相似度，和用户对物品的喜好度，预测任一个用户对任一个物品的喜好度。其中<span class="math inline">\(p\_{i,j}\)</span>表示第<span class="math inline">\(i\)</span>用户对第<span class="math inline">\(j\)</span>个物品的喜好度，<span class="math inline">\(x\_{i,k}\)</span>表示用户<span class="math inline">\(i\)</span>对物品<span class="math inline">\(k\)</span>的喜好度，<span class="math inline">\(is\_{k,j}\)</span>表示物品<span class="math inline">\(k\)</span>和<span class="math inline">\(j\)</span>之间的相似度，注意这里除以<span class="math inline">\(Σis\_{k,j}\)</span>是为了进行归一化。从这个公式可以看出，如果<span class="math inline">\(is\_{k,j}\)</span>越大，<span class="math inline">\(x\_{i,k}\)</span>对最终<span class="math inline">\(p\_{i,j}\)</span>的影响越大，反之如果<span class="math inline">\(is\_{k,j}\)</span>越小，<span class="math inline">\(x\_{i,k}\)</span>对最终<span class="math inline">\(p\_{i,j}\)</span>的影响越小，充分体现了“基于相似物品”的推荐。</p>
<p>类似地，用户喜好程度的不一致性，同样会影响相似物品查找的效果，并最终影响推荐结果。我们也需要对于原始的喜好度矩阵，按照用户的维度对用户的所有喜好度，进行归一化或者标准化处理。</p>
<h2 id="总结">总结</h2>
<p>今天我首先简要地介绍了推荐系统的概念和主要思想。为了给用户提供可靠的结果，推荐系统需要充分挖掘历史数据中，用户和物品之间的关系。协同过滤的推荐算法就很好地体现了这一点。</p>
<p>一旦涉及用户和物品的这种二元关系，矩阵就有用武之地了。我通过矩阵来表示用户和物品的关系，并通过矩阵计算来获得协同过滤的结果。协同过滤分为基于用户的过滤和基于物品的过滤两种，它们的核心思想都是相同的，因此矩阵操作也是类似的。在这两个应用场景下，矩阵点乘体现了多个用户或者物品之间的相似程度，以及聚集后的相似程度所导致的最终推荐结果。</p>
<p>当然，基于用户和物品间关系的推荐算法有很多，对矩阵的操作也远远不止点乘、按行求和、元素对应乘除法。我后面会介绍如何使用矩阵的主成分分析或奇异值分解，来进行物品的推荐。</p>
<h2 id="思考题">思考题</h2>
<p>我在介绍推荐算法时，提到了基于物品的协同过滤。请参照基于用户的协同过滤，写出相应的矩阵操作步骤。</p>
<p>欢迎留言和我分享，也欢迎你在留言区写下今天的学习笔记。你可以点击“请朋友读”，把今天的内容分享给你的好友，和他一起精进。</p>
</div>
</div>
<div>
<div id="prePage" style="float: left">
</div>
<div id="nextPage" style="float: right">
</div>
</div>
</div>
</div>
</div>
<div class="copyright">
<hr/>
<p>© 2019 - 2023 <a href="/cdn-cgi/l/email-protection#630f0f0f5a575252535423040e020a0f4d000c0e" target="_blank">Liangliang Lee</a>.
                    Powered by <a href="https://github.com/gin-gonic/gin" target="_blank">gin</a> and <a href="https://github.com/kaiiiz/hexo-theme-book" target="_blank">hexo-theme-book</a>.</p>
</div>
</div>
<a class="off-canvas-overlay" onclick="hide_canvas()"></a>
</div>
<script data-cfasync="false" src="/cdn-cgi/scripts/5c5dd728/cloudflare-static/email-decode.min.js"></script><script>(function(){function c(){var b=a.contentDocument||a.contentWindow.document;if(b){var d=b.createElement('script');d.innerHTML="window.__CF$cv$params={r:'9359cd218f457fe2',t:'MTc0NTU0MTc1NS4wMDAwMDA='};var a=document.createElement('script');a.nonce='';a.src='/cdn-cgi/challenge-platform/scripts/jsd/main.js';document.getElementsByTagName('head')[0].appendChild(a);";b.getElementsByTagName('head')[0].appendChild(d)}}if(document.body){var a=document.createElement('iframe');a.height=1;a.width=1;a.style.position='absolute';a.style.top=0;a.style.left=0;a.style.border='none';a.style.visibility='hidden';document.body.appendChild(a);if('loading'!==document.readyState)c();else if(window.addEventListener)document.addEventListener('DOMContentLoaded',c);else{var e=document.onreadystatechange||function(){};document.onreadystatechange=function(b){e(b);'loading'!==document.readyState&&(document.onreadystatechange=e,c())}}}})();</script></body>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-NPSEEVD756"></script>
<script src="/static/index.js"></script>
</head></html>