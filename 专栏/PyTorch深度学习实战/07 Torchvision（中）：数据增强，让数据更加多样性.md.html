<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<head>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<meta content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=no" name="viewport"/>
<meta content="zh-cn" http-equiv="content-language"/>
<meta content="07 Torchvision（中）：数据增强，让数据更加多样性" name="description"/>
<link href="/static/favicon.png" rel="icon"/>
<title>07 Torchvision（中）：数据增强，让数据更加多样性 </title>
<link href="/static/index.css" rel="stylesheet"/>
<link href="/static/highlight.min.css" rel="stylesheet"/>
<script src="/static/highlight.min.js"></script>
<meta content="Hexo 4.2.0" name="generator"/>
<script data-website-id="83e5d5db-9d06-40e3-b780-cbae722fdf8c" defer="" src="https://umami.lianglianglee.com/script.js"></script>
</head>
<body>
<div class="book-container">
<div class="book-sidebar">
<div class="book-brand">
<a href="/">
<img src="/static/favicon.png"/>
<span>技术文章摘抄</span>
</a>
</div>
<div class="book-menu uncollapsible">
<ul class="uncollapsible">
<li><a class="current-tab" href="/">首页</a></li>
<li><a href="../">上一级</a></li>
</ul>
<ul class="uncollapsible">
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/00%20%e5%bc%80%e7%af%87%e8%af%8d%20%e5%a6%82%e4%bd%95%e9%ab%98%e6%95%88%e5%85%a5%e9%97%a8PyTorch%ef%bc%9f.md.html" id="00 开篇词 如何高效入门PyTorch？.md.html">00 开篇词 如何高效入门PyTorch？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/01%20PyTorch%ef%bc%9a%e7%bd%91%e7%ba%a2%e4%b8%ad%e7%9a%84%e9%a1%b6%e6%b5%81%e6%98%8e%e6%98%9f.md.html" id="01 PyTorch：网红中的顶流明星.md.html">01 PyTorch：网红中的顶流明星.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/02%20NumPy%ef%bc%88%e4%b8%8a%ef%bc%89%ef%bc%9a%e6%a0%b8%e5%bf%83%e6%95%b0%e6%8d%ae%e7%bb%93%e6%9e%84%e8%af%a6%e8%a7%a3.md.html" id="02 NumPy（上）：核心数据结构详解.md.html">02 NumPy（上）：核心数据结构详解.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/03%20NumPy%ef%bc%88%e4%b8%8b%ef%bc%89%ef%bc%9a%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e4%b8%ad%e7%9a%84%e5%b8%b8%e7%94%a8%e6%93%8d%e4%bd%9c.md.html" id="03 NumPy（下）：深度学习中的常用操作.md.html">03 NumPy（下）：深度学习中的常用操作.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/04%20Tensor%ef%bc%9aPyTorch%e4%b8%ad%e6%9c%80%e5%9f%ba%e7%a1%80%e7%9a%84%e8%ae%a1%e7%ae%97%e5%8d%95%e5%85%83.md.html" id="04 Tensor：PyTorch中最基础的计算单元.md.html">04 Tensor：PyTorch中最基础的计算单元.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/05%20Tensor%e5%8f%98%e5%bd%a2%e8%ae%b0%ef%bc%9a%e5%bf%ab%e9%80%9f%e6%8e%8c%e6%8f%a1Tensor%e5%88%87%e5%88%86%e3%80%81%e5%8f%98%e5%bd%a2%e7%ad%89%e6%96%b9%e6%b3%95.md.html" id="05 Tensor变形记：快速掌握Tensor切分、变形等方法.md.html">05 Tensor变形记：快速掌握Tensor切分、变形等方法.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/06%20Torchvision%ef%bc%88%e4%b8%8a%ef%bc%89%ef%bc%9a%e6%95%b0%e6%8d%ae%e8%af%bb%e5%8f%96%ef%bc%8c%e8%ae%ad%e7%bb%83%e5%bc%80%e5%a7%8b%e7%9a%84%e7%ac%ac%e4%b8%80%e6%ad%a5.md.html" id="06 Torchvision（上）：数据读取，训练开始的第一步.md.html">06 Torchvision（上）：数据读取，训练开始的第一步.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/07%20Torchvision%ef%bc%88%e4%b8%ad%ef%bc%89%ef%bc%9a%e6%95%b0%e6%8d%ae%e5%a2%9e%e5%bc%ba%ef%bc%8c%e8%ae%a9%e6%95%b0%e6%8d%ae%e6%9b%b4%e5%8a%a0%e5%a4%9a%e6%a0%b7%e6%80%a7.md.html" id="07 Torchvision（中）：数据增强，让数据更加多样性.md.html">07 Torchvision（中）：数据增强，让数据更加多样性.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/08%20Torchvision%ef%bc%88%e4%b8%8b%ef%bc%89%ef%bc%9a%e5%85%b6%e4%bb%96%e6%9c%89%e8%b6%a3%e7%9a%84%e5%8a%9f%e8%83%bd.md.html" id="08 Torchvision（下）：其他有趣的功能.md.html">08 Torchvision（下）：其他有趣的功能.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/09%20%e5%8d%b7%e7%a7%af%ef%bc%88%e4%b8%8a%ef%bc%89%ef%bc%9a%e5%a6%82%e4%bd%95%e7%94%a8%e5%8d%b7%e7%a7%af%e4%b8%ba%e8%ae%a1%e7%ae%97%e6%9c%ba%e2%80%9c%e5%bc%80%e5%a4%a9%e7%9c%bc%e2%80%9d%ef%bc%9f.md.html" id="09 卷积（上）：如何用卷积为计算机“开天眼”？.md.html">09 卷积（上）：如何用卷积为计算机“开天眼”？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/10%20%e5%8d%b7%e7%a7%af%ef%bc%88%e4%b8%8b%ef%bc%89%ef%bc%9a%e5%a6%82%e4%bd%95%e7%94%a8%e5%8d%b7%e7%a7%af%e4%b8%ba%e8%ae%a1%e7%ae%97%e6%9c%ba%e2%80%9c%e5%bc%80%e5%a4%a9%e7%9c%bc%e2%80%9d%ef%bc%9f.md.html" id="10 卷积（下）：如何用卷积为计算机“开天眼”？.md.html">10 卷积（下）：如何用卷积为计算机“开天眼”？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/11%20%e6%8d%9f%e5%a4%b1%e5%87%bd%e6%95%b0%ef%bc%9a%e5%a6%82%e4%bd%95%e5%b8%ae%e5%8a%a9%e6%a8%a1%e5%9e%8b%e5%ad%a6%e4%bc%9a%e2%80%9c%e8%87%aa%e7%9c%81%e2%80%9d%ef%bc%9f.md.html" id="11 损失函数：如何帮助模型学会“自省”？.md.html">11 损失函数：如何帮助模型学会“自省”？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/12%20%e8%ae%a1%e7%ae%97%e6%a2%af%e5%ba%a6%ef%bc%9a%e7%bd%91%e7%bb%9c%e7%9a%84%e5%89%8d%e5%90%91%e4%b8%8e%e5%8f%8d%e5%90%91%e4%bc%a0%e6%92%ad.md.html" id="12 计算梯度：网络的前向与反向传播.md.html">12 计算梯度：网络的前向与反向传播.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/13%20%e4%bc%98%e5%8c%96%e6%96%b9%e6%b3%95%ef%bc%9a%e6%9b%b4%e6%96%b0%e6%a8%a1%e5%9e%8b%e5%8f%82%e6%95%b0%e7%9a%84%e6%96%b9%e6%b3%95.md.html" id="13 优化方法：更新模型参数的方法.md.html">13 优化方法：更新模型参数的方法.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/14%20%e6%9e%84%e5%bb%ba%e7%bd%91%e7%bb%9c%ef%bc%9a%e4%b8%80%e7%ab%99%e5%bc%8f%e5%ae%9e%e7%8e%b0%e6%a8%a1%e5%9e%8b%e6%90%ad%e5%bb%ba%e4%b8%8e%e8%ae%ad%e7%bb%83.md.html" id="14 构建网络：一站式实现模型搭建与训练.md.html">14 构建网络：一站式实现模型搭建与训练.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/15%20%e5%8f%af%e8%a7%86%e5%8c%96%e5%b7%a5%e5%85%b7%ef%bc%9a%e5%a6%82%e4%bd%95%e5%ae%9e%e7%8e%b0%e8%ae%ad%e7%bb%83%e7%9a%84%e5%8f%af%e8%a7%86%e5%8c%96%e7%9b%91%e6%8e%a7%ef%bc%9f.md.html" id="15 可视化工具：如何实现训练的可视化监控？.md.html">15 可视化工具：如何实现训练的可视化监控？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/16%20%e5%88%86%e5%b8%83%e5%bc%8f%e8%ae%ad%e7%bb%83%ef%bc%9a%e5%a6%82%e4%bd%95%e5%8a%a0%e9%80%9f%e4%bd%a0%e7%9a%84%e6%a8%a1%e5%9e%8b%e8%ae%ad%e7%bb%83%ef%bc%9f.md.html" id="16 分布式训练：如何加速你的模型训练？.md.html">16 分布式训练：如何加速你的模型训练？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/17%20%e5%9b%be%e5%83%8f%e5%88%86%e7%b1%bb%ef%bc%88%e4%b8%8a%ef%bc%89%ef%bc%9a%e5%9b%be%e5%83%8f%e5%88%86%e7%b1%bb%e5%8e%9f%e7%90%86%e4%b8%8e%e5%9b%be%e5%83%8f%e5%88%86%e7%b1%bb%e6%a8%a1%e5%9e%8b.md.html" id="17 图像分类（上）：图像分类原理与图像分类模型.md.html">17 图像分类（上）：图像分类原理与图像分类模型.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/18%20%e5%9b%be%e5%83%8f%e5%88%86%e7%b1%bb%ef%bc%88%e4%b8%8b%ef%bc%89%ef%bc%9a%e5%a6%82%e4%bd%95%e6%9e%84%e5%bb%ba%e4%b8%80%e4%b8%aa%e5%9b%be%e5%83%8f%e5%88%86%e7%b1%bb%e6%a8%a1%e5%9e%8b_.md.html" id="18 图像分类（下）：如何构建一个图像分类模型_.md.html">18 图像分类（下）：如何构建一个图像分类模型_.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/19%20%e5%9b%be%e5%83%8f%e5%88%86%e5%89%b2%ef%bc%88%e4%b8%8a%ef%bc%89%ef%bc%9a%e8%af%a6%e8%a7%a3%e5%9b%be%e5%83%8f%e5%88%86%e5%89%b2%e5%8e%9f%e7%90%86%e4%b8%8e%e5%9b%be%e5%83%8f%e5%88%86%e5%89%b2%e6%a8%a1%e5%9e%8b.md.html" id="19 图像分割（上）：详解图像分割原理与图像分割模型.md.html">19 图像分割（上）：详解图像分割原理与图像分割模型.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/20%20%e5%9b%be%e5%83%8f%e5%88%86%e5%89%b2%ef%bc%88%e4%b8%8b%ef%bc%89%ef%bc%9a%e5%a6%82%e4%bd%95%e6%9e%84%e5%bb%ba%e4%b8%80%e4%b8%aa%e5%9b%be%e5%83%8f%e5%88%86%e5%89%b2%e6%a8%a1%e5%9e%8b%ef%bc%9f.md.html" id="20 图像分割（下）：如何构建一个图像分割模型？.md.html">20 图像分割（下）：如何构建一个图像分割模型？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/21%20NLP%e5%9f%ba%e7%a1%80%ef%bc%88%e4%b8%8a%ef%bc%89%ef%bc%9a%e8%af%a6%e8%a7%a3%e8%87%aa%e7%84%b6%e8%af%ad%e8%a8%80%e5%a4%84%e7%90%86%e5%8e%9f%e7%90%86%e4%b8%8e%e5%b8%b8%e7%94%a8%e7%ae%97%e6%b3%95.md.html" id="21 NLP基础（上）：详解自然语言处理原理与常用算法.md.html">21 NLP基础（上）：详解自然语言处理原理与常用算法.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/22%20NLP%e5%9f%ba%e7%a1%80%ef%bc%88%e4%b8%8b%ef%bc%89%ef%bc%9a%e8%af%a6%e8%a7%a3%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b%e4%b8%8e%e6%b3%a8%e6%84%8f%e5%8a%9b%e6%9c%ba%e5%88%b6.md.html" id="22 NLP基础（下）：详解语言模型与注意力机制.md.html">22 NLP基础（下）：详解语言模型与注意力机制.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/23%20%e6%83%85%e6%84%9f%e5%88%86%e6%9e%90%ef%bc%9a%e5%a6%82%e4%bd%95%e4%bd%bf%e7%94%a8LSTM%e8%bf%9b%e8%a1%8c%e6%83%85%e6%84%9f%e5%88%86%e6%9e%90%ef%bc%9f.md.html" id="23 情感分析：如何使用LSTM进行情感分析？.md.html">23 情感分析：如何使用LSTM进行情感分析？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/24%20%e6%96%87%e6%9c%ac%e5%88%86%e7%b1%bb%ef%bc%9a%e5%a6%82%e4%bd%95%e4%bd%bf%e7%94%a8BERT%e6%9e%84%e5%bb%ba%e6%96%87%e6%9c%ac%e5%88%86%e7%b1%bb%e6%a8%a1%e5%9e%8b%ef%bc%9f.md.html" id="24 文本分类：如何使用BERT构建文本分类模型？.md.html">24 文本分类：如何使用BERT构建文本分类模型？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/25%20%e6%91%98%e8%a6%81%ef%bc%9a%e5%a6%82%e4%bd%95%e5%bf%ab%e9%80%9f%e5%ae%9e%e7%8e%b0%e8%87%aa%e5%8a%a8%e6%96%87%e6%91%98%e7%94%9f%e6%88%90%ef%bc%9f.md.html" id="25 摘要：如何快速实现自动文摘生成？.md.html">25 摘要：如何快速实现自动文摘生成？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/%e5%8a%a0%e9%a4%90%20%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e5%85%b6%e5%ae%9e%e5%b0%b1%e9%82%a3%e4%b9%88%e5%87%a0%e4%bb%b6%e4%ba%8b.md.html" id="加餐 机器学习其实就那么几件事.md.html">加餐 机器学习其实就那么几件事.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/%e7%94%a8%e6%88%b7%e6%95%85%e4%ba%8b%20Tango%ef%bc%9a%e5%b8%88%e5%82%85%e9%a2%86%e8%bf%9b%e9%97%a8%ef%bc%8c%e4%bf%ae%e8%a1%8c%e5%9c%a8%e4%b8%aa%e4%ba%ba.md.html" id="用户故事 Tango：师傅领进门，修行在个人.md.html">用户故事 Tango：师傅领进门，修行在个人.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/%e7%ad%94%e7%96%91%e7%af%87%20%e6%80%9d%e8%80%83%e9%a2%98%e7%ad%94%e6%a1%88%e9%9b%86%e9%94%a6.md.html" id="答疑篇 思考题答案集锦.md.html">答疑篇 思考题答案集锦.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/%e7%bb%93%e6%9d%9f%e8%af%ad%20%e4%ba%ba%e7%94%9f%e5%85%85%e6%bb%a1%e9%80%89%e6%8b%a9%ef%bc%8c%e9%80%89%e6%8b%a9%e4%b8%8e%e5%8a%aa%e5%8a%9b%e5%90%8c%e6%a0%b7%e9%87%8d%e8%a6%81.md.html" id="结束语 人生充满选择，选择与努力同样重要.md.html">结束语 人生充满选择，选择与努力同样重要.md.html</a>
</li>
<li><a href="/assets/捐赠.md.html">捐赠</a></li>
</ul>
</div>
</div>
<div class="sidebar-toggle" onclick="sidebar_toggle()" onmouseleave="remove_inner()" onmouseover="add_inner()">
<div class="sidebar-toggle-inner"></div>
</div>
<div class="off-canvas-content">
<div class="columns">
<div class="column col-12 col-lg-12">
<div class="book-navbar">
<header class="navbar">
<section class="navbar-section">
<a onclick="open_sidebar()">
<i class="icon icon-menu"></i>
</a>
</section>
</header>
</div>
<div class="book-content" style="max-width: 960px; margin: 0 auto;
    overflow-x: auto;
    overflow-y: hidden;">
<div class="book-post">
<div align="center">因收到Google相关通知，网站将会择期关闭。<a href="https://lumendatabase.org/notices/44265620" target="_blank">相关通知内容</a><hr/></div>
<p align="center" id="tip"></p>
<h1 class="title" data-id="07 Torchvision（中）：数据增强，让数据更加多样性" id="title">07 Torchvision（中）：数据增强，让数据更加多样性</h1>
<div><p>你好，我是方远。</p>
<p>上一节课，我们一同迈出了训练开始的第一步——数据读取，初步认识了Torchvision，学习了如何利用Torchvision读取数据。不过仅仅将数据集中的图片读取出来是不够的，在训练的过程中，神经网络模型接收的数据类型是Tensor，而不是PIL对象，因此我们还需要对数据进行预处理操作，比如图像格式的转换。</p>
<p>与此同时，加载后的图像数据可能还需要进行一系列图像变换与增强操作，例如裁切边框、调整图像比例和大小、标准化等，以便模型能够更好地学习到数据的特征。这些操作都可以使用<code>torchvision.transforms</code>工具完成。</p>
<p>今天我们就来学习一下，利用Torchvision如何进行数据预处理操作，如何进行图像变换与增强。</p>
<h2 id="图像处理工具之torchvision-transforms">图像处理工具之torchvision.transforms</h2>
<p>Torchvision库中的<code>torchvision.transforms</code>包中提供了常用的图像操作，包括对Tensor 及PIL Image对象的操作，例如随机切割、旋转、数据类型转换等等。</p>
<p>按照<code>torchvision.transforms</code> 的功能，大致分为以下几类：数据类型转换、对PIL.Image 和 Tensor进行变化和变换的组合。下面我们依次来学习这些类别中的操作。</p>
<h3 id="数据类型转换">数据类型转换</h3>
<p>在上一节课中，我们学习了读取数据集中的图片，读取到的数据是PIL.Image的对象。而在模型训练阶段，需要传入Tensor类型的数据，神经网络才能进行运算。</p>
<p>那么如何将PIL.Image或Numpy.ndarray格式的数据转化为Tensor格式呢？这需要用到<code>transforms.ToTensor()</code> 类。</p>
<p>而反之，将Tensor 或 Numpy.ndarray 格式的数据转化为PIL.Image格式，则使用<code>transforms.ToPILImage(mode=None)</code> 类。它则是ToTensor的一个逆操作，它能把Tensor或Numpy的数组转换成PIL.Image对象。</p>
<p>其中，参数mode代表PIL.Image的模式，如果mode为None（默认值），则根据输入数据的维度进行推断：</p>
<ul>
<li>输入为3通道：mode为’RGB’；</li>
<li>输入为4通道：mode为’RGBA’；</li>
<li>输入为2通道：mode为’LA’;</li>
<li>输入为单通道：mode根据输入数据的类型确定具体模式。</li>
</ul>
<p><img alt="图片" src="assets/7b2d02d3ff5b41739ed8a60ce9d31bcf.jpg"/></p>
<p>说完用法，我们来看一个具体的例子加深理解。以极客时间的LOGO图片（文件名为：jk.jpg）为例，进行一下数据类型的相互转换。具体代码如下。</p>
<pre><code class="language-python">from PIL import Image
from torchvision import transforms 



img = Image.open('jk.jpg') 
display(img)
print(type(img)) # PIL.Image.Image是PIL.JpegImagePlugin.JpegImageFile的基类
'''
输出: 
&lt;class 'PIL.JpegImagePlugin.JpegImageFile'&gt;
'''

# PIL.Image转换为Tensor
img1 = transforms.ToTensor()(img)
print(type(img1))
'''
输出: 
&lt;class 'torch.Tensor'&gt;
'''

# Tensor转换为PIL.Image
img2 = transforms.ToPILImage()(img1)  #PIL.Image.Image
print(type(img2))
'''
输出: 
&lt;class 'PIL.Image.Image'&gt;
'''
</code></pre>
<p>首先用读取图片，查看一下图片的类型为PIL.JpegImagePlugin.JpegImageFile，这里需要注意<strong>，PIL.JpegImagePlugin.JpegImageFile类是PIL.Image.Image类的子类</strong>。然后，用<code>transforms.ToTensor()</code> 将PIL.Image转换为Tensor。最后，再将Tensor转换回PIL.Image。</p>
<h3 id="对-pil-image-和-tensor-进行变换">对 PIL.Image 和 Tensor 进行变换</h3>
<p><code>torchvision.transforms</code> 提供了丰富的图像变换方法，例如：改变尺寸、剪裁、翻转等。并且这些图像变换操作可以接收多种数据格式，不仅可以直接对PIL格式的图像进行变换，也可以对Tensor进行变换，无需我们再去做额外的数据类型转换。</p>
<p>下面我们依次来看一看。</p>
<h4 id="resize">Resize</h4>
<p>将输入的 PIL Image 或 Tensor 尺寸调整为给定的尺寸，具体定义为：</p>
<pre><code class="language-python">torchvision.transforms.Resize(size, interpolation=2)
</code></pre>
<p>我们依次看下相关的参数：</p>
<ul>
<li>size：期望输出的尺寸。如果 size 是一个像 (h, w) 这样的元组，则图像输出尺寸将与之匹配。如果 size 是一个 int 类型的整数，图像较小的边将被匹配到该整数，另一条边按比例缩放。</li>
<li>interpolation：插值算法，int类型，默认为2，表示 PIL.Image.BILINEAR。</li>
</ul>
<p>有关Size中是tuple还是int这一点请你一定要注意。</p>
<p>让我说明一下，在我们训练时，通常要把图片resize到一定的大小，比如说128x128，256x256这样的。如果直接给定resize后的高与宽，是没有问题的。但如果设定的是一个int型，较长的边就会按比例缩放。</p>
<p>在resize之后呢，一般会接一个crop操作，crop到指定的大小。对于高与宽接近的图片来说，这么做问题不大，但是高与宽的差距较大时，就会crop掉很多有用的信息。关于这一点，我们在后续的图像分类部分还会遇到，到时我在详细展开。</p>
<p>我们还是以极客时间的LOGO图片为例，一起看一下Resize的效果。</p>
<pre><code class="language-python">from PIL import Image
from torchvision import transforms 

# 定义一个Resize操作
resize_img_oper = transforms.Resize((200,200), interpolation=2)

# 原图
orig_img = Image.open('jk.jpg') 
display(orig_img)

# Resize操作后的图
img = resize_img_oper(orig_img)
display(img)
</code></pre>
<p>首先定义一个Resize操作，设置好变换后的尺寸为(200, 200)，然后对极客时间LOGO图片进行Resize变换。-
原图以及Resize变换后的效果如下表所示。</p>
<p><img alt="图片" src="assets/31953dd7422349558967b1fb5105b946.jpg"/></p>
<h4 id="剪裁">剪裁</h4>
<p><code>torchvision.transforms</code>提供了多种剪裁方法，例如中心剪裁、随机剪裁、四角和中心剪裁等。我们依次来看下它们的定义。</p>
<p>先说中心剪裁，顾名思义，在中心裁剪指定的 PIL Image 或 Tensor，其定义如下：</p>
<pre><code class="language-python">torchvision.transforms.CenterCrop(size)
</code></pre>
<p>其中，size表示期望输出的剪裁尺寸。如果 size 是一个像 (h, w) 这样的元组，则剪裁后的图像尺寸将与之匹配。如果 size 是 int 类型的整数，剪裁出来的图像是 (size, size) 的正方形。</p>
<p>然后是随机剪裁，就是在一个随机位置剪裁指定的 PIL Image 或 Tensor，定义如下：</p>
<pre><code class="language-python">torchvision.transforms.RandomCrop(size, padding=None)
</code></pre>
<p>其中，size代表期望输出的剪裁尺寸，用法同上。而padding表示图像的每个边框上的可选填充。默认值是 None，即没有填充。通常来说，不会用padding这个参数，至少对于我来说至今没用过。</p>
<p>最后要说的是FiveCrop，我们将给定的 PIL Image 或 Tensor ，分别从四角和中心进行剪裁，共剪裁成五块，定义如下：</p>
<pre><code>torchvision.transforms.FiveCrop(size)
</code></pre>
<p>size可以是int或tuple，用法同上。-
掌握了各种剪裁的定义和参数用法以后，我们来看一下这些剪裁操作具体如何调用，代码如下。</p>
<pre><code class="language-python">from PIL import Image
from torchvision import transforms 

# 定义剪裁操作
center_crop_oper = transforms.CenterCrop((60,70))
random_crop_oper = transforms.RandomCrop((80,80))
five_crop_oper = transforms.FiveCrop((60,70))

# 原图
orig_img = Image.open('jk.jpg') 
display(orig_img)

# 中心剪裁
img1 = center_crop_oper(orig_img)
display(img1)
# 随机剪裁
img2 = random_crop_oper(orig_img)
display(img2)
# 四角和中心剪裁
imgs = five_crop_oper(orig_img)
for img in imgs:
    display(img)
</code></pre>
<p>流程和Resize类似，都是先定义剪裁操作，然后对极客时间LOGO图片进行不同的剪裁。-
具体剪裁效果如下表所示。</p>
<p><img alt="图片" src="assets/99d8daca017040d6a74254d1aef13f9f.jpg"/></p>
<h4 id="翻转">翻转</h4>
<p>接下来，我们来看一看翻转操作。<code>torchvision.transforms</code>提供了两种翻转操作，分别是：以某一概率随机水平翻转图像和以某一概率随机垂直翻转图像。我们分别来看它们的定义。</p>
<p>以概率p随机水平翻转图像，定义如下：</p>
<pre><code class="language-plain">torchvision.transforms.RandomHorizontalFlip(p=0.5)
</code></pre>
<p>以概率p随机垂直翻转图像，定义如下：</p>
<pre><code class="language-plain">torchvision.transforms.RandomVerticalFlip(p=0.5)
</code></pre>
<p>其中，p表示随机翻转的概率值，默认为0.5。-
这里的随机翻转，是为数据增强提供方便。如果想要必须执行翻转操作的话，将p设置为1即可。</p>
<p>以极客时间的LOGO图片为例，图片翻转的代码如下。</p>
<pre><code class="language-python">from PIL import Image
from torchvision import transforms 

# 定义翻转操作
h_flip_oper = transforms.RandomHorizontalFlip(p=1)
v_flip_oper = transforms.RandomVerticalFlip(p=1)

# 原图
orig_img = Image.open('jk.jpg') 
display(orig_img)

# 水平翻转
img1 = h_flip_oper(orig_img)
display(img1)
# 垂直翻转
img2 = v_flip_oper(orig_img)
display(img2)
</code></pre>
<p>翻转效果如下表所示。</p>
<p><img alt="图片" src="assets/7cff3a44ac4d41839a25cec70bf77396.jpg"/></p>
<h3 id="只对tensor进行变换">只对Tensor进行变换</h3>
<p>目前版本的Torchvision（v0.10.0）对各种图像变换操作已经基本同时支持 PIL Image 和 Tensor 类型了，因此只针对Tensor的变换操作很少，只有4个，分别是LinearTransformation（线性变换）、Normalize（标准化）、RandomErasing（随机擦除）、ConvertImageDtype（格式转换）。</p>
<p>这里我们重点来看最常用的一个操作：标准化，其他3个你可以查阅官方文档。</p>
<h4 id="标准化">标准化</h4>
<p>标准化是指每一个数据点减去所在通道的平均值，再除以所在通道的标准差，数学的计算公式如下：</p>
<p><span class="math display">\[output=(input-mean)/std\]</span></p><p>而对图像进行标准化，就是对图像的每个通道利用均值和标准差进行正则化。这样做的目的，是<strong>为了保证数据集中所有的图像分布都相似，这样在训练的时候更容易收敛，既加快了训练速度，也提高了训练效果</strong>。</p>
<p>让我来解释一下：首先，标准化是一个常规做法，可以理解为无脑进行标准化后再训练的效果，大概率要好于不进行标准化。</p>
<p>我把极客时间的LOGO读入后，所有像素都减去50，获得下图。</p>
<p><img alt="图片" src="assets/4a669e60e9b64578a9a80a0ffebcc446.jpg"/></p>
<p>对于我们人来说是可以分辨出，这也是极客时间的LOGO。但是计算机（也就是卷积神经网络）就不一定能分辨出来了，因为卷积神经网络是通过图像的像素进行提取特征的，这两张图片像素的数值都不一样，凭什么还让神经网络认为是一张图片？</p>
<p>而标准化后的数据就会避免这一问题，标准化后会将数据映射到同一区间中，一个类别的图片虽说有的像素值可能有差异，但是它们分布都是类似的分布。</p>
<p><code>torchvision.transforms</code>提供了对Tensor进行标准化的函数，定义如下。</p>
<pre><code class="language-plain">torchvision.transforms.Normalize(mean, std, inplace=False)
</code></pre>
<p>其中，每个参数的含义如下所示：</p>
<ul>
<li>mean：表示各通道的均值；</li>
<li>std：表示各通道的标准差；</li>
<li>inplace：表示是否原地操作，默认为否。</li>
</ul>
<p>以极客时间的LOGO图片为例，我们来看看以(R, G, B)均值和标准差均为(0.5, 0.5, 0.5)来标准化图片后，是什么效果。</p>
<pre><code class="language-python">from PIL import Image
from torchvision import transforms 

# 定义标准化操作
norm_oper = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))

# 原图
orig_img = Image.open('jk.jpg') 
display(orig_img)

# 图像转化为Tensor
img_tensor = transforms.ToTensor()(orig_img)

# 标准化
tensor_norm = norm_oper(img_tensor)

# Tensor转化为图像
img_norm = transforms.ToPILImage()(tensor_norm)
display(img_norm)
</code></pre>
<p>上面代码的过程是，首先定义了均值和标准差均为(0.5, 0.5, 0.5)的标准化操作，然后将原图转化为Tensor，接着对Tensor进行标准化，最后再将Tensor转化为图像输出。</p>
<p>标准化的效果如下表所示。</p>
<p><img alt="" src="assets/b53c826e514c456b8d5d1414a61a7150.jpg"/></p>
<h3 id="变换的组合">变换的组合</h3>
<p>其实前面介绍过的所有操作都可以用 Compose 类组合起来，进行连续操作。</p>
<p>Compose类是将多个变换组合到一起，它的定义如下。</p>
<pre><code class="language-plain">torchvision.transforms.Compose(transforms)
</code></pre>
<p>其中，transforms是一个Transform对象的列表，表示要组合的变换列表。-
我们还是结合例子动手试试，如果我们想要将图片变为200*200像素大小，并且随机裁切成80像素的正方形。那么我们可以组合Resize和RandomCrop变换，具体代码如下所示。</p>
<pre><code class="language-python">from PIL import Image
from torchvision import transforms 

# 原图
orig_img = Image.open('jk.jpg') 
display(orig_img)

# 定义组合操作
composed = transforms.Compose([transforms.Resize((200, 200)),
                               transforms.RandomCrop(80)])

# 组合操作后的图
img = composed(orig_img)
display(img)
</code></pre>
<p>运行的结果如下表所示，也推荐你动手试试看。</p>
<p><img alt="图片" src="assets/9889ceb5643a4c84b11924e7c68db722.jpg"/></p>
<h2 id="结合datasets使用">结合datasets使用</h2>
<p>Compose类是未来我们在实际项目中经常要使用到的类，结合<code>torchvision.datasets</code>包，就可以在读取数据集的时候做图像变换与数据增强操作。下面让我们一起来看一看。</p>
<p>还记得<a href="https://time.geekbang.org/column/article/429048" target="_blank">上一节课</a>中，在利用<code>torchvision.datasets</code> 读取MNIST数据集时，有一个参数“transform”吗？它就是用于对图像进行预处理操作的，例如数据增强、归一化、旋转或缩放等。这里的“transform”就可以接收一个<code>torchvision.transforms</code>操作或者由Compose类所定义的操作组合。</p>
<p>上节课中，我们在读取MNIST数据集时，直接读取出来的图像数据是PIL.Image.Image类型的。但是遇到要训练手写数字识别模型这类的情况，模型接收的数据类型是Tensor，而不是PIL对象。这时候，我们就可以利用“transform”参数，使数据在读取的同时做类型转换，这样读取出的数据直接就可以是Tensor类型了。</p>
<p>不只是数据类型的转换，我们还可以增加归一化等数据增强的操作，只需要使用上面介绍过的Compose类进行组合即可。这样，在读取数据的同时，我们也就完成了数据预处理、数据增强等一系列操作。</p>
<p>我们还是以读取MNIST数据集为例，看下如何在读取数据的同时，完成数据预处理等操作。具体代码如下。</p>
<pre><code class="language-python">from torchvision import transforms
from torchvision import datasets

# 定义一个transform
my_transform = transforms.Compose([transforms.ToTensor(),
                                   transforms.Normalize((0.5), (0.5))
                                  ])
# 读取MNIST数据集 同时做数据变换
mnist_dataset = datasets.MNIST(root='./data',
                               train=False,
                               transform=my_transform,
                               target_transform=None,
                               download=True)

# 查看变换后的数据类型
item = mnist_dataset.__getitem__(0)
print(type(item[0]))
'''
输出：
&lt;class 'torch.Tensor'&gt;
'''
</code></pre>
<p>当然，MNIST数据集非常简单，根本不进行任何处理直接读入的话，效果也非常好，但是它确实适合学习来使用，你可以在利用它进行各种尝试。</p>
<p>我们下面先来看看，在图像分类实战中使用的transform，可以感受一下实际使用的transforms是什么样子：</p>
<pre><code class="language-python">transform = transforms.Compose([
    transforms.RandomResizedCrop(dest_image_size),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
</code></pre>
<p>这也是我在项目中使用的transform。数据增强的方法有很多，不过根据我的经验来看，并不是用的越多，效果越好。</p>
<h2 id="小结">小结</h2>
<p>恭喜你完成了这节课的学习，我来给你做个总结。</p>
<p><strong>今天的重点内容就是<code>torchvision.transforms</code>工具的使用。包括常用的图像处理操作，以及如何与<code>torchvision.datasets</code>结合使用</strong>。</p>
<p>常用的图像处理操作包括数据类型转换、图像尺寸变化、剪裁、翻转、标准化等等。Compose类还可以将多个变换操作组合成一个Transform对象的列表。</p>
<p><code>torchvision.transforms</code>与<code>torchvision.datasets</code>结合使用，可以在数据加载的同时进行一系列图像变换与数据增强操作，不仅能够直接将数据送入模型训练，还可以加快模型收敛速度，让模型更好地学习到数据特征。</p>
<p>当然，我们在实际的项目中会有自己的数据，而不会使用torchvision.datasets中提供的公开数据集，我们今天讲的<code>torchvision.transforms</code> 同样可以在我们自定义的数据集中使用，关于这一点，我会在图像分类的实战中继续讲解。</p>
<p>下节课中，我们会介绍Torchvision中其他有趣的功能。包括经典网络模型的实例化与其他有用的函数。</p>
<h2 id="每课一练">每课一练</h2>
<p>Torchvision中 transforms 模块的作用是什么？</p>
<p>欢迎你在留言区跟我交流讨论，也欢迎你把这节课分享给自己的朋友，和他一起尝试一下Torchvision的各种功能。</p>
</div>
</div>
<div>
<div id="prePage" style="float: left">
</div>
<div id="nextPage" style="float: right">
</div>
</div>
</div>
</div>
</div>
<div class="copyright">
<hr/>
<p>© 2019 - 2023 <a href="/cdn-cgi/l/email-protection#7b171717424f4a4a4b4c3b1c161a121755181416" target="_blank">Liangliang Lee</a>.
                    Powered by <a href="https://github.com/gin-gonic/gin" target="_blank">gin</a> and <a href="https://github.com/kaiiiz/hexo-theme-book" target="_blank">hexo-theme-book</a>.</p>
</div>
</div>
<a class="off-canvas-overlay" onclick="hide_canvas()"></a>
</div>
<script data-cfasync="false" src="/cdn-cgi/scripts/5c5dd728/cloudflare-static/email-decode.min.js"></script><script>(function(){function c(){var b=a.contentDocument||a.contentWindow.document;if(b){var d=b.createElement('script');d.innerHTML="window.__CF$cv$params={r:'9358707f5dc33994',t:'MTc0NTUyNzQ3NS4wMDAwMDA='};var a=document.createElement('script');a.nonce='';a.src='/cdn-cgi/challenge-platform/scripts/jsd/main.js';document.getElementsByTagName('head')[0].appendChild(a);";b.getElementsByTagName('head')[0].appendChild(d)}}if(document.body){var a=document.createElement('iframe');a.height=1;a.width=1;a.style.position='absolute';a.style.top=0;a.style.left=0;a.style.border='none';a.style.visibility='hidden';document.body.appendChild(a);if('loading'!==document.readyState)c();else if(window.addEventListener)document.addEventListener('DOMContentLoaded',c);else{var e=document.onreadystatechange||function(){};document.onreadystatechange=function(b){e(b);'loading'!==document.readyState&&(document.onreadystatechange=e,c())}}}})();</script></body>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-NPSEEVD756"></script>
<script src="/static/index.js"></script>
</head></html>