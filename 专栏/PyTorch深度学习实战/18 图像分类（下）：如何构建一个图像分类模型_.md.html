<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<head>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<meta content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=no" name="viewport"/>
<meta content="zh-cn" http-equiv="content-language"/>
<meta content="18 图像分类（下）：如何构建一个图像分类模型_" name="description"/>
<link href="/static/favicon.png" rel="icon"/>
<title>18 图像分类（下）：如何构建一个图像分类模型_ </title>
<link href="/static/index.css" rel="stylesheet"/>
<link href="/static/highlight.min.css" rel="stylesheet"/>
<script src="/static/highlight.min.js"></script>
<meta content="Hexo 4.2.0" name="generator"/>
<script data-website-id="83e5d5db-9d06-40e3-b780-cbae722fdf8c" defer="" src="https://umami.lianglianglee.com/script.js"></script>
</head>
<body>
<div class="book-container">
<div class="book-sidebar">
<div class="book-brand">
<a href="/">
<img src="/static/favicon.png"/>
<span>技术文章摘抄</span>
</a>
</div>
<div class="book-menu uncollapsible">
<ul class="uncollapsible">
<li><a class="current-tab" href="/">首页</a></li>
<li><a href="../">上一级</a></li>
</ul>
<ul class="uncollapsible">
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/00%20%e5%bc%80%e7%af%87%e8%af%8d%20%e5%a6%82%e4%bd%95%e9%ab%98%e6%95%88%e5%85%a5%e9%97%a8PyTorch%ef%bc%9f.md.html" id="00 开篇词 如何高效入门PyTorch？.md.html">00 开篇词 如何高效入门PyTorch？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/01%20PyTorch%ef%bc%9a%e7%bd%91%e7%ba%a2%e4%b8%ad%e7%9a%84%e9%a1%b6%e6%b5%81%e6%98%8e%e6%98%9f.md.html" id="01 PyTorch：网红中的顶流明星.md.html">01 PyTorch：网红中的顶流明星.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/02%20NumPy%ef%bc%88%e4%b8%8a%ef%bc%89%ef%bc%9a%e6%a0%b8%e5%bf%83%e6%95%b0%e6%8d%ae%e7%bb%93%e6%9e%84%e8%af%a6%e8%a7%a3.md.html" id="02 NumPy（上）：核心数据结构详解.md.html">02 NumPy（上）：核心数据结构详解.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/03%20NumPy%ef%bc%88%e4%b8%8b%ef%bc%89%ef%bc%9a%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e4%b8%ad%e7%9a%84%e5%b8%b8%e7%94%a8%e6%93%8d%e4%bd%9c.md.html" id="03 NumPy（下）：深度学习中的常用操作.md.html">03 NumPy（下）：深度学习中的常用操作.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/04%20Tensor%ef%bc%9aPyTorch%e4%b8%ad%e6%9c%80%e5%9f%ba%e7%a1%80%e7%9a%84%e8%ae%a1%e7%ae%97%e5%8d%95%e5%85%83.md.html" id="04 Tensor：PyTorch中最基础的计算单元.md.html">04 Tensor：PyTorch中最基础的计算单元.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/05%20Tensor%e5%8f%98%e5%bd%a2%e8%ae%b0%ef%bc%9a%e5%bf%ab%e9%80%9f%e6%8e%8c%e6%8f%a1Tensor%e5%88%87%e5%88%86%e3%80%81%e5%8f%98%e5%bd%a2%e7%ad%89%e6%96%b9%e6%b3%95.md.html" id="05 Tensor变形记：快速掌握Tensor切分、变形等方法.md.html">05 Tensor变形记：快速掌握Tensor切分、变形等方法.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/06%20Torchvision%ef%bc%88%e4%b8%8a%ef%bc%89%ef%bc%9a%e6%95%b0%e6%8d%ae%e8%af%bb%e5%8f%96%ef%bc%8c%e8%ae%ad%e7%bb%83%e5%bc%80%e5%a7%8b%e7%9a%84%e7%ac%ac%e4%b8%80%e6%ad%a5.md.html" id="06 Torchvision（上）：数据读取，训练开始的第一步.md.html">06 Torchvision（上）：数据读取，训练开始的第一步.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/07%20Torchvision%ef%bc%88%e4%b8%ad%ef%bc%89%ef%bc%9a%e6%95%b0%e6%8d%ae%e5%a2%9e%e5%bc%ba%ef%bc%8c%e8%ae%a9%e6%95%b0%e6%8d%ae%e6%9b%b4%e5%8a%a0%e5%a4%9a%e6%a0%b7%e6%80%a7.md.html" id="07 Torchvision（中）：数据增强，让数据更加多样性.md.html">07 Torchvision（中）：数据增强，让数据更加多样性.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/08%20Torchvision%ef%bc%88%e4%b8%8b%ef%bc%89%ef%bc%9a%e5%85%b6%e4%bb%96%e6%9c%89%e8%b6%a3%e7%9a%84%e5%8a%9f%e8%83%bd.md.html" id="08 Torchvision（下）：其他有趣的功能.md.html">08 Torchvision（下）：其他有趣的功能.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/09%20%e5%8d%b7%e7%a7%af%ef%bc%88%e4%b8%8a%ef%bc%89%ef%bc%9a%e5%a6%82%e4%bd%95%e7%94%a8%e5%8d%b7%e7%a7%af%e4%b8%ba%e8%ae%a1%e7%ae%97%e6%9c%ba%e2%80%9c%e5%bc%80%e5%a4%a9%e7%9c%bc%e2%80%9d%ef%bc%9f.md.html" id="09 卷积（上）：如何用卷积为计算机“开天眼”？.md.html">09 卷积（上）：如何用卷积为计算机“开天眼”？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/10%20%e5%8d%b7%e7%a7%af%ef%bc%88%e4%b8%8b%ef%bc%89%ef%bc%9a%e5%a6%82%e4%bd%95%e7%94%a8%e5%8d%b7%e7%a7%af%e4%b8%ba%e8%ae%a1%e7%ae%97%e6%9c%ba%e2%80%9c%e5%bc%80%e5%a4%a9%e7%9c%bc%e2%80%9d%ef%bc%9f.md.html" id="10 卷积（下）：如何用卷积为计算机“开天眼”？.md.html">10 卷积（下）：如何用卷积为计算机“开天眼”？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/11%20%e6%8d%9f%e5%a4%b1%e5%87%bd%e6%95%b0%ef%bc%9a%e5%a6%82%e4%bd%95%e5%b8%ae%e5%8a%a9%e6%a8%a1%e5%9e%8b%e5%ad%a6%e4%bc%9a%e2%80%9c%e8%87%aa%e7%9c%81%e2%80%9d%ef%bc%9f.md.html" id="11 损失函数：如何帮助模型学会“自省”？.md.html">11 损失函数：如何帮助模型学会“自省”？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/12%20%e8%ae%a1%e7%ae%97%e6%a2%af%e5%ba%a6%ef%bc%9a%e7%bd%91%e7%bb%9c%e7%9a%84%e5%89%8d%e5%90%91%e4%b8%8e%e5%8f%8d%e5%90%91%e4%bc%a0%e6%92%ad.md.html" id="12 计算梯度：网络的前向与反向传播.md.html">12 计算梯度：网络的前向与反向传播.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/13%20%e4%bc%98%e5%8c%96%e6%96%b9%e6%b3%95%ef%bc%9a%e6%9b%b4%e6%96%b0%e6%a8%a1%e5%9e%8b%e5%8f%82%e6%95%b0%e7%9a%84%e6%96%b9%e6%b3%95.md.html" id="13 优化方法：更新模型参数的方法.md.html">13 优化方法：更新模型参数的方法.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/14%20%e6%9e%84%e5%bb%ba%e7%bd%91%e7%bb%9c%ef%bc%9a%e4%b8%80%e7%ab%99%e5%bc%8f%e5%ae%9e%e7%8e%b0%e6%a8%a1%e5%9e%8b%e6%90%ad%e5%bb%ba%e4%b8%8e%e8%ae%ad%e7%bb%83.md.html" id="14 构建网络：一站式实现模型搭建与训练.md.html">14 构建网络：一站式实现模型搭建与训练.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/15%20%e5%8f%af%e8%a7%86%e5%8c%96%e5%b7%a5%e5%85%b7%ef%bc%9a%e5%a6%82%e4%bd%95%e5%ae%9e%e7%8e%b0%e8%ae%ad%e7%bb%83%e7%9a%84%e5%8f%af%e8%a7%86%e5%8c%96%e7%9b%91%e6%8e%a7%ef%bc%9f.md.html" id="15 可视化工具：如何实现训练的可视化监控？.md.html">15 可视化工具：如何实现训练的可视化监控？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/16%20%e5%88%86%e5%b8%83%e5%bc%8f%e8%ae%ad%e7%bb%83%ef%bc%9a%e5%a6%82%e4%bd%95%e5%8a%a0%e9%80%9f%e4%bd%a0%e7%9a%84%e6%a8%a1%e5%9e%8b%e8%ae%ad%e7%bb%83%ef%bc%9f.md.html" id="16 分布式训练：如何加速你的模型训练？.md.html">16 分布式训练：如何加速你的模型训练？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/17%20%e5%9b%be%e5%83%8f%e5%88%86%e7%b1%bb%ef%bc%88%e4%b8%8a%ef%bc%89%ef%bc%9a%e5%9b%be%e5%83%8f%e5%88%86%e7%b1%bb%e5%8e%9f%e7%90%86%e4%b8%8e%e5%9b%be%e5%83%8f%e5%88%86%e7%b1%bb%e6%a8%a1%e5%9e%8b.md.html" id="17 图像分类（上）：图像分类原理与图像分类模型.md.html">17 图像分类（上）：图像分类原理与图像分类模型.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/18%20%e5%9b%be%e5%83%8f%e5%88%86%e7%b1%bb%ef%bc%88%e4%b8%8b%ef%bc%89%ef%bc%9a%e5%a6%82%e4%bd%95%e6%9e%84%e5%bb%ba%e4%b8%80%e4%b8%aa%e5%9b%be%e5%83%8f%e5%88%86%e7%b1%bb%e6%a8%a1%e5%9e%8b_.md.html" id="18 图像分类（下）：如何构建一个图像分类模型_.md.html">18 图像分类（下）：如何构建一个图像分类模型_.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/19%20%e5%9b%be%e5%83%8f%e5%88%86%e5%89%b2%ef%bc%88%e4%b8%8a%ef%bc%89%ef%bc%9a%e8%af%a6%e8%a7%a3%e5%9b%be%e5%83%8f%e5%88%86%e5%89%b2%e5%8e%9f%e7%90%86%e4%b8%8e%e5%9b%be%e5%83%8f%e5%88%86%e5%89%b2%e6%a8%a1%e5%9e%8b.md.html" id="19 图像分割（上）：详解图像分割原理与图像分割模型.md.html">19 图像分割（上）：详解图像分割原理与图像分割模型.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/20%20%e5%9b%be%e5%83%8f%e5%88%86%e5%89%b2%ef%bc%88%e4%b8%8b%ef%bc%89%ef%bc%9a%e5%a6%82%e4%bd%95%e6%9e%84%e5%bb%ba%e4%b8%80%e4%b8%aa%e5%9b%be%e5%83%8f%e5%88%86%e5%89%b2%e6%a8%a1%e5%9e%8b%ef%bc%9f.md.html" id="20 图像分割（下）：如何构建一个图像分割模型？.md.html">20 图像分割（下）：如何构建一个图像分割模型？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/21%20NLP%e5%9f%ba%e7%a1%80%ef%bc%88%e4%b8%8a%ef%bc%89%ef%bc%9a%e8%af%a6%e8%a7%a3%e8%87%aa%e7%84%b6%e8%af%ad%e8%a8%80%e5%a4%84%e7%90%86%e5%8e%9f%e7%90%86%e4%b8%8e%e5%b8%b8%e7%94%a8%e7%ae%97%e6%b3%95.md.html" id="21 NLP基础（上）：详解自然语言处理原理与常用算法.md.html">21 NLP基础（上）：详解自然语言处理原理与常用算法.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/22%20NLP%e5%9f%ba%e7%a1%80%ef%bc%88%e4%b8%8b%ef%bc%89%ef%bc%9a%e8%af%a6%e8%a7%a3%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b%e4%b8%8e%e6%b3%a8%e6%84%8f%e5%8a%9b%e6%9c%ba%e5%88%b6.md.html" id="22 NLP基础（下）：详解语言模型与注意力机制.md.html">22 NLP基础（下）：详解语言模型与注意力机制.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/23%20%e6%83%85%e6%84%9f%e5%88%86%e6%9e%90%ef%bc%9a%e5%a6%82%e4%bd%95%e4%bd%bf%e7%94%a8LSTM%e8%bf%9b%e8%a1%8c%e6%83%85%e6%84%9f%e5%88%86%e6%9e%90%ef%bc%9f.md.html" id="23 情感分析：如何使用LSTM进行情感分析？.md.html">23 情感分析：如何使用LSTM进行情感分析？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/24%20%e6%96%87%e6%9c%ac%e5%88%86%e7%b1%bb%ef%bc%9a%e5%a6%82%e4%bd%95%e4%bd%bf%e7%94%a8BERT%e6%9e%84%e5%bb%ba%e6%96%87%e6%9c%ac%e5%88%86%e7%b1%bb%e6%a8%a1%e5%9e%8b%ef%bc%9f.md.html" id="24 文本分类：如何使用BERT构建文本分类模型？.md.html">24 文本分类：如何使用BERT构建文本分类模型？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/25%20%e6%91%98%e8%a6%81%ef%bc%9a%e5%a6%82%e4%bd%95%e5%bf%ab%e9%80%9f%e5%ae%9e%e7%8e%b0%e8%87%aa%e5%8a%a8%e6%96%87%e6%91%98%e7%94%9f%e6%88%90%ef%bc%9f.md.html" id="25 摘要：如何快速实现自动文摘生成？.md.html">25 摘要：如何快速实现自动文摘生成？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/%e5%8a%a0%e9%a4%90%20%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e5%85%b6%e5%ae%9e%e5%b0%b1%e9%82%a3%e4%b9%88%e5%87%a0%e4%bb%b6%e4%ba%8b.md.html" id="加餐 机器学习其实就那么几件事.md.html">加餐 机器学习其实就那么几件事.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/%e7%94%a8%e6%88%b7%e6%95%85%e4%ba%8b%20Tango%ef%bc%9a%e5%b8%88%e5%82%85%e9%a2%86%e8%bf%9b%e9%97%a8%ef%bc%8c%e4%bf%ae%e8%a1%8c%e5%9c%a8%e4%b8%aa%e4%ba%ba.md.html" id="用户故事 Tango：师傅领进门，修行在个人.md.html">用户故事 Tango：师傅领进门，修行在个人.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/%e7%ad%94%e7%96%91%e7%af%87%20%e6%80%9d%e8%80%83%e9%a2%98%e7%ad%94%e6%a1%88%e9%9b%86%e9%94%a6.md.html" id="答疑篇 思考题答案集锦.md.html">答疑篇 思考题答案集锦.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/PyTorch%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%ae%9e%e6%88%98/%e7%bb%93%e6%9d%9f%e8%af%ad%20%e4%ba%ba%e7%94%9f%e5%85%85%e6%bb%a1%e9%80%89%e6%8b%a9%ef%bc%8c%e9%80%89%e6%8b%a9%e4%b8%8e%e5%8a%aa%e5%8a%9b%e5%90%8c%e6%a0%b7%e9%87%8d%e8%a6%81.md.html" id="结束语 人生充满选择，选择与努力同样重要.md.html">结束语 人生充满选择，选择与努力同样重要.md.html</a>
</li>
<li><a href="/assets/捐赠.md.html">捐赠</a></li>
</ul>
</div>
</div>
<div class="sidebar-toggle" onclick="sidebar_toggle()" onmouseleave="remove_inner()" onmouseover="add_inner()">
<div class="sidebar-toggle-inner"></div>
</div>
<div class="off-canvas-content">
<div class="columns">
<div class="column col-12 col-lg-12">
<div class="book-navbar">
<header class="navbar">
<section class="navbar-section">
<a onclick="open_sidebar()">
<i class="icon icon-menu"></i>
</a>
</section>
</header>
</div>
<div class="book-content" style="max-width: 960px; margin: 0 auto;
    overflow-x: auto;
    overflow-y: hidden;">
<div class="book-post">
<div align="center">因收到Google相关通知，网站将会择期关闭。<a href="https://lumendatabase.org/notices/44265620" target="_blank">相关通知内容</a><hr/></div>
<p align="center" id="tip"></p>
<h1 class="title" data-id="18 图像分类（下）：如何构建一个图像分类模型_" id="title">18 图像分类（下）：如何构建一个图像分类模型_</h1>
<div><p>你好，我是方远。欢迎来到第18节课的学习。</p>
<p>我相信经过上节课的学习，你已经了解了图像分类的原理，还初步认识了一些经典的卷积神经网络。</p>
<p>正所谓“纸上得来终觉浅，绝知此事要躬行”，今天就让我们把上节课的理论知识应用起来，一起从数据的准备、模型训练以及模型评估，从头至尾一起来完成一个完整的图像分类项目实践。</p>
<p>课程代码你可以从<a href="https://github.com/syuu1987/geekTime-image-classification" target="_blank">这里</a>下载。</p>
<h2 id="问题回顾">问题回顾</h2>
<p>我们先来回顾一下问题背景，我们要解决的问题是，在众多图片中自动识别出极客时间Logo的图片。想要实现自动识别，首先需要分析数据集里的图片是啥样子的。</p>
<p>那我们先来看一张包含极客时间Logo的图片，如下所示。</p>
<p><img alt="图片" src="assets/2b57a49987cd41dba8e6a126b1cc18f1.jpg"/></p>
<p>你可以看到，Logo占整张图片的比例还是比较小的，所以说，如果这个项目是真实存在的，目标检测其实更加合适。不过，我们可以将问题稍微修改一下，修改成自动识别极客时间宣传海报，这其实就很适合图像分类任务了。</p>
<h2 id="数据准备">数据准备</h2>
<p>相比目标检测与图像分割来说，图像分类的数据准备还是比较简单的。在图像分类中，我们只需要将每个类别的图片放到指定的文件夹里就行了。</p>
<p>下图是我的图片组织方式，文件夹就是图片所属的类别。</p>
<p><img alt="图片" src="assets/3ca17660f78c41a6b364d20a27c5c47a.jpg"/></p>
<p>logo文件夹中存放的是10张极客时间海报的图片。</p>
<p><img alt="图片" src="assets/171f640f18dc4d1d9b3cf30e38098e73.jpg"/></p>
<p>而others中，理论上应该是各种其它类型的图片，但这里为了简化问题，我这个文件夹中存放的都是小猫的图片。</p>
<p><img alt="图片" src="assets/09d92eb071b64e14b54d8f810f6094f8.jpg"/></p>
<h2 id="模型训练">模型训练</h2>
<p>好啦，数据准备就绪，我们现在进入模型训练阶段。</p>
<p>今天我想向你介绍一个在最近2年非常受欢迎的一个网络——EfficientNet。它为我们提供了B0～B7，一共8个不同版本的模型，这8个版本有着不同的参数量，在同等参数量的模型中，它的精度都是首屈一指的。因此，这8个版本的模型可以解决你的大多数问题。</p>
<h3 id="efficientnet">EfficientNet</h3>
<p>我先给你解读一下<a href="https://arxiv.org/pdf/1905.11946.pdf" target="_blank">EfficientNet</a>的这篇论文，这里我着重分享论文的核心思路还有我的理解，学有余力的同学可以在课后自行阅读原文。</p>
<p>EfficientNet一共有B0到B7，8个模型，参数量由少到多，精度也越来越高，具体你可以看看后面的评价指标。</p>
<p>在之前的那些网络，要么从网络的深度出发，要么从网络的宽度出发来优化网络的性能，但从来没有人将这些方向结合在一起考虑。<strong>而EfficientNet就做了这样的尝试，它探索了网络深度、网络宽度、图像分辨率之间的最优组合</strong>。</p>
<p>EfficientNet利用一种复合的缩放手段，对网络的深度depth、宽度width和分辨率resolution同时进行缩放（按照一定的缩放规律），来达到精度和运算复杂度FLOPS的权衡。</p>
<p>但即使只探索这三个维度，搜索空间仍然很大，所以作者规定只在B0（作者提出的EfficientNet的一个Baseline）上进行放大。</p>
<p>首先，作者比较了单独放大这三个维度中的任意一个维度效果如何。得出结论是放大网络深度或网络宽度或图像分辨率，均可提升模型精度，但是越放大，精度增加越缓慢，如下图所示：</p>
<p><img alt="图片" src="assets/332761262a8a46f79c1d6acd603fe977.jpg"/></p>
<p>然后，作者做了第二个实验，尝试在不同的r（分辨率），d（深度）组合下变动w（宽度），得到下图：</p>
<p><img alt="图片" src="assets/50b83f53c00d4ce69c4e7828a4fa257c.jpg"/></p>
<p>结论是，得到更高的精度以及效率的关键是平衡网络宽度，网络深度，图像分辨率三个维度的缩放倍率(d, r, w)。</p>
<p>因此，作者提出了混合维度放大法，该方法使用一个<span class="math inline">\(\\phi\)</span>（混合稀疏）来决定三个维度的放大倍率。</p>
<p>深度depth：<span class="math inline">\(d = \\alpha ^{\\phi}\)</span></p>
<p>宽度width：<span class="math inline">\(w = \\beta ^{\\phi}\)</span></p>
<p>分辨率resolution: <span class="math inline">\(r = \\gamma ^{\\phi}\)</span></p>
<p><span class="math display">\[s.t. \\space \\alpha\\cdot\\beta^2\\cdot\\gamma^2 \\approx2 \\space \\space \\alpha \\geq1,\\beta \\geq1,\\gamma \\geq1\]</span></p><p>第一步，固定<span class="math inline">\(\\phi\)</span>为1，也就是计算量为2倍，使用网格搜索，得到了最佳的组合，也就是<span class="math inline">\(\\alpha=1.2, \\beta = 1.1, \\gamma = 1.15\)</span>。</p>
<p>第二步，固定<span class="math inline">\(\\alpha=1.2, \\beta = 1.1, \\gamma = 1.15\)</span>，使用不同的混合稀疏<span class="math inline">\(\\phi\)</span>，得到了B1~B7。</p>
<p>整体评估效果如下图所示：</p>
<p><img alt="图片" src="assets/408a5b158e28419b9c3cf6a437e04958.jpg"/></p>
<p>从评估结果上可以看到，EfficientNet的各个版本均超过了之前的一些经典卷积神经网络。</p>
<p>EfficientNet v2也已经被提出来了，有时间的话你可以自己去看看。</p>
<p>我们不妨借助一下EfficientNet的<a href="https://github.com/lukemelas/EfficientNet-PyTorch" target="_blank">GitHub</a>，它里面有训练ImageNet的demo(demo/imagenet/main.py)，接下来我们一起看看它的核心代码，然后精简一下代码，把它运行起来(Torchvision也提供了EfficientNet的模型，课后你也可以自己试一试)。</p>
<p>这里我们再回顾一下，之前说的机器学习3件套：</p>
<p>1.数据处理-
2.模型训练（构建模型、损失函数与优化方法）-
3.模型评估</p>
<p>接下来我们就挨个看看这些步骤。你需要先把<a href="https://github.com/lukemelas/EfficientNet-PyTorch" target="_blank">https://github.com/lukemelas/EfficientNet-PyTorch</a>给克隆下来，我们只使用efficientnet_pytorch中的内容，它包含着模型的网络结构。</p>
<p>之后我们来创建一个叫做geektime的项目文件夹，然后把efficientnet_pytorch放进去。</p>
<p>在开始之前，我先把程序需要的参数给你列一下，在下面的讲解中，我们就直接使用这些参数了。当你在实现今天代码的时候，需要将这些参数补充到代码中（可以使用argparsem模块）。</p>
<p><img alt="图片" src="assets/9d5a3564cc8540cca0fae6fc756caac1.jpg"/></p>
<p>好，下面让我们正式开始动手。</p>
<h3 id="加载数据">加载数据</h3>
<p>首先是数据加载的环节，我们创建一个dataset.py文件，用来存储与数据有关的内容。dataset.py如下（我省略了模块的引入）。</p>
<pre><code class="language-python">
# 作者给出的标准化方法
def _norm_advprop(img):
    return img * 2.0 - 1.0

def build_transform(dest_image_size):
    normalize = transforms.Lambda(_norm_advprop)

    if not isinstance(dest_image_size, tuple):
        dest_image_size = (dest_image_size, dest_image_size)
    else:
        dest_image_size = dest_image_size

    transform = transforms.Compose([
        transforms.RandomResizedCrop(dest_image_size),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        normalize
    ])

    return transform

def build_data_set(dest_image_size, data):
    transform = build_transform(dest_image_size) 
    dataset=datasets.ImageFolder(data, transform=transform, target_transform=None) 

    return dataset

</code></pre>
<p>这部分代码完成的工作是，通过build_data_set构建数据集。这里我们使用了torchvision.datasets.ImageFolder来创建Dataset。ImageFolder能将按文件夹形式的组织数据生成到一个Dataset。</p>
<p>在这个例子中，我传入的训练集路径为’./data/train’，你可以看看开篇的截图。</p>
<p>ImageFolder会自动的将同一文件夹内的数据打上一个标签，也就是说logo文件夹的数据，ImageFolder会认为是来自同一类别，others文件夹的数据，ImageFolder会认为是来自另外一个类别。</p>
<p>我们这个精简版只构建了训练集的Dataset，当你看Efficient官方代码的时候，在验证集的构建过程中，你需要留意一下验证集的<a href="https://github.com/lukemelas/EfficientNet-PyTorch/blob/master/examples/imagenet/main.py#L240-L245" target="_blank">transforms</a>。</p>
<p>我认为，这里这么做是有点问题的，原因是Resize中size参数如果是个tuple类型，则直接按照size的尺寸进行resize。如果是一个int的时候，如果图片的height大于width，则按照(size * height/width, size)进行resize。</p>
<p>在作者的原始程序中，imag_size是个int，而不是tuple。所以按照这种先resize再crop的方式处理一下，对长宽比比较大的图片来说，效果不是很好。</p>
<p>让我们实际验证一下这个想法，我将开篇的例子（也就是那张海报图）的image_size设定为224后，用上述的方式进行处理后，获得下图。</p>
<p><img alt="图片" src="assets/90f2491c0665452bbe65dcbc917bbd72.jpg"/></p>
<p>你看，是不是缺少了很多信息？</p>
<p>所以，如果在我们的例子中使用作者的程序，就需要做一下修改。把这里的代码逻辑修改为如果image_size不是tuple，先将image_size转换为tuple，并且也不需要crop了。代码如下所示：</p>
<pre><code class="language-python">if not isinstance(image_size, tuple):
    image_size = (image_size, image_size)
else:
    image_size = image_size

transform = transforms.Compose([
    transforms.Resize(image_size, interpolation=Image.BICUBIC),
    transforms.ToTensor(),
    normalize,
])
</code></pre>
<p>训练的主程序我们定义在main.py中，在main.py中的main()中，进行数据的加载，如下所示。</p>
<p>然后，我们通过for循环一个一个Epoch的调用train方法进行训练就可以了。</p>
<pre><code class="language-python"># 省略了一些模块的引入
from efficientnet import EfficientNet
from dataset import build_data_set

def main():
    # part1: 模型加载 (稍后补充)
    # part2: 损失函数、优化方法(稍后补充)    
    train_dataset = build_data_set(args.image_size, args.train_data)

    train_loader = torch.utils.data.DataLoader(
        train_dataset, 
        batch_size=args.batch_size,
        shuffle=True,
        num_workers=args.workers,
        )

    for epoch in range(args.epochs):
        # 调用train函数进行训练，稍后补充
        train(train_loader, model, criterion, optimizer, epoch, args)
        # 模型保存        
        if epoch % args.save_interval == 0:
            if not os.path.exists(args.checkpoint_dir):
                os.mkdir(args.checkpoint_dir)
            torch.save(model.state_dict(), os.path.join(args.checkpoint_dir,
                    'checkpoint.pth.tar.epoch_%s' % epoch))
</code></pre>
<h3 id="创建模型">创建模型</h3>
<p>接下来，我们来看看如何创建模型，这一步我们直接使用作者给出的Efficient模型。在上面代码注释中的part1部分，用下述代码即可加载EfficientNet模型。</p>
<pre><code class="language-python">    args.classes_num = 2
    if args.pretrained:
        model = EfficientNet.from_pretrained(args.arch, num_classes=args.classes_num,
                advprop=args.advprop)
        print("=&gt; using pre-trained model '{}'".format(args.arch))
    else:
        print("=&gt; creating model '{}'".format(args.arch))
        model = EfficientNet.from_name(args.arch, override_params={'num_classes': args.classes_num})
    # 有GPU的话，加上cuda()
    #mode.cuda()
</code></pre>
<p>这段代码是说，如果pretrained model参数为True，则自动下载并加载pretrained model后进行训练，否则是使用随机数初始化网络。-
from_pretrained与from_name中，都需要修改一下num_classes，将EfficientNet的全连接层修改我们项目对应的类别数，这里的args.classes_num为2（logo类与others类）。</p>
<h4 id="模型微调">模型微调</h4>
<p>模型微调在<a href="https://time.geekbang.org/column/article/431420" target="_blank">第8节课</a>和<a href="https://time.geekbang.org/column/article/442442" target="_blank">第14节课</a>时说过，这个概念比较重要，我们一起再复习一下。</p>
<p>Pretrained model一般是在ImageNet（也有可能是COCO或VOC，都是公开数据集）上训练过的模型，我们可以直接把它在ImageNet上训练好的模型参数直接拿过来，在其基础上训练我们自己的模型，这就是模型微调。</p>
<p>所以说，<strong>如果有Pretrained model，我们一定会使用Pretrained model进行训练，收敛速度会快</strong>。</p>
<p>使用Pretrained model的时候要注意一点，在ImageNet上训练后的全连接层一共有1000个节点，所以使用Pretrained model的时候只使用全连接层以外的参数。</p>
<p>在上述代码的EfficientNet.from_pretrained中，会通调用load_pretrained_weights函数，调用之前num_classes已经被修改为2（logo与others），所以说传入load_pretrained_weights的load_fc参数为False，也就是说不会加载全连接层的参数。load_pretrained_weights的调用如下所示：</p>
<pre><code class="language-python">load_pretrained_weights(model, model_name, load_fc=(num_classes == 1000), advprop=advprop)
</code></pre>
<p>load_pretrained_weights函数中包含下面这段代码，就像刚才所说，如果不加载全连接层，则删除_fc的weight与bias：</p>
<pre><code class="language-python">if load_fc:
    ret = model.load_state_dict(state_dict, strict=False)
    assert not ret.missing_keys, 'Missing keys when loading pretrained weights: {}'.format(ret.missing_keys)
else:
    state_dict.pop('_fc.weight')
    state_dict.pop('_fc.bias')
    ret = model.load_state_dict(state_dict, strict=False)
</code></pre>
<h3 id="设定损失函数与优化方法">设定损失函数与优化方法</h3>
<p>最后要做的就是设定损失函数与优化方法了，我们将下面的代码补充到part2部分：</p>
<pre><code class="language-python">criterion = nn.CrossEntropyLoss() # 有GPU的话加上.cuda()

optimizer = torch.optim.SGD(model.parameters(), args.lr,
                            momentum=args.momentum,
                            weight_decay=args.weight_decay)
</code></pre>
<p>到这里，我们就完成训练的所有准备了，只要再补充好train函数就可以了，代码如下。下面的代码的原理我们在<a href="https://time.geekbang.org/column/article/438639" target="_blank">第13节课</a>中已经讲过了，记不清的可以去回顾一下。</p>
<pre><code class="language-python">def train(train_loader, model, criterion, optimizer, epoch, args):
    # switch to train mode
    model.train()

    for i, (images, target) in enumerate(train_loader):
        # compute output
        output = model(images)
        loss = criterion(output, target)
        print('Epoch ', epoch, loss)

        # compute gradient and do SGD step
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
</code></pre>
<p>不过在我的程序里，保存了若干个Epoch的模型，我们应该怎么选择呢？这就要说到模型的评估环节。</p>
<h2 id="模型评估">模型评估</h2>
<p>对于分类模型的评估来说，有很多评价指标，例如准确率、精确率、召回率、F1-Score等。其中，<strong>我认为最直观、最有说服力的就是精确率与召回率</strong>，这也是我在项目中观察的主要是指标。下面我们依次来看看。</p>
<h3 id="混淆矩阵">混淆矩阵</h3>
<p>在讲解精确率与召回率之前，我们先看看混淆矩阵这个概念。其实精确率与召回率就是通过它计算出来的。下表就是一个混淆矩阵，正例就是logo类，负例就是others类。</p>
<p><img alt="图片" src="assets/fff9ea14f2124b04bd422222b2199f32.jpg"/></p>
<p>根据预测结果和真实类别的组合，一共有四种情况：</p>
<p>1.TP是说真实类别为Logo，模型也预测为Logo；-
2.FP是说真实类别为Others，但模型预测为Logo；-
3.FN是说真实类别为Logo，但模型预测为Others；-
4.TN是说真实类别为Others，模型也预测为Others；</p>
<p>精确率的计算方法为：</p>
<p><span class="math display">\[precision = \\frac{TP}{ (TP + FP)}\]</span></p><p>召回率的计算方式为：</p>
<p><span class="math display">\[recall = \\frac{TP}{(TP + FN)}\]</span></p><p>精确率与召回率分别衡量了模型的不同表现，精确率说的是，如果模型认为一张图片是Logo类，那有多大概率是Logo类。而召回率衡量的是，在整个验证集中，模型能找到多少Logo图片。</p>
<p>那问题来了，怎样根据这两个指标来选择模型呢？业务需求不同，我们侧重的指标就不一样。</p>
<p>比如在我们的这个项目中，如果老板允许一部分Logo图片没有被识别，但是模型必须非常准，模型说一张图片是Logo类，那图片真实类别就有非常大的概率是Logo类图片，那应该侧重的就是精确率；如果老板希望把线上Logo类尽可能地识别出来，允许一部分图片被误识别，那应该侧重的就是召回率。</p>
<p>在计算精确率与召回率的时候，给你分享一下我的经验。在实际项目中，我习惯把模型对每张图片的预测结果保存到一个txt中，这样可以比较直观地筛选一些模型的badcase，并且验证集如果非常大，又需要调整的时候，直接更改txt就可以了，不需要再次让模型预测整个验证集。</p>
<p>下面是txt文件的一部分，分别记录了logo类的概率、others类的概率、真实类别是否为logo、真实类别是否为others、预测类别是否为logo、预测类别是否为ohters、图片名。</p>
<p>14.jpeg是开篇例子的那张图片，模型认为它是Logo的概率是0.58476，others类的概率是0.41524。</p>
<pre><code class="language-python">...
0.64460 0.35540 1 0 1 0 ./data/val/logo/13.jpeg
0.58476 0.41524 1 0 1 0 ./data/val/logo/14.jpeg
...
</code></pre>
<p>下图是我训练了10个Epoch的B0模型，在验证集(这里我用训练集充当了一下验证集)上的评价效果。-
<img alt="图片" src="assets/33644bff89a844ceb45554f3f01cc8eb.jpg"/></p>
<p>通过混淆矩阵可以看到，整个验证集一共有8+0张图片被预测为logo类，所以logo类的精确率为8 / (8 + 0 ) = 1；logo类一共有8+2张图片，有两张预测错了，所以召回率为8 / (8 +2) = 0.8。</p>
<p>others类别的计算类似，你可以自己算算看。</p>
<h2 id="小结">小结</h2>
<p>恭喜你，完成了今天的学习任务。今天我们一起完成了一个图像分类项目的实践。虽然项目规模较小，但是在真实项目中的每一个环节都包含在内了，可以说是麻雀虽小，五脏俱全。</p>
<p>下面我们回顾一下每个环节上的关键要点和实操经验。</p>
<p><strong>数据准备其实是最关键的一步，数据的质量直接决定了模型好坏</strong>。所以，在开始训练之前你应该对你的数据集有十足的了解才可以。例如，验证集还是否可以反映出训练集、数据中有没有脏数据、数据分布有没有偏等等。</p>
<p>完成数据准备之后就到了模型训练，图像分类任务其实基本上都是采用主流的卷积神经网络了，很少对模型结构做一些更改。</p>
<p>最后的模型评估环节要侧重业务场景，看业务上需要高精确还是高召回，然后再对你的模型做调整。</p>
<h2 id="思考题">思考题</h2>
<p>老板希望你的模型能尽可能的把线上所有极客时间的海报都找到，允许一些误召回。训练模型的时候你应该侧重精确率还是召回率？</p>
<p>推荐你动手实现一下今天的Demo，也欢迎你把这节课分享给更多的同事、朋友，跟他一起学习进步。</p>
</div>
</div>
<div>
<div id="prePage" style="float: left">
</div>
<div id="nextPage" style="float: right">
</div>
</div>
</div>
</div>
</div>
<div class="copyright">
<hr/>
<p>© 2019 - 2023 <a href="/cdn-cgi/l/email-protection#f09c9c9cc9c4c1c1c0c7b0979d91999cde939f9d" target="_blank">Liangliang Lee</a>.
                    Powered by <a href="https://github.com/gin-gonic/gin" target="_blank">gin</a> and <a href="https://github.com/kaiiiz/hexo-theme-book" target="_blank">hexo-theme-book</a>.</p>
</div>
</div>
<a class="off-canvas-overlay" onclick="hide_canvas()"></a>
</div>
<script data-cfasync="false" src="/cdn-cgi/scripts/5c5dd728/cloudflare-static/email-decode.min.js"></script><script>(function(){function c(){var b=a.contentDocument||a.contentWindow.document;if(b){var d=b.createElement('script');d.innerHTML="window.__CF$cv$params={r:'93587213cae94406',t:'MTc0NTUyNzUzOS4wMDAwMDA='};var a=document.createElement('script');a.nonce='';a.src='/cdn-cgi/challenge-platform/scripts/jsd/main.js';document.getElementsByTagName('head')[0].appendChild(a);";b.getElementsByTagName('head')[0].appendChild(d)}}if(document.body){var a=document.createElement('iframe');a.height=1;a.width=1;a.style.position='absolute';a.style.top=0;a.style.left=0;a.style.border='none';a.style.visibility='hidden';document.body.appendChild(a);if('loading'!==document.readyState)c();else if(window.addEventListener)document.addEventListener('DOMContentLoaded',c);else{var e=document.onreadystatechange||function(){};document.onreadystatechange=function(b){e(b);'loading'!==document.readyState&&(document.onreadystatechange=e,c())}}}})();</script></body>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-NPSEEVD756"></script>
<script src="/static/index.js"></script>
</head></html>