<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<head>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<meta content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=no" name="viewport"/>
<meta content="zh-cn" http-equiv="content-language"/>
<meta content="21  神经网络与深度学习：计算机是如何理解图像、文本和语音的？" name="description"/>
<link href="/static/favicon.png" rel="icon"/>
<title>21  神经网络与深度学习：计算机是如何理解图像、文本和语音的？ </title>
<link href="/static/index.css" rel="stylesheet"/>
<link href="/static/highlight.min.css" rel="stylesheet"/>
<script src="/static/highlight.min.js"></script>
<meta content="Hexo 4.2.0" name="generator"/>
<script data-website-id="83e5d5db-9d06-40e3-b780-cbae722fdf8c" defer="" src="https://umami.lianglianglee.com/script.js"></script>
</head>
<body>
<div class="book-container">
<div class="book-sidebar">
<div class="book-brand">
<a href="/">
<img src="/static/favicon.png"/>
<span>技术文章摘抄</span>
</a>
</div>
<div class="book-menu uncollapsible">
<ul class="uncollapsible">
<li><a class="current-tab" href="/">首页</a></li>
<li><a href="../">上一级</a></li>
</ul>
<ul class="uncollapsible">
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e8%af%be/00%20%e5%bc%80%e7%af%87%e8%af%8d%20%20%e6%95%b0%e5%ad%a6%ef%bc%8c%e7%bc%96%e7%a8%8b%e8%83%bd%e5%8a%9b%e7%9a%84%e8%90%a5%e5%85%bb%e6%a0%b9%e5%9f%ba.md.html" id="00 开篇词  数学，编程能力的营养根基.md.html">00 开篇词  数学，编程能力的营养根基.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e8%af%be/01%20%20%e4%bb%8e%e8%ae%a1%e6%95%b0%e5%bc%80%e5%a7%8b%ef%bc%8c%e7%a8%8b%e5%ba%8f%e5%91%98%e5%bf%85%e7%9f%a5%e5%bf%85%e4%bc%9a%e7%9a%84%e6%95%b0%e5%88%b6%e8%bd%ac%e6%8d%a2%e6%b3%95.md.html" id="01  从计数开始，程序员必知必会的数制转换法.md.html">01  从计数开始，程序员必知必会的数制转换法.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e8%af%be/02%20%20%e9%80%bb%e8%be%91%e4%b8%8e%e6%b2%9f%e9%80%9a%ef%bc%8c%e6%80%8e%e6%a0%b7%e6%89%8d%e8%83%bd%e8%ae%b2%e5%87%ba%e6%9c%89%e9%80%bb%e8%be%91%e7%9a%84%e8%af%9d%ef%bc%9f.md.html" id="02  逻辑与沟通，怎样才能讲出有逻辑的话？.md.html">02  逻辑与沟通，怎样才能讲出有逻辑的话？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e8%af%be/03%20%20%e7%94%a8%e6%95%b0%e5%ad%a6%e5%86%b3%e7%ad%96%ef%bc%8c%e5%a6%82%e4%bd%95%e8%a7%84%e5%88%92%e5%a5%bd%e6%8a%95%e5%85%a5%e3%80%81%e8%bd%ac%e5%8c%96%e5%92%8c%e4%ba%a7%e5%87%ba%ef%bc%9f.md.html" id="03  用数学决策，如何规划好投入、转化和产出？.md.html">03  用数学决策，如何规划好投入、转化和产出？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e8%af%be/04%20%20%e4%b8%87%e7%89%a9%e5%8f%af%e6%95%b0%e5%ad%a6%ef%bc%8c%e7%bb%8f%e5%85%b8%e5%85%ac%e5%bc%8f%e6%98%af%e5%a6%82%e4%bd%95%e5%9c%a8%e7%94%9f%e6%b4%bb%e4%b8%ad%e5%ba%94%e7%94%a8%e7%9a%84%ef%bc%9f.md.html" id="04  万物可数学，经典公式是如何在生活中应用的？.md.html">04  万物可数学，经典公式是如何在生活中应用的？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e8%af%be/05%20%20%e6%b1%82%e6%9e%81%e5%80%bc%ef%bc%9a%e5%a6%82%e4%bd%95%e6%89%be%e5%88%b0%e5%a4%8d%e6%9d%82%e4%b8%9a%e5%8a%a1%e7%9a%84%e6%9c%80%e4%bc%98%e8%a7%a3%ef%bc%9f.md.html" id="05  求极值：如何找到复杂业务的最优解？.md.html">05  求极值：如何找到复杂业务的最优解？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e8%af%be/06%20%20%e5%90%91%e9%87%8f%e5%8f%8a%e5%85%b6%e5%af%bc%e6%95%b0%ef%bc%9a%e8%ae%a1%e7%ae%97%e6%9c%ba%e5%a6%82%e4%bd%95%e5%ae%8c%e6%88%90%e5%af%b9%e6%b5%b7%e9%87%8f%e9%ab%98%e7%bb%b4%e5%ba%a6%e6%95%b0%e6%8d%ae%e8%ae%a1%e7%ae%97%ef%bc%9f.md.html" id="06  向量及其导数：计算机如何完成对海量高维度数据计算？.md.html">06  向量及其导数：计算机如何完成对海量高维度数据计算？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e8%af%be/07%20%20%e7%ba%bf%e6%80%a7%e5%9b%9e%e5%bd%92%ef%bc%9a%e5%a6%82%e4%bd%95%e5%9c%a8%e7%a6%bb%e6%95%a3%e7%82%b9%e4%b8%ad%e5%af%bb%e6%89%be%e6%95%b0%e6%8d%ae%e8%a7%84%e5%be%8b%ef%bc%9f.md.html" id="07  线性回归：如何在离散点中寻找数据规律？.md.html">07  线性回归：如何在离散点中寻找数据规律？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e8%af%be/08%20%20%e5%8a%a0%e4%b9%98%e6%b3%95%e5%88%99%ef%bc%9a%e5%a6%82%e4%bd%95%e8%ae%a1%e7%ae%97%e5%a4%8d%e6%9d%82%e4%ba%8b%e4%bb%b6%e5%8f%91%e7%94%9f%e7%9a%84%e6%a6%82%e7%8e%87%ef%bc%9f.md.html" id="08  加乘法则：如何计算复杂事件发生的概率？.md.html">08  加乘法则：如何计算复杂事件发生的概率？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e8%af%be/09%20%20%e4%bc%bc%e7%84%b6%e4%bc%b0%e8%ae%a1%ef%bc%9a%e5%a6%82%e4%bd%95%e5%88%a9%e7%94%a8%20MLE%20%e5%af%b9%e5%8f%82%e6%95%b0%e8%bf%9b%e8%a1%8c%e4%bc%b0%e8%ae%a1%ef%bc%9f.md.html" id="09  似然估计：如何利用 MLE 对参数进行估计？.md.html">09  似然估计：如何利用 MLE 对参数进行估计？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e8%af%be/10%20%20%e4%bf%a1%e6%81%af%e7%86%b5%ef%bc%9a%e4%ba%8b%e4%bb%b6%e7%9a%84%e4%b8%8d%e7%a1%ae%e5%ae%9a%e6%80%a7%e5%a6%82%e4%bd%95%e8%ae%a1%e7%ae%97%ef%bc%9f.md.html" id="10  信息熵：事件的不确定性如何计算？.md.html">10  信息熵：事件的不确定性如何计算？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e8%af%be/11%20%20%e7%81%b0%e5%ba%a6%e5%ae%9e%e9%aa%8c%ef%bc%9a%e5%a6%82%e4%bd%95%e8%ae%be%e8%ae%a1%e7%81%b0%e5%ba%a6%e5%ae%9e%e9%aa%8c%e5%b9%b6%e8%ae%a1%e7%ae%97%e5%ae%9e%e9%aa%8c%e7%9a%84%e6%94%b6%e7%9b%8a%ef%bc%9f.md.html" id="11  灰度实验：如何设计灰度实验并计算实验的收益？.md.html">11  灰度实验：如何设计灰度实验并计算实验的收益？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e8%af%be/12%20%20%e7%bb%9f%e8%ae%a1%e5%ad%a6%e6%96%b9%e6%b3%95%ef%bc%9a%e5%a6%82%e4%bd%95%e8%af%81%e6%98%8e%e7%81%b0%e5%ba%a6%e5%ae%9e%e9%aa%8c%e6%95%88%e6%9e%9c%e4%b8%8d%e6%98%af%e5%81%b6%e7%84%b6%e5%be%97%e5%88%b0%e7%9a%84%ef%bc%9f.md.html" id="12  统计学方法：如何证明灰度实验效果不是偶然得到的？.md.html">12  统计学方法：如何证明灰度实验效果不是偶然得到的？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e8%af%be/13%20%20%e5%a4%8d%e6%9d%82%e5%ba%a6%ef%bc%9a%e5%a6%82%e4%bd%95%e5%88%a9%e7%94%a8%e6%95%b0%e5%ad%a6%e6%8e%a8%e5%af%bc%e5%af%b9%e7%a8%8b%e5%ba%8f%e8%bf%9b%e8%a1%8c%e4%bc%98%e5%8c%96%ef%bc%9f.md.html" id="13  复杂度：如何利用数学推导对程序进行优化？.md.html">13  复杂度：如何利用数学推导对程序进行优化？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e8%af%be/14%20%20%e7%a8%8b%e5%ba%8f%e7%9a%84%e5%be%aa%e7%8e%af%ef%bc%9a%e5%a6%82%e4%bd%95%e5%88%a9%e7%94%a8%e6%95%b0%e5%ad%a6%e5%bd%92%e7%ba%b3%e6%b3%95%e8%bf%9b%e8%a1%8c%e7%a8%8b%e5%ba%8f%e5%bc%80%e5%8f%91%ef%bc%9f.md.html" id="14  程序的循环：如何利用数学归纳法进行程序开发？.md.html">14  程序的循环：如何利用数学归纳法进行程序开发？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e8%af%be/15%20%20%e9%80%92%e5%bd%92%ef%bc%9a%e5%a6%82%e4%bd%95%e8%ae%a1%e7%ae%97%e6%b1%89%e8%af%ba%e5%a1%94%e9%97%ae%e9%a2%98%e7%9a%84%e7%a7%bb%e5%8a%a8%e6%ad%a5%e6%95%b0%ef%bc%9f.md.html" id="15  递归：如何计算汉诺塔问题的移动步数？.md.html">15  递归：如何计算汉诺塔问题的移动步数？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e8%af%be/16%20%20%e4%ba%8c%e5%88%86%e6%b3%95%ef%bc%9a%e5%a6%82%e4%bd%95%e5%88%a9%e7%94%a8%e6%8c%87%e6%95%b0%e7%88%86%e7%82%b8%e4%bc%98%e5%8c%96%e7%a8%8b%e5%ba%8f%ef%bc%9f.md.html" id="16  二分法：如何利用指数爆炸优化程序？.md.html">16  二分法：如何利用指数爆炸优化程序？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e8%af%be/17%20%20%e5%8a%a8%e6%80%81%e8%a7%84%e5%88%92%ef%bc%9a%e5%a6%82%e4%bd%95%e5%88%a9%e7%94%a8%e6%9c%80%e4%bc%98%e5%ad%90%e7%bb%93%e6%9e%84%e8%a7%a3%e5%86%b3%e9%97%ae%e9%a2%98%ef%bc%9f.md.html" id="17  动态规划：如何利用最优子结构解决问题？.md.html">17  动态规划：如何利用最优子结构解决问题？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e8%af%be/18%20%20AI%20%e5%85%a5%e9%97%a8%ef%bc%9a%e5%88%a9%e7%94%a8%203%20%e4%b8%aa%e5%85%ac%e5%bc%8f%e6%90%ad%e5%bb%ba%e6%9c%80%e7%ae%80%20AI%20%e6%a1%86%e6%9e%b6.md.html" id="18  AI 入门：利用 3 个公式搭建最简 AI 框架.md.html">18  AI 入门：利用 3 个公式搭建最简 AI 框架.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e8%af%be/19%20%20%e9%80%bb%e8%be%91%e5%9b%9e%e5%bd%92%ef%bc%9a%e5%a6%82%e4%bd%95%e8%ae%a9%e8%ae%a1%e7%ae%97%e6%9c%ba%e5%81%9a%e5%87%ba%e4%ba%8c%e5%80%bc%e5%8c%96%e5%86%b3%e7%ad%96%ef%bc%9f.md.html" id="19  逻辑回归：如何让计算机做出二值化决策？.md.html">19  逻辑回归：如何让计算机做出二值化决策？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e8%af%be/20%20%20%e5%86%b3%e7%ad%96%e6%a0%91%ef%bc%9a%e5%a6%82%e4%bd%95%e5%af%b9%20NP%20%e9%9a%be%e5%a4%8d%e6%9d%82%e9%97%ae%e9%a2%98%e8%bf%9b%e8%a1%8c%e5%90%af%e5%8f%91%e5%bc%8f%e6%b1%82%e8%a7%a3%ef%bc%9f.md.html" id="20  决策树：如何对 NP 难复杂问题进行启发式求解？.md.html">20  决策树：如何对 NP 难复杂问题进行启发式求解？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e8%af%be/21%20%20%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%e4%b8%8e%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%ef%bc%9a%e8%ae%a1%e7%ae%97%e6%9c%ba%e6%98%af%e5%a6%82%e4%bd%95%e7%90%86%e8%a7%a3%e5%9b%be%e5%83%8f%e3%80%81%e6%96%87%e6%9c%ac%e5%92%8c%e8%af%ad%e9%9f%b3%e7%9a%84%ef%bc%9f.md.html" id="21  神经网络与深度学习：计算机是如何理解图像、文本和语音的？.md.html">21  神经网络与深度学习：计算机是如何理解图像、文本和语音的？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e8%af%be/22%20%20%e9%9d%a2%e8%af%95%e4%b8%ad%e9%82%a3%e4%ba%9b%e5%9d%91%e4%ba%86%e6%97%a0%e6%95%b0%e4%ba%ba%e7%9a%84%e7%ae%97%e6%b3%95%e9%a2%98.md.html" id="22  面试中那些坑了无数人的算法题.md.html">22  面试中那些坑了无数人的算法题.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e8%af%be/23%20%20%e7%ab%99%e5%9c%a8%e7%94%9f%e6%b4%bb%e7%9a%84%e5%8d%81%e5%ad%97%e8%b7%af%e5%8f%a3%ef%bc%8c%e5%a6%82%e4%bd%95%e7%94%a8%e6%95%b0%e5%ad%a6%e6%8a%89%e6%8b%a9%ef%bc%9f.md.html" id="23  站在生活的十字路口，如何用数学抉择？.md.html">23  站在生活的十字路口，如何用数学抉择？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e6%95%b0%e5%ad%a6%e8%af%be/24%20%e7%bb%93%e6%9d%9f%e8%af%ad%20%20%e6%95%b0%e5%ad%a6%e5%ba%95%e5%ad%90%e5%a5%bd%ef%bc%8c%e5%ad%a6%e5%95%a5%e9%83%bd%e5%bf%ab.md.html" id="24 结束语  数学底子好，学啥都快.md.html">24 结束语  数学底子好，学啥都快.md.html</a>
</li>
<li><a href="/assets/捐赠.md.html">捐赠</a></li>
</ul>
</div>
</div>
<div class="sidebar-toggle" onclick="sidebar_toggle()" onmouseleave="remove_inner()" onmouseover="add_inner()">
<div class="sidebar-toggle-inner"></div>
</div>
<div class="off-canvas-content">
<div class="columns">
<div class="column col-12 col-lg-12">
<div class="book-navbar">
<header class="navbar">
<section class="navbar-section">
<a onclick="open_sidebar()">
<i class="icon icon-menu"></i>
</a>
</section>
</header>
</div>
<div class="book-content" style="max-width: 960px; margin: 0 auto;
    overflow-x: auto;
    overflow-y: hidden;">
<div class="book-post">
<div align="center">因收到Google相关通知，网站将会择期关闭。<a href="https://lumendatabase.org/notices/44265620" target="_blank">相关通知内容</a><hr/></div>
<p align="center" id="tip"></p>
<h1 class="title" data-id="21  神经网络与深度学习：计算机是如何理解图像、文本和语音的？" id="title">21  神经网络与深度学习：计算机是如何理解图像、文本和语音的？</h1>
<div><p>在上一讲的最后，我们提到过“浅层模型”和“深层模型”。其实，人工智能的早期并没有“浅层模型”的概念，浅层模型是深度学习出现之后，与之对应而形成的概念。在浅层模型向深层模型转变的过程中，<strong>神经网络算法无疑是个催化剂</strong>，并在此基础上诞生了深度学习。</p>
<p>这一讲，我们就来学习一下神经网络和深度学习。</p>
<h3 id="神经网络的基本结构及其表达式">神经网络的基本结构及其表达式</h3>
<p>回想一下上一讲我们学的决策树，理论上来看，只要一直递归，一层又一层地寻找分裂变量，决策树做出预测的准确率是可以达到 100% 的。可见，这种层次化建立模型的思想，是不断提高模型效果的重要手段。</p>
<p>然而，对于决策树而言，AI 框架的第一个公式 y = f(<strong><em>w;x</em></strong>)，只能被“画出”却很难用被写出。而这背后的原因，其实是决策树是一种类似于“if-else-”的条件分支结构，这本身就不是一种基于函数的数学表达形式。</p>
<p>那么我们不禁会想，有没有哪个模型既能保留层次化建模提高效果的优势，又能拥有基于函数的数学表达形式呢？</p>
<p>答案，就是神经网络。</p>
<p>神经网络是一种具有层次化结构的模型，它的设计来自生物学中对于人类大脑的研究。我们知道，神经元是人脑的基本结构，众多神经元组织在一起，就构成了人的大脑。</p>
<h4 id="1-神经元-神经网络的基本单位">1.神经元，神经网络的基本单位</h4>
<p>神经网络的结构与人类大脑结构非常相似，它的基本单位是函数化的神经元，再通过层次化地把这些神经元组织在一起，就构成了神经网络的表达式。</p>
<p>如下图，就是神经网络的神经元。</p>
<p><img alt="图片1.png" src="assets/Ciqc1F_wgVSAJnWRAACyABgNtZA007.png"/></p>
<p>我们假设输入变量有两个。</p>
<blockquote>
<p>实际中如果输入变量较多，只需要增加输入变量 xi 和权重系数 wi 的链接就可以了。</p>
</blockquote>
<p>图中，x1 和 x2 是两个输入变量，它们分别与两个系数变量 w1 和 w2 相乘之后，指向了“+”号的模块。</p>
<p>得到了加权求和的结果之后，需要输入到一个 Sigmoid 函数中，最右的 y 就是这个神经元的输出，即</p>
<p><img alt="图片2.png" src="assets/Cip5yF_wgaqAMJCPAAAl_m9Hvxs824.png"/></p>
<p>有了神经元的表达式之后，我们把图中虚线框的神经元用一个圆形的结点来进行封装，再把输出 y 写入这个结点中，这样就有了下面的表示形式。</p>
<p><img alt="图片3.png" src="assets/Cip5yF_wgWSAFcJnAACIbvQJjQc885.png"/></p>
<h4 id="2-层次化将-神经元-构成神经网络">2.层次化将“神经元”构成神经网络</h4>
<p>我们说过，层次化地把多个神经元组织在一起，才构成了神经网络。在这里，<strong>层次化</strong>的含义是，每一层有若干个神经元结点，层与层之间通过带权重的边互相连接。如下图，就是一个简单的神经网络。</p>
<p><img alt="图片4.png" src="assets/CgpVE1_wgbSARHK6AAElMQEDF1Q333.png"/></p>
<p>在这个神经网络中，输入变量有 3 个，分别是 x1、x2 和 x3。结点与结点之间，由带箭头的边连接，每条边都是一个权重系数 wijk。作用是将前面一个结点的输出，乘以权重系数后，输入给后面一个结点中。</p>
<blockquote>
<p>这里 wijk 的含义，是第 i 层的第 j 个结点到第 i+1 层的第 k 个结点的权重。</p>
</blockquote>
<p>网络中，除了最后一个结点以外，其余结点的输出都是临时结果；且每个临时结果，都将成为下一层神经元结点的输入。而最后一个结点的输出，也就是最终模型的输出 y。</p>
<p>对于神经网络而言，它既可以用图画的方式“画出”模型的结构，也可以通过函数化的形式写出输入和输出的关系，上图中的表达式如下。</p>
<p>y = y3 = sigmoid(y1w211+y2w221)</p>
<p>y1 = sigmoid(x1w111+x2w121+x3w131)</p>
<p>y2 = sigmoid(x1w112+x2w122+x3w132)</p>
<p>我们将 y1 和 y2 代入 y3，则有</p>
<p>y = sigmoid[sigmoid(x1w111+x2w121+x3w131) ·w211 + sigmoid(x1w112+x2w122+x3w132)·w221]</p>
<p>虽然，神经网络模型可以用函数来写出输入输出关系的表达式，但由于网络结构本身的复杂性导致这个表达式并不好看。而且随着网络层数变多、每一层结点数变多，这个表达式会变得越来越复杂。</p>
<p>在实际应用中，根据需要神经网络可以有任意多个层次，每层里可以有任意多个神经元，这通常是由开发者自己根据问题的复杂程度而预先设置的。</p>
<h3 id="神经网络的损失函数">神经网络的损失函数</h3>
<p>有了神经网络的表达式之后，我们就继续用 AI 框架的第二个公式，去写出它的损失函数。神经网络的损失函数并没有什么特殊性，在绝大多数场景下，都会选择最小二乘的平方误差作为损失函数。</p>
<blockquote>
<p>这一点，与线性回归是一致的。</p>
</blockquote>
<p>最小二乘损失函数计算方式，是所有样本真实值 ŷ 与预测值 y 之间差值的平方和，则有：</p>
<p><img alt="图片6.png" src="assets/Ciqc1F_wgeqAI7WGAAAdxe9diJE517.png"/></p>
<p>其中 n 代表的是所有的样本数。在这个损失函数中还有一个 <sup>1</sup>⁄<sub>2</sub> 的系数，增加一个系数会影响损失函数 L(<strong><em>w</em></strong>) 的值，但并不会影响最优系数的取值。</p>
<blockquote>
<p>例如，y = 2x2+4和 y=x2+2 取得极值都是在 x=0 的点，之所以增加这个系数，是为了抵消后面平方项求导而产生的 2 倍的系数。</p>
</blockquote>
<h3 id="随机梯度下降法求解神经网络参数">随机梯度下降法求解神经网络参数</h3>
<p>最后，我们利用 AI 框架的第三个公式<strong><em>w</em></strong>*= argmin L(<strong><em>w</em></strong>)，来求解神经网络。在神经网络中，<strong><em>w</em></strong>系数就是所有的 wijk。</p>
<p>我们把到现在为止的所有已知条件进行整理</p>
<p><img alt="71.png" src="assets/Cip5yF_wgq2AKSy7AABA7VeZyF8001.png"/></p>
<p>y = sigmoid[sigmoid(x1w111+x2w121+x3w131)·w211+sigmoid(x1w112+x2w122+x3w132)·</p>
<p>w221]</p>
<p>其中，对于某个给定的数据集而言，xi 和 ŷi 都是已知的。也就是说，我们要求解出让上面损失函数 L(<strong><em>w</em></strong>) 取得极小值的 wijk 的值，我们可以考虑用先前学的随机梯度下降法来进行求解。</p>
<p>在使用随机梯度下降法的时候，只会随机选择一个样本（假设标记为 m）进行梯度下降的优化。因此，损失函数的大型求和符号就可以消灭掉了，即</p>
<p><img alt="81.png" src="assets/Cip5yF_wgreAHb13AAAotbO_Dwc622.png"/></p>
<p>ym=sigmoid[sigmoid(xm1w111+xm2w121+xm3w131)·w211+sigmoid(xm1w112+xm2w122+xm3w132)·w221]</p>
<p>在这个例子中，我们有 8 个 wijk 变量，分别是 w111、w121、w131、w211、w112、w122、w132、w221，因此需要求分别计算损失函数关于这 8 个变量的导数。</p>
<p>既然表达式都有了，我们就利用大学数学求导的<strong>链式法则</strong>，耐着性子来求解一下吧。</p>
<blockquote>
<p>别忘了，y=sigmoid(x) 的一阶导数是 y·(1-y)。</p>
</blockquote>
<p><img alt="图片9.png" src="assets/Cip5yF_wgh-AHZJJAABVXWdACA8110.png"/></p>
<p>有了梯度之后，就可以设置学习率，再利用随机梯度下降法求解最优参数了。</p>
<h3 id="神经网络建模案例"><strong>神经网络建模案例</strong></h3>
<p>利用下面的数据集，建立一个神经网络。这个数据集中，每一行是一个样本，每一列一个变量，最后一列是真实值标签。</p>
<p><img alt="图片10.png" src="assets/Ciqc1F_wgiqAI97lAABd8lOjn78149.png"/></p>
<p>在利用神经网络建模时，需要预先设计网络结构。也就是说，你计划采用几层的网络，每一层准备设置多少个神经元结点。</p>
<p>我们看到，每个样本包含了 3 个输入变量。那么，我们可以直接采用上面推倒过的网络结构，即神经网络的结构如下所示。</p>
<p><img alt="图片11.png" src="assets/CgqCHl_wgjKAFyLOAADrEi6vHSo470.png"/></p>
<p>同时，我们也已经推导出了损失函数关于每个链接权重边的梯度，即</p>
<p><img alt="图片12.png" src="assets/Ciqc1F_wgjuASOELAABXlbT4eT8833.png"/></p>
<p>由于神经网络的代码量比较多，而且有非常多的开源工具可以使用。因此，我们这里给出伪代码，来展示其核心思想。</p>
<pre><code>#获取数据集x和y

x,y = getData()

#随机初始化参数w

w = init()

#设置学习率

a = 1.0

#随机梯度下降法

for _ in range(1000):

	index = random.randint()

	y1,y2,y3 = getResult(x,w)

	g = getGrad(x,y,w)

	w = w - a*g
</code></pre>
<p>我们对代码进行解读：</p>
<ul>
<li>第 2 行，读取数据集，并保存在变量 x 和 y 中，可以考虑用 Numpy 的 array 进行保存；</li>
<li>第 5 行，随机初始化参数向量 w，因为神经网络是多层、多结点的结构，所以可以考虑用个三维数组进行保存；</li>
<li>第 8 行，设置学习率，与以前的结论一样，如果迭代轮数够多，学习率可以考虑设置小一些；</li>
<li>第 11 行开始，进行随机梯度下降法的迭代。</li>
<li>第 12 行，调用随机函数，随机获取一个数据样本。</li>
<li>第 13 行，根据网络结构，计算 y1、y2、y3 每个结点的输出，其中还需要多次调用 Sigmoid 函数，可以考虑把 Sigmoid 的计算单独函数化；</li>
<li>第 14 行，根据梯度公式计算梯度值，并保存在 g 变量中，g 和 w 应该设置一样的数据类型；</li>
<li>第 15 行，利用梯度下降法进行参数更新。</li>
</ul>
<p>在实际工作中，如果你需要建立神经网络的模型，除了上面自己开发代码的方式外，还可以考虑使用 Tensorflow 或者 Keras 等开源的人工神经网络库。</p>
<blockquote>
<p>因为这只是实现的工具，原理上并没有什么差异，故而我们不再深入展开讨论。</p>
</blockquote>
<h3 id="神经网络和深度学习"><strong>神经网络和深度学习</strong></h3>
<p>深度学习通常指训练大型深度的神经网络的过程。</p>
<ul>
<li>与传统的神经网络模型相比，深度学习模型在结构上与之非常相似；</li>
<li>不同的是，深度学习模型的“深度”更大，“深度”的体现就是神经网络层数多，神经网络每一层的结点数多。</li>
</ul>
<p>下面，我们简单介绍两种深度神经网络——卷积神经网络和循环神经网络，以及它们分别在图像处理、文本处理和语音处理上的效果。</p>
<h4 id="1-卷积神经网络-cnn">1.卷积神经网络（CNN）</h4>
<p>与普通神经网络相比，卷积神经网络引入了“卷积”和“池化”两个操作，下面通过详细的例子，讲解卷积神经网络在图像处理的主要思路。</p>
<p>彩色图像由红、绿、蓝三原色组成，每种原色按照深浅可以表示为 0 到 255 间的一个数字。因此，对于图像中的每个像素（图像中不可分割的最小单位），都可以写出其相应的红、绿、蓝数值。</p>
<p>所以在计算机中，一幅彩色图像可由红、绿、蓝三个颜色的像素矩阵表示出来，下图给出了一幅 128×128 像素图像的矩阵表示：</p>
<p><img alt="图片13.png" src="assets/CgqCHl_wgk2AM9wAAAonpFyfDOo523.png"/></p>
<ul>
<li><strong>“卷积”操作的思想</strong>
采用一个较小的卷积核，例如 3×3 的矩阵，来对图像特征进行局部的提取。这样做可以增加参数的共享，减少随着神经网络变深、结点数变多而带来的巨大计算量。</li>
<li><strong>“池化”操作的思想</strong>
采用一种过滤的方法，去除冗余信息并且加快计算。池化可以将一个 4×4 的图像切割成 4 个 2×2 的小矩阵，在每个小矩阵中取最大值，所得结果形成一个新矩阵。这种操作，可以减少神经网络结点的个数，加快计算速度。</li>
</ul>
<p>在卷积神经网络中，通常某一个层都是在做卷积处理，某一层都是在做池化处理。一般，它们都是在层次之间交替进行的。经过多层卷积、池化操作后，所得特征图的分辨率远小于输入图像的分辨率，减少了计算量，加快了计算速度。</p>
<p>通过卷积和池化两项操作，卷积神经网络能在准确提取图像特征的同时，提升运算效率，因此在图像处理中取得了良好效果。</p>
<h4 id="2-循环神经网络-rnn">2.循环神经网络（RNN）</h4>
<p>循环神经网络是一种善于处理序列信息的神经网络，在语音、文本处理方面有着非常大的优势。因为人类的自然语言属于一种时序信息，它有着明显的顺序关系，这就让以循环神经网络结构为基础的深度神经网络有其发挥空间。</p>
<p>除此之外，循环神经网络在引入 LSTM（Long Short-TermMemory）结构后，在对有用时序信息的“记忆”和没用时序信息的“忘记”上有着强大的处理能力。</p>
<p>下图给出了一个 LSTM 的神经元结构。</p>
<p><img alt="图片14.png" src="assets/Ciqc1F_wglaAH-ZjAAD1d_BWqcY925.png"/></p>
<p>可以发现，LSTM 的网络结构和神经元结构已经非常复杂了，但它仍然保持着神经网络的那些特性。尤其是结构可被“画出”，输入、输出之间可以用函数表达。有了这些基本条件后，就仍然可以用损失函数和随机梯度下降法，来求解网络结构的参数。</p>
<h3 id="小结">小结</h3>
<p>这一讲，我们学习了神经网络和深度学习。在当前的 AI 时代下，深度学习模型在效果方面打败了传统的浅层模型。而深度学习的基本原理都主要来自神经网络，神经网络结构可被“画出”，输入、输出之间可以用函数表达，这些特点都是支持它深度化的前提。</p>
<p>神经网络之所以能取得很好的效果，主要是因为网络结构的多样性。计算机在面对语音、图像、文本的不同问题时，主要是通过对网络结构进行优化迭代，设计出 CNN、RNN 的新型神经网络结构的。</p>
<p>此外，神经网络的损失函数和参数求解，仍然和其他浅层模型相似，并没有什么特别。</p>
<p>最后，我们给大家留一个练习题。假设有一个 4 层的神经网络，第一层是输入 xi，最后一层是输出 y。4 层的结点数分别是 3、2、2、1。试着去求解一下损失函数关于每个链接权重的梯度吧。</p>
</div>
</div>
<div>
<div id="prePage" style="float: left">
</div>
<div id="nextPage" style="float: right">
</div>
</div>
</div>
</div>
</div>
<div class="copyright">
<hr/>
<p>© 2019 - 2023 <a href="/cdn-cgi/l/email-protection#cda1a1a1f4f9fcfcfdfa8daaa0aca4a1e3aea2a0" target="_blank">Liangliang Lee</a>.
                    Powered by <a href="https://github.com/gin-gonic/gin" target="_blank">gin</a> and <a href="https://github.com/kaiiiz/hexo-theme-book" target="_blank">hexo-theme-book</a>.</p>
</div>
</div>
<a class="off-canvas-overlay" onclick="hide_canvas()"></a>
</div>
<script data-cfasync="false" src="/cdn-cgi/scripts/5c5dd728/cloudflare-static/email-decode.min.js"></script><script>(function(){function c(){var b=a.contentDocument||a.contentWindow.document;if(b){var d=b.createElement('script');d.innerHTML="window.__CF$cv$params={r:'93593c25cb70379e',t:'MTc0NTUzNTgxNi4wMDAwMDA='};var a=document.createElement('script');a.nonce='';a.src='/cdn-cgi/challenge-platform/scripts/jsd/main.js';document.getElementsByTagName('head')[0].appendChild(a);";b.getElementsByTagName('head')[0].appendChild(d)}}if(document.body){var a=document.createElement('iframe');a.height=1;a.width=1;a.style.position='absolute';a.style.top=0;a.style.left=0;a.style.border='none';a.style.visibility='hidden';document.body.appendChild(a);if('loading'!==document.readyState)c();else if(window.addEventListener)document.addEventListener('DOMContentLoaded',c);else{var e=document.onreadystatechange||function(){};document.onreadystatechange=function(b){e(b);'loading'!==document.readyState&&(document.onreadystatechange=e,c())}}}})();</script></body>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-NPSEEVD756"></script>
<script src="/static/index.js"></script>
</head></html>