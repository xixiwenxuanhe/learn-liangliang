<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<head>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<meta content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=no" name="viewport"/>
<meta content="zh-cn" http-equiv="content-language"/>
<meta content="加餐 推荐系统的参考阅读" name="description"/>
<link href="/static/favicon.png" rel="icon"/>
<title>加餐 推荐系统的参考阅读 </title>
<link href="/static/index.css" rel="stylesheet"/>
<link href="/static/highlight.min.css" rel="stylesheet"/>
<script src="/static/highlight.min.js"></script>
<meta content="Hexo 4.2.0" name="generator"/>
<script data-website-id="83e5d5db-9d06-40e3-b780-cbae722fdf8c" defer="" src="https://umami.lianglianglee.com/script.js"></script>
</head>
<body>
<div class="book-container">
<div class="book-sidebar">
<div class="book-brand">
<a href="/">
<img src="/static/favicon.png"/>
<span>技术文章摘抄</span>
</a>
</div>
<div class="book-menu uncollapsible">
<ul class="uncollapsible">
<li><a class="current-tab" href="/">首页</a></li>
<li><a href="../">上一级</a></li>
</ul>
<ul class="uncollapsible">
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e4%b8%89%e5%8d%81%e5%85%ad%e5%bc%8f/00%20%e5%bc%80%e7%af%87%e8%af%8d%20%e7%94%a8%e7%9f%a5%e8%af%86%e5%8e%bb%e5%af%b9%e6%8a%97%e6%8a%80%e6%9c%af%e4%b8%8d%e5%b9%b3%e7%ad%89.md.html" id="00 开篇词 用知识去对抗技术不平等.md.html">00 开篇词 用知识去对抗技术不平等.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e4%b8%89%e5%8d%81%e5%85%ad%e5%bc%8f/01%20%e4%bd%a0%e7%9c%9f%e7%9a%84%e9%9c%80%e8%a6%81%e4%b8%aa%e6%80%a7%e5%8c%96%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e5%90%97_.md.html" id="01 你真的需要个性化推荐系统吗_.md.html">01 你真的需要个性化推荐系统吗_.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e4%b8%89%e5%8d%81%e5%85%ad%e5%bc%8f/02%20%e4%b8%aa%e6%80%a7%e5%8c%96%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e6%9c%89%e5%93%aa%e4%ba%9b%e7%bb%95%e4%b8%8d%e5%bc%80%e7%9a%84%e7%bb%8f%e5%85%b8%e9%97%ae%e9%a2%98%ef%bc%9f.md.html" id="02 个性化推荐系统有哪些绕不开的经典问题？.md.html">02 个性化推荐系统有哪些绕不开的经典问题？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e4%b8%89%e5%8d%81%e5%85%ad%e5%bc%8f/03%20%e8%bf%99%e4%ba%9b%e4%bd%a0%e5%bf%85%e9%a1%bb%e5%ba%94%e8%af%a5%e5%85%b7%e5%a4%87%e7%9a%84%e6%80%9d%e7%bb%b4%e6%a8%a1%e5%bc%8f.md.html" id="03 这些你必须应该具备的思维模式.md.html">03 这些你必须应该具备的思维模式.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e4%b8%89%e5%8d%81%e5%85%ad%e5%bc%8f/04%20%e7%94%bb%e9%ac%bc%e5%ae%b9%e6%98%93%e7%94%bb%e4%ba%ba%e9%9a%be%ef%bc%9a%e7%94%a8%e6%88%b7%e7%94%bb%e5%83%8f%e7%9a%84%e2%80%9c%e8%83%bd%e2%80%9d%e5%92%8c%e2%80%9c%e4%b8%8d%e8%83%bd%e2%80%9d.md.html" id="04 画鬼容易画人难：用户画像的“能”和“不能”.md.html">04 画鬼容易画人难：用户画像的“能”和“不能”.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e4%b8%89%e5%8d%81%e5%85%ad%e5%bc%8f/05%20%e4%bb%8e%e6%96%87%e6%9c%ac%e5%88%b0%e7%94%a8%e6%88%b7%e7%94%bb%e5%83%8f%e6%9c%89%e5%a4%9a%e8%bf%9c.md.html" id="05 从文本到用户画像有多远.md.html">05 从文本到用户画像有多远.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e4%b8%89%e5%8d%81%e5%85%ad%e5%bc%8f/06%20%e8%b6%85%e8%b6%8a%e6%a0%87%e7%ad%be%e7%9a%84%e5%86%85%e5%ae%b9%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f.md.html" id="06 超越标签的内容推荐系统.md.html">06 超越标签的内容推荐系统.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e4%b8%89%e5%8d%81%e5%85%ad%e5%bc%8f/07%20%e4%ba%ba%e4%bb%a5%e7%be%a4%e5%88%86%ef%bc%8c%e4%bd%a0%e6%98%af%e4%bb%80%e4%b9%88%e4%ba%ba%e5%b0%b1%e7%9c%8b%e5%88%b0%e4%bb%80%e4%b9%88%e4%b8%96%e7%95%8c.md.html" id="07 人以群分，你是什么人就看到什么世界.md.html">07 人以群分，你是什么人就看到什么世界.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e4%b8%89%e5%8d%81%e5%85%ad%e5%bc%8f/08%20%e8%a7%a3%e5%af%86%e2%80%9c%e7%9c%8b%e4%ba%86%e5%8f%88%e7%9c%8b%e2%80%9d%e5%92%8c%e2%80%9c%e4%b9%b0%e4%ba%86%e5%8f%88%e4%b9%b0%e2%80%9d.md.html" id="08 解密“看了又看”和“买了又买”.md.html">08 解密“看了又看”和“买了又买”.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e4%b8%89%e5%8d%81%e5%85%ad%e5%bc%8f/09%20%e5%8d%8f%e5%90%8c%e8%bf%87%e6%bb%a4%e4%b8%ad%e7%9a%84%e7%9b%b8%e4%bc%bc%e5%ba%a6%e8%ae%a1%e7%ae%97%e6%96%b9%e6%b3%95%e6%9c%89%e5%93%aa%e4%ba%9b.md.html" id="09 协同过滤中的相似度计算方法有哪些.md.html">09 协同过滤中的相似度计算方法有哪些.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e4%b8%89%e5%8d%81%e5%85%ad%e5%bc%8f/10%20%e9%82%a3%e4%ba%9b%e5%9c%a8Netflix%20Prize%e4%b8%ad%e5%a4%a7%e6%94%be%e5%bc%82%e5%bd%a9%e7%9a%84%e6%8e%a8%e8%8d%90%e7%ae%97%e6%b3%95.md.html" id="10 那些在Netflix Prize中大放异彩的推荐算法.md.html">10 那些在Netflix Prize中大放异彩的推荐算法.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e4%b8%89%e5%8d%81%e5%85%ad%e5%bc%8f/11%20Facebook%e6%98%af%e6%80%8e%e4%b9%88%e4%b8%ba%e5%8d%81%e4%ba%bf%e4%ba%ba%e4%ba%92%e7%9b%b8%e6%8e%a8%e8%8d%90%e5%a5%bd%e5%8f%8b%e7%9a%84.md.html" id="11 Facebook是怎么为十亿人互相推荐好友的.md.html">11 Facebook是怎么为十亿人互相推荐好友的.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e4%b8%89%e5%8d%81%e5%85%ad%e5%bc%8f/12%20%e5%a6%82%e6%9e%9c%e5%85%b3%e6%b3%a8%e6%8e%92%e5%ba%8f%e6%95%88%e6%9e%9c%ef%bc%8c%e9%82%a3%e4%b9%88%e8%bf%99%e4%b8%aa%e6%a8%a1%e5%9e%8b%e5%8f%af%e4%bb%a5%e5%b8%ae%e5%88%b0%e4%bd%a0.md.html" id="12 如果关注排序效果，那么这个模型可以帮到你.md.html">12 如果关注排序效果，那么这个模型可以帮到你.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e4%b8%89%e5%8d%81%e5%85%ad%e5%bc%8f/13%20%e7%bb%8f%e5%85%b8%e6%a8%a1%e5%9e%8b%e8%9e%8d%e5%90%88%e5%8a%9e%e6%b3%95%ef%bc%9a%e7%ba%bf%e6%80%a7%e6%a8%a1%e5%9e%8b%e5%92%8c%e6%a0%91%e6%a8%a1%e5%9e%8b%e7%9a%84%e7%bb%84%e5%90%88%e6%8b%b3.md.html" id="13 经典模型融合办法：线性模型和树模型的组合拳.md.html">13 经典模型融合办法：线性模型和树模型的组合拳.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e4%b8%89%e5%8d%81%e5%85%ad%e5%bc%8f/14%20%e4%b8%80%e7%bd%91%e6%89%93%e5%b0%bd%e5%8d%8f%e5%90%8c%e8%bf%87%e6%bb%a4%e3%80%81%e7%9f%a9%e9%98%b5%e5%88%86%e8%a7%a3%e5%92%8c%e7%ba%bf%e6%80%a7%e6%a8%a1%e5%9e%8b.md.html" id="14 一网打尽协同过滤、矩阵分解和线性模型.md.html">14 一网打尽协同过滤、矩阵分解和线性模型.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e4%b8%89%e5%8d%81%e5%85%ad%e5%bc%8f/15%20%e6%b7%b1%e5%ba%a6%e5%92%8c%e5%ae%bd%e5%ba%a6%e5%85%bc%e5%85%b7%e7%9a%84%e8%9e%8d%e5%90%88%e6%a8%a1%e5%9e%8b%20Wide%20and%20Deep.md.html" id="15 深度和宽度兼具的融合模型 Wide and Deep.md.html">15 深度和宽度兼具的融合模型 Wide and Deep.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e4%b8%89%e5%8d%81%e5%85%ad%e5%bc%8f/16%20%e7%ae%80%e5%8d%95%e5%8d%b4%e6%9c%89%e6%95%88%e7%9a%84Bandit%e7%ae%97%e6%b3%95.md.html" id="16 简单却有效的Bandit算法.md.html">16 简单却有效的Bandit算法.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e4%b8%89%e5%8d%81%e5%85%ad%e5%bc%8f/17%20%e7%bb%93%e5%90%88%e4%b8%8a%e4%b8%8b%e6%96%87%e4%bf%a1%e6%81%af%e7%9a%84Bandit%e7%ae%97%e6%b3%95.md.html" id="17 结合上下文信息的Bandit算法.md.html">17 结合上下文信息的Bandit算法.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e4%b8%89%e5%8d%81%e5%85%ad%e5%bc%8f/18%20%e5%a6%82%e4%bd%95%e5%b0%86Bandit%e7%ae%97%e6%b3%95%e4%b8%8e%e5%8d%8f%e5%90%8c%e8%bf%87%e6%bb%a4%e7%bb%93%e5%90%88%e4%bd%bf%e7%94%a8.md.html" id="18 如何将Bandit算法与协同过滤结合使用.md.html">18 如何将Bandit算法与协同过滤结合使用.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e4%b8%89%e5%8d%81%e5%85%ad%e5%bc%8f/19%20%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%9c%a8%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e4%b8%ad%e7%9a%84%e5%ba%94%e7%94%a8%e6%9c%89%e5%93%aa%e4%ba%9b_.md.html" id="19 深度学习在推荐系统中的应用有哪些_.md.html">19 深度学习在推荐系统中的应用有哪些_.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e4%b8%89%e5%8d%81%e5%85%ad%e5%bc%8f/20%20%e7%94%a8RNN%e6%9e%84%e5%bb%ba%e4%b8%aa%e6%80%a7%e5%8c%96%e9%9f%b3%e4%b9%90%e6%92%ad%e5%8d%95.md.html" id="20 用RNN构建个性化音乐播单.md.html">20 用RNN构建个性化音乐播单.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e4%b8%89%e5%8d%81%e5%85%ad%e5%bc%8f/21%20%e6%9e%84%e5%bb%ba%e4%b8%80%e4%b8%aa%e7%a7%91%e5%ad%a6%e7%9a%84%e6%8e%92%e8%a1%8c%e6%a6%9c%e4%bd%93%e7%b3%bb.md.html" id="21 构建一个科学的排行榜体系.md.html">21 构建一个科学的排行榜体系.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e4%b8%89%e5%8d%81%e5%85%ad%e5%bc%8f/22%20%e5%ae%9e%e7%94%a8%e7%9a%84%e5%8a%a0%e6%9d%83%e9%87%87%e6%a0%b7%e7%ae%97%e6%b3%95.md.html" id="22 实用的加权采样算法.md.html">22 实用的加权采样算法.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e4%b8%89%e5%8d%81%e5%85%ad%e5%bc%8f/23%20%e6%8e%a8%e8%8d%90%e5%80%99%e9%80%89%e6%b1%a0%e7%9a%84%e5%8e%bb%e9%87%8d%e7%ad%96%e7%95%a5.md.html" id="23 推荐候选池的去重策略.md.html">23 推荐候选池的去重策略.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e4%b8%89%e5%8d%81%e5%85%ad%e5%bc%8f/24%20%e5%85%b8%e5%9e%8b%e7%9a%84%e4%bf%a1%e6%81%af%e6%b5%81%e6%9e%b6%e6%9e%84%e6%98%af%e4%bb%80%e4%b9%88%e6%a0%b7%e7%9a%84.md.html" id="24 典型的信息流架构是什么样的.md.html">24 典型的信息流架构是什么样的.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e4%b8%89%e5%8d%81%e5%85%ad%e5%bc%8f/25%20Netflix%e4%b8%aa%e6%80%a7%e5%8c%96%e6%8e%a8%e8%8d%90%e6%9e%b6%e6%9e%84.md.html" id="25 Netflix个性化推荐架构.md.html">25 Netflix个性化推荐架构.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e4%b8%89%e5%8d%81%e5%85%ad%e5%bc%8f/26%20%e6%80%bb%e8%a7%88%e6%8e%a8%e8%8d%90%e6%9e%b6%e6%9e%84%e5%92%8c%e6%90%9c%e7%b4%a2%e3%80%81%e5%b9%bf%e5%91%8a%e7%9a%84%e5%85%b3%e7%b3%bb.md.html" id="26 总览推荐架构和搜索、广告的关系.md.html">26 总览推荐架构和搜索、广告的关系.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e4%b8%89%e5%8d%81%e5%85%ad%e5%bc%8f/27%20%e5%b7%a7%e5%a6%87%e9%9a%be%e4%b8%ba%e6%97%a0%e7%b1%b3%e4%b9%8b%e7%82%8a%ef%bc%9a%e6%95%b0%e6%8d%ae%e9%87%87%e9%9b%86%e5%85%b3%e9%94%ae%e8%a6%81%e7%b4%a0.md.html" id="27 巧妇难为无米之炊：数据采集关键要素.md.html">27 巧妇难为无米之炊：数据采集关键要素.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e4%b8%89%e5%8d%81%e5%85%ad%e5%bc%8f/28%20%e8%ae%a9%e4%bd%a0%e7%9a%84%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e5%8f%8d%e5%ba%94%e6%9b%b4%e5%bf%ab%ef%bc%9a%e5%ae%9e%e6%97%b6%e6%8e%a8%e8%8d%90.md.html" id="28 让你的推荐系统反应更快：实时推荐.md.html">28 让你的推荐系统反应更快：实时推荐.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e4%b8%89%e5%8d%81%e5%85%ad%e5%bc%8f/29%20%e8%ae%a9%e6%95%b0%e6%8d%ae%e9%a9%b1%e5%8a%a8%e8%90%bd%e5%9c%b0%ef%bc%8c%e4%bd%a0%e9%9c%80%e8%a6%81%e4%b8%80%e4%b8%aa%e5%ae%9e%e9%aa%8c%e5%b9%b3%e5%8f%b0.md.html" id="29 让数据驱动落地，你需要一个实验平台.md.html">29 让数据驱动落地，你需要一个实验平台.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e4%b8%89%e5%8d%81%e5%85%ad%e5%bc%8f/30%20%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e6%9c%8d%e5%8a%a1%e5%8c%96%e3%80%81%e5%ad%98%e5%82%a8%e9%80%89%e5%9e%8b%e5%8f%8aAPI%e8%ae%be%e8%ae%a1.md.html" id="30 推荐系统服务化、存储选型及API设计.md.html">30 推荐系统服务化、存储选型及API设计.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e4%b8%89%e5%8d%81%e5%85%ad%e5%bc%8f/31%20%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e7%9a%84%e6%b5%8b%e8%af%95%e6%96%b9%e6%b3%95%e5%8f%8a%e5%b8%b8%e7%94%a8%e6%8c%87%e6%a0%87%e4%bb%8b%e7%bb%8d.md.html" id="31 推荐系统的测试方法及常用指标介绍.md.html">31 推荐系统的测试方法及常用指标介绍.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e4%b8%89%e5%8d%81%e5%85%ad%e5%bc%8f/32%20%e9%81%93%e9%ab%98%e4%b8%80%e5%b0%ba%e9%ad%94%e9%ab%98%e4%b8%80%e4%b8%88%ef%bc%9a%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e7%9a%84%e6%94%bb%e9%98%b2.md.html" id="32 道高一尺魔高一丈：推荐系统的攻防.md.html">32 道高一尺魔高一丈：推荐系统的攻防.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e4%b8%89%e5%8d%81%e5%85%ad%e5%bc%8f/33%20%e5%92%8c%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e6%9c%89%e5%85%b3%e7%9a%84%e5%bc%80%e6%ba%90%e5%b7%a5%e5%85%b7%e5%8f%8a%e6%a1%86%e6%9e%b6%e4%bb%8b%e7%bb%8d.md.html" id="33 和推荐系统有关的开源工具及框架介绍.md.html">33 和推荐系统有关的开源工具及框架介绍.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e4%b8%89%e5%8d%81%e5%85%ad%e5%bc%8f/34%20%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e5%9c%a8%e4%ba%92%e8%81%94%e7%bd%91%e4%ba%a7%e5%93%81%e5%95%86%e4%b8%9a%e9%93%be%e6%9d%a1%e4%b8%ad%e7%9a%84%e5%9c%b0%e4%bd%8d.md.html" id="34 推荐系统在互联网产品商业链条中的地位.md.html">34 推荐系统在互联网产品商业链条中的地位.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e4%b8%89%e5%8d%81%e5%85%ad%e5%bc%8f/35%20%e8%af%b4%e8%af%b4%e4%bf%a1%e6%81%af%e6%b5%81%e7%9a%84%e5%89%8d%e4%b8%96%e4%bb%8a%e7%94%9f.md.html" id="35 说说信息流的前世今生.md.html">35 说说信息流的前世今生.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e4%b8%89%e5%8d%81%e5%85%ad%e5%bc%8f/36%20%e7%bb%84%e5%bb%ba%e6%8e%a8%e8%8d%90%e5%9b%a2%e9%98%9f%e5%8f%8a%e5%b7%a5%e7%a8%8b%e5%b8%88%e7%9a%84%e5%ad%a6%e4%b9%a0%e8%b7%af%e5%be%84.md.html" id="36 组建推荐团队及工程师的学习路径.md.html">36 组建推荐团队及工程师的学习路径.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e4%b8%89%e5%8d%81%e5%85%ad%e5%bc%8f/%e5%8a%a0%e9%a4%90%20%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e7%9a%84%e5%8f%82%e8%80%83%e9%98%85%e8%af%bb.md.html" id="加餐 推荐系统的参考阅读.md.html">加餐 推荐系统的参考阅读.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e4%b8%89%e5%8d%81%e5%85%ad%e5%bc%8f/%e7%bb%93%e6%9d%9f%e8%af%ad%20%e9%81%87%e2%80%9c%e8%8d%90%e2%80%9d%e4%b9%8b%e5%90%8e%ef%bc%8c%e6%b1%9f%e6%b9%96%e5%86%8d%e8%a7%81.md.html" id="结束语 遇“荐”之后，江湖再见.md.html">结束语 遇“荐”之后，江湖再见.md.html</a>
</li>
<li><a href="/assets/捐赠.md.html">捐赠</a></li>
</ul>
</div>
</div>
<div class="sidebar-toggle" onclick="sidebar_toggle()" onmouseleave="remove_inner()" onmouseover="add_inner()">
<div class="sidebar-toggle-inner"></div>
</div>
<div class="off-canvas-content">
<div class="columns">
<div class="column col-12 col-lg-12">
<div class="book-navbar">
<header class="navbar">
<section class="navbar-section">
<a onclick="open_sidebar()">
<i class="icon icon-menu"></i>
</a>
</section>
</header>
</div>
<div class="book-content" style="max-width: 960px; margin: 0 auto;
    overflow-x: auto;
    overflow-y: hidden;">
<div class="book-post">
<div align="center">因收到Google相关通知，网站将会择期关闭。<a href="https://lumendatabase.org/notices/44265620" target="_blank">相关通知内容</a><hr/></div>
<p align="center" id="tip"></p>
<h1 class="title" data-id="加餐 推荐系统的参考阅读" id="title">加餐 推荐系统的参考阅读</h1>
<div><p>专栏主体内容已经结束了，在专栏写作的过程中，我阅读了很多业界公开的资料，我觉得有必要整理出来，供想深入阅读的人继续去找虐。</p>
<p>整体来说，在选择参考文献时，我偏爱那些由公司发表的。因为推荐系统本质上还是一种非常依赖实践的算法应用方向，并且，这些商业公司论文中的技术内容也在他们实际的场景中经过了检验。</p>
<p>另外，更多的内容是来自我自己的大脑中，所以我在下面列出来的只是一部分，在经过反复删减之后，保留了这些，有中文有英文，一般来说英文居多。有较理论化的，如优化理论，更多的是较实践派，可以学完即用。这些资料分成这么几个类型。</p>
<ol>
<li>论文：以论文形式发表的，期刊数据库中可以下载到。</li>
<li>网络文章：就是在网上自由流传的内容或者博客，为了方便阅读，我将它们保存为PDF格式。</li>
<li>演示文稿：就是作者曾公开演讲过的内容，相对来说不是那么严谨，但是更容易理解。</li>
<li>书：推荐系统相关的书较少，我在专栏中参考过的书只有一本（附件中不提供书的电子文档）。</li>
</ol>
<p>以上的参考文献我按照章节顺序列在了下面，我还在后面附上一个推荐书单。你可以点击查看。</p>
<h2 id="原理篇">原理篇</h2>
<h2 id="1-内容推荐">1.内容推荐</h2>
<ul>
<li>### 题目：Bag of Tricks for Efficient Text Classification</li>
</ul>
<h3 id="类型-论文"><strong>类型</strong>：论文</h3>
<h3 id="作者-facebook"><strong>作者</strong>：Facebook</h3>
<h3 id="说明"><strong>说明</strong>：</h3>
<p>Facebook开源的文本处理工具fastText背后原理。可以训练词嵌入向量，文本多分类，效率和线性模型一样，效果和深度学习一样，值得拥有。</p>
<ul>
<li>### <strong>题目</strong>：The Learning Behind Gmail Priority Inbox</li>
</ul>
<h3 id="类型-论文-1"><strong>类型</strong>：论文</h3>
<h3 id="作者-google"><strong>作者</strong>：Google</h3>
<h3 id="说明-1"><strong>说明</strong>：</h3>
<p>介绍了一种基于文本和行为给用户建模的思路，是信息流推荐的早期探索，Gmail智能邮箱背后的原理。</p>
<ul>
<li>### <strong>题目</strong>：Recommender Systems Handbook(第三章，第九章)</li>
</ul>
<h3 id="类型-书"><strong>类型</strong>：书</h3>
<h3 id="作者-francesco-ricci等"><strong>作者</strong>：Francesco Ricci等</h3>
<h3 id="说明-2"><strong>说明</strong>：</h3>
<p>这本书收录了推荐系统很多经典论文，话题涵盖非常广，第三章专门讲内容推荐的基本原理，第九章是一个具体的基于内容推荐系统的案例。</p>
<ul>
<li>### <strong>题目</strong>：文本上的算法</li>
</ul>
<h3 id="类型-网络文章-网络免费版-已有成书-文本上的算法-深入浅出自然语言处理-内容更丰富"><strong>类型</strong>：网络文章(网络免费版，已有成书《文本上的算法:深入浅出自然语言处理》，内容更丰富)</h3>
<h3 id="作者-路彦雄"><strong>作者</strong>：路彦雄</h3>
<h3 id="说明-3"><strong>说明</strong>：</h3>
<p>介绍了文本挖掘中常用的算法，及基础概念。内容涉及概率论，信息论，文本分类，聚类，深度学习，推荐系统等。</p>
<ul>
<li>### 题目：LDA数学八卦</li>
</ul>
<h3 id="类型-网络文章">类型：网络文章</h3>
<h3 id="作者-rickjin-靳志辉">作者：Rickjin(@靳志辉)</h3>
<h3 id="说明-4">说明：</h3>
<p>由浅入深地讲解LDA原理，对于实际LDA工具的使用有非常大的帮助。</p>
<h2 id="2-近邻推荐">2.近邻推荐</h2>
<ul>
<li>### 题目：Amazon.com recommendations: item-to-item collaborative filtering</li>
</ul>
<h3 id="类型-论文-2">类型：论文</h3>
<h3 id="作者-amazon">作者：Amazon</h3>
<h3 id="说明-5">说明：</h3>
<p>介绍Amazon的推荐系统原理，主要是介绍Item-Based协同过滤算法。</p>
<ul>
<li>### 题目：Slope One Predictors for Online Rating-Based Collaborative Filtering</li>
</ul>
<h3 id="类型-论文-3">类型：论文</h3>
<h3 id="作者-daniel-lemire等">作者：Daniel Lemire等</h3>
<h3 id="说明-6">说明：</h3>
<p>Slope One算法。</p>
<ul>
<li>### 题目：Item-Based Collaborative Filtering Recommendation Algorithms</li>
</ul>
<h3 id="类型-论文-4">类型：论文</h3>
<h3 id="作者-badrul-sarwar等">作者：Badrul Sarwar等</h3>
<h3 id="说明-7">说明：</h3>
<p>GroupLens的研究团队对比了不同的Item-to-Item的推荐算法。</p>
<ul>
<li>### 题目：Collaborative Recommendations Using Item-to-Item Similarity Mappings</li>
</ul>
<h3 id="类型-专利">类型：专利</h3>
<h3 id="作者-amazon-1">作者：Amazon</h3>
<h3 id="说明-8">说明：</h3>
<p>是的，Amazon申请了Item-Based算法的专利，所以如果在美上市企业，小心用这个算法。</p>
<ul>
<li>### 题目：Recommender Systems Handbook（第4章）</li>
</ul>
<h3 id="类型-书-1">类型：书</h3>
<h3 id="作者-francesco-ricci等-1">作者：Francesco Ricci等</h3>
<h3 id="说明-9">说明：</h3>
<p>第四章综述性地讲了近邻推荐，也就是基础协同过滤算法。</p>
<h2 id="3-矩阵分解">3.矩阵分解</h2>
<ul>
<li>### 题目：Matrix Factorization and Collaborative Filtering</li>
</ul>
<h3 id="类型-演示文稿">类型：演示文稿</h3>
<h3 id="作者-daryl-lim">作者：Daryl Lim</h3>
<h3 id="说明-10">说明：</h3>
<p>从PCA这种传统的数据降维方法讲起，综述了矩阵分解和协同过滤算法。矩阵分解也是一种降维方法。</p>
<ul>
<li>### 题目：Factorization Meets the Neighborhood: a Multifaceted Collaborative Filtering Model</li>
</ul>
<h3 id="类型-论文-5">类型：论文</h3>
<h3 id="作者-yehuda-koren">作者：Yehuda Koren</h3>
<h3 id="说明-11">说明：</h3>
<p>把矩阵分解和近邻模型融合在一起。</p>
<ul>
<li>### 题目：BPR- Bayesian Personalized Ranking from Implicit Feedback</li>
</ul>
<h3 id="类型-论文-6">类型：论文</h3>
<h3 id="作者-steffen-rendle等">作者：Steffen Rendle等</h3>
<h3 id="说明-12">说明：</h3>
<p>更关注推荐结果的排序好坏，而不是评分预测精度，那么BPR模型可能是首选，本篇是出处。</p>
<ul>
<li>### 题目：Collaborative Filtering for Implicit Feedback Datasets</li>
</ul>
<h3 id="类型-论文-7">类型：论文</h3>
<h3 id="作者-yifan-hu等">作者：Yifan Hu等</h3>
<h3 id="说明-13">说明：</h3>
<p>不同于通常矩阵分解处理的都是评分数据这样的显式反馈，本文介绍一种处理点击等隐式反馈数据的矩阵分解模型。</p>
<ul>
<li>### 题目：Matrix Factorization Techniques For Recommender Systems</li>
</ul>
<h3 id="类型-论文-8">类型：论文</h3>
<h3 id="作者-yehuda-koren等">作者：Yehuda Koren等</h3>
<h3 id="说明-14">说明：</h3>
<p>本文是大神Yehuda Koren对矩阵分解在推荐系统中的应用做的一个普及性介绍，值得一读。</p>
<ul>
<li>### 题目：The BellKor Solution to the Netflix Grand Prize</li>
</ul>
<h3 id="类型-论文-9">类型：论文</h3>
<h3 id="作者-yehuda-koren-1">作者：Yehuda Koren</h3>
<h3 id="说明-15">说明：</h3>
<p>也是一篇综述，或者说教程，针对Netflix Prize的。</p>
<h2 id="4-模型融合">4.模型融合</h2>
<ul>
<li>### 题目：Adaptive Bound Optimization for Online Convex Optimization</li>
</ul>
<h3 id="类型-论文-10">类型：论文</h3>
<h3 id="作者-google-1">作者：Google</h3>
<h3 id="说明-16">说明：</h3>
<p>FTRL是CTR预估常用的优化算法，本文介绍FTRL算法原理。</p>
<ul>
<li>### 题目：在线最优化求解</li>
</ul>
<h3 id="类型-网络文章-1">类型：网络文章</h3>
<h3 id="作者-冯扬">作者：冯扬</h3>
<h3 id="说明-17">说明：</h3>
<p>是对FTRL的通俗版解说。</p>
<ul>
<li>### 题目：Ad Click Prediction: a View from the Trenches</li>
</ul>
<h3 id="类型-论文-11">类型：论文</h3>
<h3 id="作者-google-2">作者：Google</h3>
<h3 id="说明-18">说明：</h3>
<p>FTRL工程实现解读。</p>
<ul>
<li>### 题目：Factorization Machines</li>
</ul>
<h3 id="类型-论文-12">类型：论文</h3>
<h3 id="作者-steffen-rendle">作者：Steffen Rendle</h3>
<h3 id="说明-19">说明：</h3>
<p>提出FM模型的论文，FM用于CTR预估。</p>
<ul>
<li>### 题目：Field-aware Factorization Machines for CTR Prediction</li>
</ul>
<h3 id="类型-论文-13">类型：论文</h3>
<h3 id="作者-yuchin-juan">作者：Yuchin Juan</h3>
<h3 id="说明-20">说明：</h3>
<p>FFM模型，用于CTR预估。</p>
<ul>
<li>### 题目：Practical Lessons from Predicting Clicks on Ads at Facebook</li>
</ul>
<h3 id="类型-论文-14">类型：论文</h3>
<h3 id="说明-21">说明：</h3>
<p>提出了LR + GBDT的CTR预估模型。</p>
<ul>
<li>### 题目：Wide &amp; Deep Learning for Recommender Systems</li>
</ul>
<h3 id="类型-论文-15">类型：论文</h3>
<h3 id="作者-google-3">作者：Google</h3>
<h3 id="说明-22">说明：</h3>
<p>提出融合深度和宽度模型的Wide&amp;Deep模型，用于CTR预估。</p>
<h2 id="5-bandit算法">5.Bandit算法</h2>
<ul>
<li>### 题目：Introduction to Bandits- Algorithms and Theory Part 1- Bandits with small sets of actions</li>
</ul>
<h3 id="类型-演示文稿-1">类型：演示文稿</h3>
<h3 id="作者-jean-yves-audibert等">作者：Jean-Yves Audibert等</h3>
<h3 id="说明-23">说明：</h3>
<p>介绍bandit算法概念，理论和算法，这部分主要针对小的选项候选集。</p>
<ul>
<li>### 题目：Introduction to Bandits- Algorithms and Theory Part 2- Bandits with large sets of actions</li>
</ul>
<h3 id="类型-演示文稿-2">类型：演示文稿</h3>
<h3 id="作者-jean-yves-audibert等-1">作者：Jean-Yves Audibert等</h3>
<h3 id="说明-24">说明：</h3>
<p>介绍Bandit算法概念，理论和算法，这部分主要针对较大的选项候选集。</p>
<ul>
<li>### 题目：A Contextual-Bandit Approach to Personalized News Article Recommendation</li>
</ul>
<h3 id="类型-论文-16">类型：论文</h3>
<h3 id="作者-yahoo">作者：Yahoo</h3>
<h3 id="说明-25">说明：</h3>
<p>Linucb的原始论文，考虑上下文的Bandit算法。</p>
<ul>
<li>### 题目：Collaborative Filtering Bandits</li>
</ul>
<h3 id="类型-论文-17">类型：论文</h3>
<h3 id="作者-shuai-li等">作者：Shuai Li等</h3>
<h3 id="说明-26">说明：</h3>
<p>Bandit 算法与协同过滤结合，提出COFIBA算法。</p>
<h2 id="6-深度学习">6.深度学习</h2>
<ul>
<li>### 题目：Deep Neural Networks for YouTube Recommendations</li>
</ul>
<h3 id="类型-论文-18">类型：论文</h3>
<h3 id="作者-google-4">作者：Google</h3>
<h3 id="说明-27">说明：</h3>
<p>介绍YouTube视频推荐系统在深度神经网络上的尝试。能从中看到wide&amp;deep模型的影子。</p>
<ul>
<li>### 题目：Efficient Estimation of Word Representations in Vector Space</li>
</ul>
<h3 id="类型-论文-19">类型：论文</h3>
<h3 id="作者-google-5">作者：Google</h3>
<h3 id="说明-28">说明：</h3>
<p>Word2Vec的作者在这篇文章中提出了一种词嵌入向量学习方法，也就是把开源工具包Word2Vec背后的模型详细介绍了一次。理论上很简单，更多是一些工程技巧的分享。Word2Vec给推荐系统带来了一种新的隐因子向量学习方法，深陷评分预测泥潭的矩阵分解被开拓了思路。</p>
<ul>
<li>### 题目：Item2Vec: Neural Item Embedding for Collaborative Filtering</li>
</ul>
<h3 id="类型-论文-20">类型：论文</h3>
<h3 id="作者-microsoft">作者：Microsoft</h3>
<h3 id="说明-29">说明：</h3>
<p>这篇就是借鉴了word2vec在语言建模中的思路，为推荐系统的行为建模，从中为物品学习嵌入向量。</p>
<ul>
<li>### 题目：Learning Representations of Text using Neural Networks</li>
</ul>
<h3 id="类型-演示文稿-3">类型：演示文稿</h3>
<h3 id="作者-google-6">作者：Google</h3>
<h3 id="说明-30">说明：</h3>
<p>理解为word2vec作者写一个教程。</p>
<ul>
<li>### 题目：Long Short-Term Memory</li>
</ul>
<h3 id="类型-论文-21">类型：论文</h3>
<h3 id="作者-sepp-hochreiter等">作者：Sepp Hochreiter等</h3>
<h3 id="说明-31">说明：</h3>
<p>可以用来为序列建模的LSTM，实际上在1997年就发表论文了，只是在十几年后才大火。</p>
<ul>
<li>### 题目：An Empirical Exploration of Recurrent Network Architectures</li>
</ul>
<h3 id="类型-论文-22">类型：论文</h3>
<h3 id="作者-google-7">作者：Google</h3>
<h3 id="说明-32">说明：</h3>
<p>Google在RNN模型使用上的经验分享。</p>
<ul>
<li>### 题目：Recurrent Neural Networks for Collaborative Filtering</li>
</ul>
<h3 id="类型-网络文章-2">类型：网络文章</h3>
<h3 id="作者-erik-bernhardsson">作者：Erik Bernhardsson</h3>
<h3 id="说明-33">说明：</h3>
<p>这是Erik Bernhardsson在Spotify期间所做的尝试，用RNN自动构建音乐播单。Erik Bernhardsson还有一项开源项目Annoy，用于稠密向量的近邻搜索，在推荐系统中也用得较多。</p>
<h2 id="7-其他实用算法">7.其他实用算法</h2>
<ul>
<li>### 题目：Detecting Near-Duplicates for Web Crawling</li>
</ul>
<h3 id="类型-论文-23">类型：论文</h3>
<h3 id="作者-google-8">作者：Google</h3>
<h3 id="说明-34">说明：</h3>
<p>在这篇论文中提出了simhash算法，用于大规模网页去重。</p>
<ul>
<li>### 题目：Weighted Random Sampling over Data Streams</li>
</ul>
<h3 id="类型-论文-24">类型：论文</h3>
<h3 id="作者-pavlos-s-efraimidis">作者：Pavlos S. Efraimidis</h3>
<h3 id="说明-35">说明：</h3>
<p>对流式数据的加权采样。</p>
<ul>
<li>### 题目：Weighted Sampling Without Replacement from Data Streams</li>
</ul>
<h3 id="类型-论文-25">类型：论文：</h3>
<h3 id="作者-vladimir-braverman等">作者：Vladimir Braverman等</h3>
<h3 id="说明-36">说明：</h3>
<p>介绍了两种对流式数据的加权采样。</p>
<h2 id="工程篇">工程篇</h2>
<h2 id="1-常见架构">1.常见架构</h2>
<ul>
<li>### 题目：Activity Feeds Architecture</li>
</ul>
<h3 id="类型-演示文稿-4">类型：演示文稿</h3>
<h3 id="作者-etsy">作者：Etsy</h3>
<h3 id="说明-37">说明：</h3>
<p>本文非常详细地介绍了社交动态信息流的架构设计细节。</p>
<ul>
<li>### 题目：Atom Activity Streams 1.0</li>
</ul>
<h3 id="类型-规范文档">类型：规范文档</h3>
<h3 id="作者-activity-streams-working-group">作者：Activity Streams Working Group</h3>
<h3 id="说明-38">说明：</h3>
<p>这是一份动态信息流数据模型的协议规范文档，由Activity Streams Working Group共同发出，这个组织包含Google和Microsoft。</p>
<ul>
<li>### 题目：Beyond the 5 stars（Netflix Recommendations）</li>
</ul>
<h3 id="类型-网络文章-3">类型：网络文章</h3>
<h3 id="作者-netflix">作者：Netflix</h3>
<h3 id="说明-39">说明：</h3>
<p>Netflix详细宏观上介绍了自家推荐系统的产品形态，不只是比赛中的评分预测那么简单的。</p>
<ul>
<li>### 题目：System Architectures for Personalization and Recommendation</li>
</ul>
<h3 id="类型-网络文章-4">类型：网络文章</h3>
<h3 id="作者-netflix-1">作者：Netflix</h3>
<h3 id="说明-40">说明：</h3>
<p>Netflix 推荐系统的架构介绍。</p>
<ul>
<li>### 题目：Information Seeking-Convergence of Search, Recommendations and Advertising</li>
</ul>
<h3 id="类型-论文-26">类型：论文</h3>
<h3 id="作者-h-garcia-molina等">作者：H Garcia-Molina等</h3>
<h3 id="说明-41">说明：</h3>
<p>探讨搜索、推荐、广告三者架构统一。</p>
<h2 id="2-关键模块">2.关键模块</h2>
<ul>
<li>### 题目：Overlapping Experiment Infrastructure- More, Better, Faster Experimentation</li>
</ul>
<h3 id="类型-论文-27">类型：论文</h3>
<h3 id="作者-google-9">作者：Google</h3>
<h3 id="说明-42">说明：</h3>
<p>ABTest实验平台的扛鼎之作，Google出品，值得拥有。</p>
<ul>
<li>### 题目：TencentRec：Real-time Stream Recommendation in Practice</li>
</ul>
<h3 id="类型-论文-28">类型：论文</h3>
<h3 id="作者-腾讯">作者：腾讯</h3>
<h3 id="说明-43">说明：</h3>
<p>介绍了腾讯内部的实时推荐系统架构。</p>
<ul>
<li>### 题目：Personalization at Spotify using Cassandra</li>
</ul>
<h3 id="类型-网络文章-5">类型：网络文章</h3>
<h3 id="作者-spotify">作者：Spotify</h3>
<h3 id="说明-44">说明：</h3>
<p>介绍了Spotify在推荐系统所用到的数据存储中间件。</p>
<h2 id="3-效果保证">3.效果保证</h2>
<ul>
<li>### 题目：Tutorial on Robustness of Recommender Systems</li>
</ul>
<h3 id="类型-演示文稿-5">类型：演示文稿</h3>
<h3 id="作者-neil-hurley">作者：Neil Hurley</h3>
<h3 id="说明-45">说明：</h3>
<p>本文非常详细讨论了对推荐系统的攻击和防护，并有实验模拟。</p>
<ul>
<li>### 题目：Recommender Systems Handbook(第八章)</li>
</ul>
<h3 id="类型-书-2">类型：书</h3>
<h3 id="作者-francesco-ricci等-2">作者：Francesco Ricci等</h3>
<h3 id="说明-46">说明：</h3>
<p>该书第八章介绍了能见到的几乎所有推荐系统评价指标，只是实际上用不到这么多指标。</p>
<h2 id="其他书目">其他书目</h2>
<ol>
<li>Pattern Recognization and Machine Learning（机器学习基础，有此一本足够了）。</li>
<li>推荐系统实践（国内唯一一本非翻译的推荐系统书籍，入门必选）。</li>
<li>信号与噪声（介绍贝叶斯统计的一本科普书）。</li>
<li>复杂（推荐系统面对的是复杂网络，了解复杂系统和复杂网络的特点，有助于开脑洞）。</li>
<li>信息简史（既然是信息经济，当然要读一本关于信息的历史）。</li>
</ol>
<p>知道你们不会读的，所以就不推荐太多了。但愿我这个激将法有助于你学习进步。</p>
<h3 id="打包资料地址">打包资料地址</h3>
<p><a href="https://github.com/xingwudao/36" target="_blank">https://github.com/xingwudao/36</a></p>
</div>
</div>
<div>
<div id="prePage" style="float: left">
</div>
<div id="nextPage" style="float: right">
</div>
</div>
</div>
</div>
</div>
<div class="copyright">
<hr/>
<p>© 2019 - 2023 <a href="/cdn-cgi/l/email-protection#076b6b6b3e333636373047606a666e6b2964686a" target="_blank">Liangliang Lee</a>.
                    Powered by <a href="https://github.com/gin-gonic/gin" target="_blank">gin</a> and <a href="https://github.com/kaiiiz/hexo-theme-book" target="_blank">hexo-theme-book</a>.</p>
</div>
</div>
<a class="off-canvas-overlay" onclick="hide_canvas()"></a>
</div>
<script data-cfasync="false" src="/cdn-cgi/scripts/5c5dd728/cloudflare-static/email-decode.min.js"></script><script>(function(){function c(){var b=a.contentDocument||a.contentWindow.document;if(b){var d=b.createElement('script');d.innerHTML="window.__CF$cv$params={r:'9358d7e87d7f43c4',t:'MTc0NTUzMTcxMS4wMDAwMDA='};var a=document.createElement('script');a.nonce='';a.src='/cdn-cgi/challenge-platform/scripts/jsd/main.js';document.getElementsByTagName('head')[0].appendChild(a);";b.getElementsByTagName('head')[0].appendChild(d)}}if(document.body){var a=document.createElement('iframe');a.height=1;a.width=1;a.style.position='absolute';a.style.top=0;a.style.left=0;a.style.border='none';a.style.visibility='hidden';document.body.appendChild(a);if('loading'!==document.readyState)c();else if(window.addEventListener)document.addEventListener('DOMContentLoaded',c);else{var e=document.onreadystatechange||function(){};document.onreadystatechange=function(b){e(b);'loading'!==document.readyState&&(document.onreadystatechange=e,c())}}}})();</script></body>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-NPSEEVD756"></script>
<script src="/static/index.js"></script>
</head></html>