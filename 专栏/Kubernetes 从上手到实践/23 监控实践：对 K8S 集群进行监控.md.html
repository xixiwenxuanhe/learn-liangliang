<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<head>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<meta content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=no" name="viewport"/>
<meta content="zh-cn" http-equiv="content-language"/>
<meta content="23 监控实践：对 K8S 集群进行监控" name="description"/>
<link href="/static/favicon.png" rel="icon"/>
<title>23 监控实践：对 K8S 集群进行监控 </title>
<link href="/static/index.css" rel="stylesheet"/>
<link href="/static/highlight.min.css" rel="stylesheet"/>
<script src="/static/highlight.min.js"></script>
<meta content="Hexo 4.2.0" name="generator"/>
<script data-website-id="83e5d5db-9d06-40e3-b780-cbae722fdf8c" defer="" src="https://umami.lianglianglee.com/script.js"></script>
</head>
<body>
<div class="book-container">
<div class="book-sidebar">
<div class="book-brand">
<a href="/">
<img src="/static/favicon.png"/>
<span>技术文章摘抄</span>
</a>
</div>
<div class="book-menu uncollapsible">
<ul class="uncollapsible">
<li><a class="current-tab" href="/">首页</a></li>
<li><a href="../">上一级</a></li>
</ul>
<ul class="uncollapsible">
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/Kubernetes%20%e4%bb%8e%e4%b8%8a%e6%89%8b%e5%88%b0%e5%ae%9e%e8%b7%b5/01%20%20%e5%bc%80%e7%af%87%ef%bc%9a%20Kubernetes%20%e6%98%af%e4%bb%80%e4%b9%88%e4%bb%a5%e5%8f%8a%e4%b8%ba%e4%bb%80%e4%b9%88%e9%9c%80%e8%a6%81%e5%ae%83.md.html" id="01  开篇： Kubernetes 是什么以及为什么需要它.md.html">01  开篇： Kubernetes 是什么以及为什么需要它.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/Kubernetes%20%e4%bb%8e%e4%b8%8a%e6%89%8b%e5%88%b0%e5%ae%9e%e8%b7%b5/02%20%e5%88%9d%e6%ad%a5%e8%ae%a4%e8%af%86%ef%bc%9aKubernetes%20%e5%9f%ba%e7%a1%80%e6%a6%82%e5%bf%b5.md.html" id="02 初步认识：Kubernetes 基础概念.md.html">02 初步认识：Kubernetes 基础概念.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/Kubernetes%20%e4%bb%8e%e4%b8%8a%e6%89%8b%e5%88%b0%e5%ae%9e%e8%b7%b5/03%20%e5%ae%8f%e8%a7%82%e8%ae%a4%e8%af%86%ef%bc%9a%e6%95%b4%e4%bd%93%e6%9e%b6%e6%9e%84.md.html" id="03 宏观认识：整体架构.md.html">03 宏观认识：整体架构.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/Kubernetes%20%e4%bb%8e%e4%b8%8a%e6%89%8b%e5%88%b0%e5%ae%9e%e8%b7%b5/04%20%e6%90%ad%e5%bb%ba%20Kubernetes%20%e9%9b%86%e7%be%a4%20-%20%e6%9c%ac%e5%9c%b0%e5%bf%ab%e9%80%9f%e6%90%ad%e5%bb%ba.md.html" id="04 搭建 Kubernetes 集群 - 本地快速搭建.md.html">04 搭建 Kubernetes 集群 - 本地快速搭建.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/Kubernetes%20%e4%bb%8e%e4%b8%8a%e6%89%8b%e5%88%b0%e5%ae%9e%e8%b7%b5/05%20%e5%8a%a8%e6%89%8b%e5%ae%9e%e8%b7%b5%ef%bc%9a%e6%90%ad%e5%bb%ba%e4%b8%80%e4%b8%aa%20Kubernetes%20%e9%9b%86%e7%be%a4%20-%20%e7%94%9f%e4%ba%a7%e5%8f%af%e7%94%a8.md.html" id="05 动手实践：搭建一个 Kubernetes 集群 - 生产可用.md.html">05 动手实践：搭建一个 Kubernetes 集群 - 生产可用.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/Kubernetes%20%e4%bb%8e%e4%b8%8a%e6%89%8b%e5%88%b0%e5%ae%9e%e8%b7%b5/06%20%e9%9b%86%e7%be%a4%e7%ae%a1%e7%90%86%ef%bc%9a%e5%88%9d%e8%af%86%20kubectl.md.html" id="06 集群管理：初识 kubectl.md.html">06 集群管理：初识 kubectl.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/Kubernetes%20%e4%bb%8e%e4%b8%8a%e6%89%8b%e5%88%b0%e5%ae%9e%e8%b7%b5/07%20%e9%9b%86%e7%be%a4%e7%ae%a1%e7%90%86%ef%bc%9a%e4%bb%a5%20Redis%20%e4%b8%ba%e4%be%8b-%e9%83%a8%e7%bd%b2%e5%8f%8a%e8%ae%bf%e9%97%ae.md.html" id="07 集群管理：以 Redis 为例-部署及访问.md.html">07 集群管理：以 Redis 为例-部署及访问.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/Kubernetes%20%e4%bb%8e%e4%b8%8a%e6%89%8b%e5%88%b0%e5%ae%9e%e8%b7%b5/08%20%e5%ae%89%e5%85%a8%e9%87%8d%e7%82%b9%20%e8%ae%a4%e8%af%81%e5%92%8c%e6%8e%88%e6%9d%83.md.html" id="08 安全重点 认证和授权.md.html">08 安全重点 认证和授权.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/Kubernetes%20%e4%bb%8e%e4%b8%8a%e6%89%8b%e5%88%b0%e5%ae%9e%e8%b7%b5/09%20%e5%ba%94%e7%94%a8%e5%8f%91%e5%b8%83%ef%bc%9a%e9%83%a8%e7%bd%b2%e5%ae%9e%e9%99%85%e9%a1%b9%e7%9b%ae.md.html" id="09 应用发布：部署实际项目.md.html">09 应用发布：部署实际项目.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/Kubernetes%20%e4%bb%8e%e4%b8%8a%e6%89%8b%e5%88%b0%e5%ae%9e%e8%b7%b5/10%20%e5%ba%94%e7%94%a8%e7%ae%a1%e7%90%86%ef%bc%9a%e5%88%9d%e8%af%86%20Helm.md.html" id="10 应用管理：初识 Helm.md.html">10 应用管理：初识 Helm.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/Kubernetes%20%e4%bb%8e%e4%b8%8a%e6%89%8b%e5%88%b0%e5%ae%9e%e8%b7%b5/11%20%e9%83%a8%e7%bd%b2%e5%ae%9e%e8%b7%b5%ef%bc%9a%e4%bb%a5%20Helm%20%e9%83%a8%e7%bd%b2%e9%a1%b9%e7%9b%ae.md.html" id="11 部署实践：以 Helm 部署项目.md.html">11 部署实践：以 Helm 部署项目.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/Kubernetes%20%e4%bb%8e%e4%b8%8a%e6%89%8b%e5%88%b0%e5%ae%9e%e8%b7%b5/12%20%e5%ba%96%e4%b8%81%e8%a7%a3%e7%89%9b%ef%bc%9akube-apiserver.md.html" id="12 庖丁解牛：kube-apiserver.md.html">12 庖丁解牛：kube-apiserver.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/Kubernetes%20%e4%bb%8e%e4%b8%8a%e6%89%8b%e5%88%b0%e5%ae%9e%e8%b7%b5/13%20%e5%ba%96%e4%b8%81%e8%a7%a3%e7%89%9b%ef%bc%9aetcd.md.html" id="13 庖丁解牛：etcd.md.html">13 庖丁解牛：etcd.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/Kubernetes%20%e4%bb%8e%e4%b8%8a%e6%89%8b%e5%88%b0%e5%ae%9e%e8%b7%b5/14%20%e5%ba%96%e4%b8%81%e8%a7%a3%e7%89%9b%ef%bc%9acontroller-manager.md.html" id="14 庖丁解牛：controller-manager.md.html">14 庖丁解牛：controller-manager.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/Kubernetes%20%e4%bb%8e%e4%b8%8a%e6%89%8b%e5%88%b0%e5%ae%9e%e8%b7%b5/15%20%e5%ba%96%e4%b8%81%e8%a7%a3%e7%89%9b%ef%bc%9akube-scheduler.md.html" id="15 庖丁解牛：kube-scheduler.md.html">15 庖丁解牛：kube-scheduler.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/Kubernetes%20%e4%bb%8e%e4%b8%8a%e6%89%8b%e5%88%b0%e5%ae%9e%e8%b7%b5/16%20%e5%ba%96%e4%b8%81%e8%a7%a3%e7%89%9b%ef%bc%9akubelet.md.html" id="16 庖丁解牛：kubelet.md.html">16 庖丁解牛：kubelet.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/Kubernetes%20%e4%bb%8e%e4%b8%8a%e6%89%8b%e5%88%b0%e5%ae%9e%e8%b7%b5/17%20%e5%ba%96%e4%b8%81%e8%a7%a3%e7%89%9b%ef%bc%9akube-proxy.md.html" id="17 庖丁解牛：kube-proxy.md.html">17 庖丁解牛：kube-proxy.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/Kubernetes%20%e4%bb%8e%e4%b8%8a%e6%89%8b%e5%88%b0%e5%ae%9e%e8%b7%b5/18%20%20%e5%ba%96%e4%b8%81%e8%a7%a3%e7%89%9b%ef%bc%9aContainer%20Runtime%20%ef%bc%88Docker%ef%bc%89.md.html" id="18  庖丁解牛：Container Runtime （Docker）.md.html">18  庖丁解牛：Container Runtime （Docker）.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/Kubernetes%20%e4%bb%8e%e4%b8%8a%e6%89%8b%e5%88%b0%e5%ae%9e%e8%b7%b5/19%20Troubleshoot.md.html" id="19 Troubleshoot.md.html">19 Troubleshoot.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/Kubernetes%20%e4%bb%8e%e4%b8%8a%e6%89%8b%e5%88%b0%e5%ae%9e%e8%b7%b5/20%20%e6%89%a9%e5%b1%95%e5%a2%9e%e5%bc%ba%ef%bc%9aDashboard.md.html" id="20 扩展增强：Dashboard.md.html">20 扩展增强：Dashboard.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/Kubernetes%20%e4%bb%8e%e4%b8%8a%e6%89%8b%e5%88%b0%e5%ae%9e%e8%b7%b5/21%20%e6%89%a9%e5%b1%95%e5%a2%9e%e5%bc%ba%ef%bc%9aCoreDNS.md.html" id="21 扩展增强：CoreDNS.md.html">21 扩展增强：CoreDNS.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/Kubernetes%20%e4%bb%8e%e4%b8%8a%e6%89%8b%e5%88%b0%e5%ae%9e%e8%b7%b5/22%20%e6%9c%8d%e5%8a%a1%e5%a2%9e%e5%bc%ba%ef%bc%9aIngress.md.html" id="22 服务增强：Ingress.md.html">22 服务增强：Ingress.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/Kubernetes%20%e4%bb%8e%e4%b8%8a%e6%89%8b%e5%88%b0%e5%ae%9e%e8%b7%b5/23%20%e7%9b%91%e6%8e%a7%e5%ae%9e%e8%b7%b5%ef%bc%9a%e5%af%b9%20K8S%20%e9%9b%86%e7%be%a4%e8%bf%9b%e8%a1%8c%e7%9b%91%e6%8e%a7.md.html" id="23 监控实践：对 K8S 集群进行监控.md.html">23 监控实践：对 K8S 集群进行监控.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/Kubernetes%20%e4%bb%8e%e4%b8%8a%e6%89%8b%e5%88%b0%e5%ae%9e%e8%b7%b5/24%20%e6%80%bb%e7%bb%93.md.html" id="24 总结.md.html">24 总结.md.html</a>
</li>
<li><a href="/assets/捐赠.md.html">捐赠</a></li>
</ul>
</div>
</div>
<div class="sidebar-toggle" onclick="sidebar_toggle()" onmouseleave="remove_inner()" onmouseover="add_inner()">
<div class="sidebar-toggle-inner"></div>
</div>
<div class="off-canvas-content">
<div class="columns">
<div class="column col-12 col-lg-12">
<div class="book-navbar">
<header class="navbar">
<section class="navbar-section">
<a onclick="open_sidebar()">
<i class="icon icon-menu"></i>
</a>
</section>
</header>
</div>
<div class="book-content" style="max-width: 960px; margin: 0 auto;
    overflow-x: auto;
    overflow-y: hidden;">
<div class="book-post">
<div align="center">因收到Google相关通知，网站将会择期关闭。<a href="https://lumendatabase.org/notices/44265620" target="_blank">相关通知内容</a><hr/></div>
<p align="center" id="tip"></p>
<h1 class="title" data-id="23 监控实践：对 K8S 集群进行监控" id="title">23 监控实践：对 K8S 集群进行监控</h1>
<div><h2 id="整体概览">整体概览</h2>
<p>通过前面的学习，我们对 K8S 有了一定的了解，也具备了一定的集群管理和排错能力。但如果要应用于生产环境中，不可能随时随地的都盯着集群，我们需要扩展我们对集群的感知能力。</p>
<p>本节，我们将介绍下 K8S 集群监控相关的内容。</p>
<h2 id="监控什么">监控什么</h2>
<p>除去 K8S 外，我们平时自己开发的系统或者负责的项目，一般都是有监控的。监控可以提升我们的感知能力，便于我们及时了解集群的变化，以及知道哪里出现了问题。</p>
<p>K8S 是一个典型的分布式系统，组件很多，那么监控的目标，就变的很重要了。</p>
<p>总体来讲，对 K8S 集群的监控的话，主要有以下方面：</p>
<ul>
<li>节点情况</li>
<li>K8S 集群自身状态</li>
<li>部署在 K8S 内的应用的状态</li>
</ul>
<h2 id="prometheus">Prometheus</h2>
<p>对于 K8S 的监控，我们选择 CNCF 旗下次于 K8S 毕业的项目<a href="https://prometheus.io/" target="_blank"> Prometheus </a>。</p>
<p>Prometheus 是一个非常灵活易于扩展的监控系统，它通过各种 <code>exporter</code> 暴露数据，并由 <code>prometheus server</code> 定时去拉数据，然后存储。</p>
<p>它自己提供了一个简单的前端界面，可在其中使用 <a href="https://prometheus.io/docs/prometheus/latest/querying/basics/" target="_blank">PromQL </a>的语法进行查询，并进行图形化展示。</p>
<h2 id="安装-prometheus">安装 Prometheus</h2>
<blockquote>
<p>这里推荐一个项目 <a href="https://github.com/coreos/prometheus-operator" target="_blank">Prometheus Operator</a>, 尽管该项目还处于 Beta 阶段，但是它给在 K8S 中搭建基于 Prometheus 的监控提供了很大的便利。</p>
</blockquote>
<p>我们此处选择以一般的方式进行部署，带你了解其整体的过程。</p>
<ul>
<li>创建一个独立的 <code>Namespace</code>：</li>
</ul>
<pre><code>  apiVersion: v1
  kind: Namespace
  metadata:
    name: monitoring
  
  # 将文件保存为 namespace.yaml 的文件，并执行 kubectl apply -f namespace.yaml 即可，后面不再赘述。
</code></pre>
<pre><code>  master $ kubectl apply -f namespace.yaml
  namespace/monitoring created
</code></pre>
<ul>
<li>RBAC</li>
</ul>
<p>我们的集群使用 <code>kubeadm</code> 创建，默认开启了 <code>RBAC</code>，所以现在需要创建相关的 Role 和 binding。</p>
<pre><code>  apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    name: prometheus
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: prometheus
  subjects:
  - kind: ServiceAccount
    name: prometheus-k8s
    namespace: monitoring
  ---
  apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    name: prometheus
  rules:
  - apiGroups: [""]
    resources:
    - nodes
    - nodes/proxy
    - services
    - endpoints
    - pods
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources:
    - configmaps
    verbs: ["get"]
  - nonResourceURLs: ["/metrics"]
    verbs: ["get"]
  ---
  apiVersion: v1
  kind: ServiceAccount
  metadata:
    name: prometheus-k8s
    namespace: monitoring
</code></pre>
<p>执行创建</p>
<pre><code>  master $ kubectl  apply -f rbac.yaml
  clusterrolebinding.rbac.authorization.k8s.io/prometheus created
  clusterrole.rbac.authorization.k8s.io/prometheus created
  serviceaccount/prometheus-k8s created
</code></pre>
<ul>
<li>创建 Promethes 的配置文件</li>
</ul>
<p>其中的内容主要参考 <a href="https://github.com/prometheus/prometheus/blob/master/documentation/examples/prometheus-kubernetes.yml" target="_blank">Prometheus 官方提供的示例</a> 和 <a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/#kubernetes_sd_config" target="_blank">Prometheus 官方文档</a>。</p>
<pre><code>  apiVersion: v1
  kind: ConfigMap
  metadata:
    name: prometheus-core
    namespace: monitoring
  data:
    prometheus.yaml: |
      global:
        scrape_interval: 30s
        scrape_timeout: 30s
      scrape_configs:
      - job_name: 'kubernetes-apiservers'
      
        kubernetes_sd_configs:
        - role: endpoints
        scheme: https
      
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      
        relabel_configs:
        - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
          action: keep
          regex: default;kubernetes;https
      
      # Scrape config for nodes (kubelet).
      - job_name: 'kubernetes-nodes'
        scheme: https
      
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      
        kubernetes_sd_configs:
        - role: node
      
        relabel_configs:
        - action: labelmap
          regex: __meta_kubernetes_node_label_(.+)
        - target_label: __address__
          replacement: kubernetes.default.svc:443
        - source_labels: [__meta_kubernetes_node_name]
          regex: (.+)
          target_label: __metrics_path__
          replacement: /api/v1/nodes/${1}/proxy/metrics
      
      # Scrape config for Kubelet cAdvisor.
      - job_name: 'kubernetes-cadvisor'
      
        scheme: https
      
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      
        kubernetes_sd_configs:
        - role: node
      
        relabel_configs:
        - action: labelmap
          regex: __meta_kubernetes_node_label_(.+)
        - target_label: __address__
          replacement: kubernetes.default.svc:443
        - source_labels: [__meta_kubernetes_node_name]
          regex: (.+)
          target_label: __metrics_path__
          replacement: /api/v1/nodes/${1}/proxy/metrics/cadvisor
      
      - job_name: 'kubernetes-service-endpoints'
      
        kubernetes_sd_configs:
        - role: endpoints
      
        relabel_configs:
        - action: labelmap
          regex: __meta_kubernetes_service_label_(.+)
        - source_labels: [__meta_kubernetes_namespace]
          action: replace
          target_label: kubernetes_namespace
        - source_labels: [__meta_kubernetes_service_name]
          action: replace
          target_label: kubernetes_name
      
      - job_name: 'kubernetes-services'
      
        metrics_path: /probe
        params:
          module: [http_2xx]
      
        kubernetes_sd_configs:
        - role: service
      
        relabel_configs:
        - source_labels: [__address__]
          target_label: __param_target
        - target_label: __address__
          replacement: blackbox-exporter.example.com:9115
        - source_labels: [__param_target]
          target_label: instance
        - action: labelmap
          regex: __meta_kubernetes_service_label_(.+)
        - source_labels: [__meta_kubernetes_namespace]
          target_label: kubernetes_namespace
        - source_labels: [__meta_kubernetes_service_name]
          target_label: kubernetes_name
      
      - job_name: 'kubernetes-ingresses'
      
        metrics_path: /probe
        params:
          module: [http_2xx]
      
        kubernetes_sd_configs:
        - role: ingress
      
        relabel_configs:
        - source_labels: [__meta_kubernetes_ingress_scheme,__address__,__meta_kubernetes_ingress_path]
          regex: (.+);(.+);(.+)
          replacement: ${1}://${2}${3}
          target_label: __param_target
        - target_label: __address__
          replacement: blackbox-exporter.example.com:9115
        - source_labels: [__param_target]
          target_label: instance
        - action: labelmap
          regex: __meta_kubernetes_ingress_label_(.+)
        - source_labels: [__meta_kubernetes_namespace]
          target_label: kubernetes_namespace
        - source_labels: [__meta_kubernetes_ingress_name]
          target_label: kubernetes_name
      
      - job_name: 'kubernetes-pods'
      
        kubernetes_sd_configs:
        - role: pod
      
        relabel_configs:
        - action: labelmap
          regex: __meta_kubernetes_pod_label_(.+)
        - source_labels: [__meta_kubernetes_namespace]
          action: replace
          target_label: kubernetes_namespace
        - source_labels: [__meta_kubernetes_pod_name]
          action: replace
          target_label: kubernetes_pod_name
</code></pre>
<ul>
<li>部署 Prometheus</li>
</ul>
<pre><code>  apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    name: prometheus-core
    namespace: monitoring
    labels:
      app: prometheus
      component: core
  spec:
    replicas: 1
    template:
      metadata:
        name: prometheus-main
        labels:
          app: prometheus
          component: core
      spec:
        serviceAccountName: prometheus-k8s
        containers:
        - name: prometheus
          image: taobeier/prometheus:v2.6.0
          args:
            - '--storage.tsdb.retention=24h'
            - '--storage.tsdb.path=/prometheus'
            - '--config.file=/etc/prometheus/prometheus.yaml'
          ports:
          - name: webui
            containerPort: 9090
          resources:
            requests:
              cpu: 500m
              memory: 500M
            limits:
              cpu: 500m
              memory: 500M
          volumeMounts:
          - name: data
            mountPath: /prometheus
          - name: config-volume
            mountPath: /etc/prometheus
        volumes:
        - name: data
          emptyDir: {}
        - name: config-volume
          configMap:
            name: prometheus-core
</code></pre>
<ul>
<li>查看部署情况</li>
</ul>
<pre><code>  master $ kubectl  -n monitoring get all
  NAME                                   READY     STATUS    RESTARTS   AGE
  pod/prometheus-core-86b8455f76-mvrn4   1/1       Running   0          12s
  
  NAME                              DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
  deployment.apps/prometheus-core   1         1         1            1           12s
  
  NAME                                         DESIRED   CURRENT   READY     AGE
  replicaset.apps/prometheus-core-86b8455f76   1         1         1         12s
</code></pre>
<p>Prometheus 的主体就已经部署完成。</p>
<ul>
<li>使用 <code>Service</code> 将 <code>Promethes</code> 的服务暴露出来</li>
</ul>
<pre><code>  apiVersion: v1
  kind: Service
  metadata:
    labels:
      app: prometheus
      component: core
    name: prometheus
    namespace: monitoring
  spec:
    ports:
    - protocol: TCP
      port: 9090
      targetPort: 9090
    selector:
      app: prometheus
      component: core
    type: NodePort
</code></pre>
<p>这里为了方便演示，直接使用了 <code>NodePort</code> 的方式暴露服务。当然你也可以参考上一节，使用 <code>Ingress</code> 的方式将服务暴露出来。</p>
<ul>
<li>查询当前状态</li>
</ul>
<p>我们使用 Promethes 自带的 PromQL 语法，查询在当前 <code>monitoring</code> Namespace 中 up 的任务。这里对查询的结果暂不进行展开。</p>
<p><img alt="img" src="assets/167df2ab2fc5b19a"/></p>
<h2 id="安装-node-exporter">安装 Node exporter</h2>
<p>我们刚才在介绍时，提到过 <code>Promethes</code> 支持多种 <code>exporter</code> 暴露指标。我们现在使用 <a href="https://github.com/prometheus/node_exporter" target="_blank">Node exporter</a> 完成对集群中机器的基础监控。</p>
<p>这里有一个需要考虑的点：</p>
<ul>
<li>使用什么方式部署 Node exporter ？</li>
</ul>
<p>Node exporter 有已经编译好的二进制文件，可以很方便的进行部署。当我们要监控集群中所有的机器时，我们是该将它直接部署在机器上，还是部署在集群内？</p>
<p>我建议是直接部署在集群内，使用 <code>DaemonSet</code> 的方式进行部署。这里的考虑是当我们直接部署在宿主机上时，我们最起码需要保证两点：1. Promethes 服务可与它正常通信（Promethes 采用 Pull 的方式采集数据） ；2. 需要服务保活，如果 exporter 挂掉了，那自然就取不到数据。</p>
<p><code>DaemonSet</code> 是一种很合适的的部署方式，可直接将 Node exporter 部署至集群的每个节点上。</p>
<ul>
<li>创建 <code>DaemonSet</code></li>
</ul>
<pre><code>  apiVersion: extensions/v1beta1
  kind: DaemonSet
  metadata:
    name: prometheus-node-exporter
    namespace: monitoring
    labels:
      app: prometheus
      component: node-exporter
  spec:
    template:
      metadata:
        name: prometheus-node-exporter
        labels:
          app: prometheus
          component: node-exporter
      spec:
        tolerations:
        - key: node-role.kubernetes.io/master
          effect: NoSchedule
        containers:
        - image: taobeier/node-exporter:v0.17.0
          name: prometheus-node-exporter
          ports:
          - name: prom-node-exp
            containerPort: 9100
            hostPort: 9100
        hostNetwork: true
        hostPID: true
</code></pre>
<ul>
<li>让 Promethes 抓取数据</li>
</ul>
<pre><code>  apiVersion: v1
  kind: Service
  metadata:
    annotations:
      prometheus.io/scrape: 'true'
    name: prometheus-node-exporter
    namespace: monitoring
    labels:
      app: prometheus
      component: node-exporter
  spec:
    clusterIP: None
    ports:
      - name: prometheus-node-exporter
        port: 9100
        protocol: TCP
    selector:
      app: prometheus
      component: node-exporter
    type: ClusterIP
</code></pre>
<p>这里我们直接使用了添加 <code>annotations</code> 的方式，让 Promethes 自动的通过 Kubernetes SD 发现我们新添加的 exporter （或者说资源）</p>
<p>我们访问 Promethes 的 web 端，进行验证。</p>
<p><img alt="img" src="assets/167df6106b58b2fb"/></p>
<h2 id="总结">总结</h2>
<p>在本节中，我们介绍了 <code>Prometheus</code> 的基本情况，也部署了 <code>Prometheus</code> 的主体服务。</p>
<p>但这是结束么？这并不是，这才刚刚开始。</p>
<p>我们提到 <code>Prometheus</code> 支持多种 <code>exporter</code> 暴露各种指标，而且我们还可以使用 <a href="https://grafana.com/" target="_blank">Grafana</a> 作为我们监控的展示手段。</p>
<p>如果要做 Dashboard 推荐使用 <a href="https://grafana.com/dashboards/162" target="_blank">Kubernetes cluster monitoring (via Prometheus)</a> 。</p>
<p>另外，监控其实涉及的内容很多，包括数据持久化方式。以及是否考虑与集群外的 Prometheus 集群做邦联模式等。这里需要考虑的实际情况较多，暂不一一展开了。</p>
<p>Prometheus 已经从 CNCF 毕业，其在云原生时代下作为标准的监控技术栈也基本确立。至于应用监控，也可使用它的 SDK 来完成。</p>
<p>下节，我们将对本小册进行一次总结。</p>
</div>
</div>
<div>
<div id="prePage" style="float: left">
</div>
<div id="nextPage" style="float: right">
</div>
</div>
</div>
</div>
</div>
<div class="copyright">
<hr/>
<p>© 2019 - 2023 <a href="/cdn-cgi/l/email-protection#375b5b5b0e030606070077505a565e5b1954585a" target="_blank">Liangliang Lee</a>.
                    Powered by <a href="https://github.com/gin-gonic/gin" target="_blank">gin</a> and <a href="https://github.com/kaiiiz/hexo-theme-book" target="_blank">hexo-theme-book</a>.</p>
</div>
</div>
<a class="off-canvas-overlay" onclick="hide_canvas()"></a>
</div>
<script data-cfasync="false" src="/cdn-cgi/scripts/5c5dd728/cloudflare-static/email-decode.min.js"></script><script>(function(){function c(){var b=a.contentDocument||a.contentWindow.document;if(b){var d=b.createElement('script');d.innerHTML="window.__CF$cv$params={r:'9357911dabb94369',t:'MTc0NTUxODMyNS4wMDAwMDA='};var a=document.createElement('script');a.nonce='';a.src='/cdn-cgi/challenge-platform/scripts/jsd/main.js';document.getElementsByTagName('head')[0].appendChild(a);";b.getElementsByTagName('head')[0].appendChild(d)}}if(document.body){var a=document.createElement('iframe');a.height=1;a.width=1;a.style.position='absolute';a.style.top=0;a.style.left=0;a.style.border='none';a.style.visibility='hidden';document.body.appendChild(a);if('loading'!==document.readyState)c();else if(window.addEventListener)document.addEventListener('DOMContentLoaded',c);else{var e=document.onreadystatechange||function(){};document.onreadystatechange=function(b){e(b);'loading'!==document.readyState&&(document.onreadystatechange=e,c())}}}})();</script></body>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-NPSEEVD756"></script>
<script src="/static/index.js"></script>
</head></html>