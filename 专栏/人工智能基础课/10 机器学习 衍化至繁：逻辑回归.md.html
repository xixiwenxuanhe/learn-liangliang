<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<head>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<meta content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=no" name="viewport"/>
<meta content="zh-cn" http-equiv="content-language"/>
<meta content="10 机器学习 衍化至繁：逻辑回归" name="description"/>
<link href="/static/favicon.png" rel="icon"/>
<title>10 机器学习 衍化至繁：逻辑回归 </title>
<link href="/static/index.css" rel="stylesheet"/>
<link href="/static/highlight.min.css" rel="stylesheet"/>
<script src="/static/highlight.min.js"></script>
<meta content="Hexo 4.2.0" name="generator"/>
<script data-website-id="83e5d5db-9d06-40e3-b780-cbae722fdf8c" defer="" src="https://umami.lianglianglee.com/script.js"></script>
</head>
<body>
<div class="book-container">
<div class="book-sidebar">
<div class="book-brand">
<a href="/">
<img src="/static/favicon.png"/>
<span>技术文章摘抄</span>
</a>
</div>
<div class="book-menu uncollapsible">
<ul class="uncollapsible">
<li><a class="current-tab" href="/">首页</a></li>
<li><a href="../">上一级</a></li>
</ul>
<ul class="uncollapsible">
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/00%20%e5%bc%80%e7%af%87%e8%af%8d%20%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%ef%bc%9a%e6%96%b0%e6%97%b6%e4%bb%a3%e7%9a%84%e5%bf%85%e4%bf%ae%e8%af%be.md.html" id="00 开篇词 人工智能：新时代的必修课.md.html">00 开篇词 人工智能：新时代的必修课.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/01%20%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%20%e4%b9%9d%e5%b1%82%e4%b9%8b%e5%8f%b0%ef%bc%8c%e8%b5%b7%e4%ba%8e%e7%b4%af%e5%9c%9f%ef%bc%9a%e7%ba%bf%e6%80%a7%e4%bb%a3%e6%95%b0.md.html" id="01 数学基础 九层之台，起于累土：线性代数.md.html">01 数学基础 九层之台，起于累土：线性代数.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/02%20%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%20%e6%9c%88%e6%9c%89%e9%98%b4%e6%99%b4%e5%9c%86%e7%bc%ba%ef%bc%8c%e6%ad%a4%e4%ba%8b%e5%8f%a4%e9%9a%be%e5%85%a8%ef%bc%9a%e6%a6%82%e7%8e%87%e8%ae%ba.md.html" id="02 数学基础 月有阴晴圆缺，此事古难全：概率论.md.html">02 数学基础 月有阴晴圆缺，此事古难全：概率论.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/03%20%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%20%e7%aa%a5%e4%b8%80%e6%96%91%e8%80%8c%e7%9f%a5%e5%85%a8%e8%b1%b9%ef%bc%9a%e6%95%b0%e7%90%86%e7%bb%9f%e8%ae%a1.md.html" id="03 数学基础 窥一斑而知全豹：数理统计.md.html">03 数学基础 窥一斑而知全豹：数理统计.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/04%20%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%20%e4%b8%8d%e7%95%8f%e6%b5%ae%e4%ba%91%e9%81%ae%e6%9c%9b%e7%9c%bc%ef%bc%9a%e6%9c%80%e4%bc%98%e5%8c%96%e6%96%b9%e6%b3%95.md.html" id="04 数学基础 不畏浮云遮望眼：最优化方法.md.html">04 数学基础 不畏浮云遮望眼：最优化方法.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/05%20%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%20%e4%b8%87%e7%89%a9%e7%9a%86%e6%95%b0%ef%bc%8c%e4%bf%a1%e6%81%af%e4%ba%a6%e7%84%b6%ef%bc%9a%e4%bf%a1%e6%81%af%e8%ae%ba.md.html" id="05 数学基础 万物皆数，信息亦然：信息论.md.html">05 数学基础 万物皆数，信息亦然：信息论.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/06%20%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%20%e6%98%8e%e6%97%a5%e9%bb%84%e8%8a%b1%e8%bf%b9%e9%9a%be%e5%af%bb%ef%bc%9a%e5%bd%a2%e5%bc%8f%e9%80%bb%e8%be%91.md.html" id="06 数学基础 明日黄花迹难寻：形式逻辑.md.html">06 数学基础 明日黄花迹难寻：形式逻辑.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/07%20%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%20%e6%95%b0%e5%b1%b1%e6%9c%89%e8%b7%af%ef%bc%8c%e5%ad%a6%e6%b5%b7%e6%97%a0%e6%b6%af%ef%bc%9a%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e6%a6%82%e8%ae%ba.md.html" id="07 机器学习 数山有路，学海无涯：机器学习概论.md.html">07 机器学习 数山有路，学海无涯：机器学习概论.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/08%20%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%20%e7%ae%80%e7%ba%a6%e8%80%8c%e4%b8%8d%e7%ae%80%e5%8d%95%ef%bc%9a%e7%ba%bf%e6%80%a7%e5%9b%9e%e5%bd%92.md.html" id="08 机器学习 简约而不简单：线性回归.md.html">08 机器学习 简约而不简单：线性回归.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/09%20%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%20%e5%a4%a7%e9%81%93%e8%87%b3%e7%ae%80%ef%bc%9a%e6%9c%b4%e7%b4%a0%e8%b4%9d%e5%8f%b6%e6%96%af%e6%96%b9%e6%b3%95.md.html" id="09 机器学习 大道至简：朴素贝叶斯方法.md.html">09 机器学习 大道至简：朴素贝叶斯方法.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/10%20%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%20%e8%a1%8d%e5%8c%96%e8%87%b3%e7%b9%81%ef%bc%9a%e9%80%bb%e8%be%91%e5%9b%9e%e5%bd%92.md.html" id="10 机器学习 衍化至繁：逻辑回归.md.html">10 机器学习 衍化至繁：逻辑回归.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/11%20%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%20%e6%ad%a5%e6%ad%a5%e4%b8%ba%e8%90%a5%ef%bc%8c%e6%9c%89%e7%ab%a0%e5%8f%af%e5%be%aa%ef%bc%9a%e5%86%b3%e7%ad%96%e6%a0%91.md.html" id="11 机器学习 步步为营，有章可循：决策树.md.html">11 机器学习 步步为营，有章可循：决策树.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/12%20%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%20%e7%a9%b7%e5%88%99%e5%8f%98%ef%bc%8c%e5%8f%98%e5%88%99%e9%80%9a%ef%bc%9a%e6%94%af%e6%8c%81%e5%90%91%e9%87%8f%e6%9c%ba.md.html" id="12 机器学习 穷则变，变则通：支持向量机.md.html">12 机器学习 穷则变，变则通：支持向量机.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/13%20%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%20%e4%b8%89%e4%b8%aa%e8%87%ad%e7%9a%ae%e5%8c%a0%ef%bc%8c%e8%b5%9b%e8%bf%87%e8%af%b8%e8%91%9b%e4%ba%ae%ef%bc%9a%e9%9b%86%e6%88%90%e5%ad%a6%e4%b9%a0.md.html" id="13 机器学习 三个臭皮匠，赛过诸葛亮：集成学习.md.html">13 机器学习 三个臭皮匠，赛过诸葛亮：集成学习.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/14%20%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%20%e7%89%a9%e4%bb%a5%e7%b1%bb%e8%81%9a%ef%bc%8c%e4%ba%ba%e4%bb%a5%e7%be%a4%e5%88%86%ef%bc%9a%e8%81%9a%e7%b1%bb%e5%88%86%e6%9e%90.md.html" id="14 机器学习 物以类聚，人以群分：聚类分析.md.html">14 机器学习 物以类聚，人以群分：聚类分析.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/15%20%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%20%e5%a5%bd%e9%92%a2%e7%94%a8%e5%9c%a8%e5%88%80%e5%88%83%e4%b8%8a%ef%bc%9a%e9%99%8d%e7%bb%b4%e5%ad%a6%e4%b9%a0.md.html" id="15 机器学习 好钢用在刀刃上：降维学习.md.html">15 机器学习 好钢用在刀刃上：降维学习.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/16%20%e4%ba%ba%e5%b7%a5%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%20%e9%81%93%e6%b3%95%e8%87%aa%e7%84%b6%ef%bc%8c%e4%b9%85%e8%97%8f%e7%8e%84%e5%86%a5%ef%bc%9a%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%e7%9a%84%e7%94%9f%e7%90%86%e5%ad%a6%e8%83%8c%e6%99%af.md.html" id="16 人工神经网络 道法自然，久藏玄冥：神经网络的生理学背景.md.html">16 人工神经网络 道法自然，久藏玄冥：神经网络的生理学背景.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/17%20%e4%ba%ba%e5%b7%a5%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%20%e4%b8%80%e4%b8%aa%e9%9d%92%e5%b9%b4%e6%89%8d%e4%bf%8a%e7%9a%84%e6%84%8f%e5%a4%96%e6%ad%bb%e4%ba%a1%ef%bc%9a%e7%a5%9e%e7%bb%8f%e5%85%83%e4%b8%8e%e6%84%9f%e7%9f%a5%e5%99%a8.md.html" id="17 人工神经网络 一个青年才俊的意外死亡：神经元与感知器.md.html">17 人工神经网络 一个青年才俊的意外死亡：神经元与感知器.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/18%20%e4%ba%ba%e5%b7%a5%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%20%e5%b7%a6%e6%89%8b%e4%bf%a1%e5%8f%b7%ef%bc%8c%e5%8f%b3%e6%89%8b%e8%af%af%e5%b7%ae%ef%bc%9a%e5%a4%9a%e5%b1%82%e6%84%9f%e7%9f%a5%e5%99%a8.md.html" id="18 人工神经网络 左手信号，右手误差：多层感知器.md.html">18 人工神经网络 左手信号，右手误差：多层感知器.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/19%20%e4%ba%ba%e5%b7%a5%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%20%e5%90%84%e4%ba%ba%e8%87%aa%e6%89%ab%e9%97%a8%e5%89%8d%e9%9b%aa%ef%bc%9a%e5%be%84%e5%90%91%e5%9f%ba%e5%87%bd%e6%95%b0%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c.md.html" id="19 人工神经网络 各人自扫门前雪：径向基函数神经网络.md.html">19 人工神经网络 各人自扫门前雪：径向基函数神经网络.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/20%20%e4%ba%ba%e5%b7%a5%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%20%e7%9c%8b%e4%b8%8d%e8%a7%81%e7%9a%84%e6%89%8b%ef%bc%9a%e8%87%aa%e7%bb%84%e7%bb%87%e7%89%b9%e5%be%81%e6%98%a0%e5%b0%84.md.html" id="20 人工神经网络 看不见的手：自组织特征映射.md.html">20 人工神经网络 看不见的手：自组织特征映射.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/21%20%e4%ba%ba%e5%b7%a5%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%20%e6%b0%b4%e6%97%a0%e8%87%b3%e6%b8%85%ef%bc%8c%e4%ba%ba%e8%8e%ab%e8%87%b3%e5%af%9f%ef%bc%9a%e6%a8%a1%e7%b3%8a%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c.md.html" id="21 人工神经网络 水无至清，人莫至察：模糊神经网络.md.html">21 人工神经网络 水无至清，人莫至察：模糊神经网络.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/22%20%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%20%e7%a9%ba%e5%b1%b1%e9%b8%a3%e5%93%8d%ef%bc%8c%e9%9d%99%e6%b0%b4%e6%b5%81%e6%b7%b1%ef%bc%9a%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e6%a6%82%e8%bf%b0.md.html" id="22 深度学习 空山鸣响，静水流深：深度学习概述.md.html">22 深度学习 空山鸣响，静水流深：深度学习概述.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/23%20%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%20%e5%89%8d%e6%96%b9%e6%9c%89%e8%b7%af%ef%bc%8c%e6%9c%aa%e6%9d%a5%e5%8f%af%e6%9c%9f%ef%bc%9a%e6%b7%b1%e5%ba%a6%e5%89%8d%e9%a6%88%e7%bd%91%e7%bb%9c.md.html" id="23 深度学习 前方有路，未来可期：深度前馈网络.md.html">23 深度学习 前方有路，未来可期：深度前馈网络.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/24%20%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%20%e5%b0%8f%e6%a0%91%e4%b8%8d%e4%bf%ae%e4%b8%8d%e7%9b%b4%e6%ba%9c%ef%bc%9a%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e4%b8%ad%e7%9a%84%e6%ad%a3%e5%88%99%e5%8c%96.md.html" id="24 深度学习 小树不修不直溜：深度学习中的正则化.md.html">24 深度学习 小树不修不直溜：深度学习中的正则化.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/25%20%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%20%e7%8e%89%e4%b8%8d%e7%90%a2%e4%b8%8d%e6%88%90%e5%99%a8%ef%bc%9a%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e4%b8%ad%e7%9a%84%e4%bc%98%e5%8c%96.md.html" id="25 深度学习 玉不琢不成器：深度学习中的优化.md.html">25 深度学习 玉不琢不成器：深度学习中的优化.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/26%20%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%20%e7%a9%ba%e7%ab%b9%e9%87%8c%e7%9a%84%e7%a7%98%e5%af%86%ef%bc%9a%e8%87%aa%e7%bc%96%e7%a0%81%e5%99%a8.md.html" id="26 深度学习 空竹里的秘密：自编码器.md.html">26 深度学习 空竹里的秘密：自编码器.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/27%20%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%20%e5%9b%b0%e7%9f%a5%e5%8b%89%e8%a1%8c%e8%80%85%e5%8b%87%ef%bc%9a%e6%b7%b1%e5%ba%a6%e5%bc%ba%e5%8c%96%e5%ad%a6%e4%b9%a0.md.html" id="27 深度学习 困知勉行者勇：深度强化学习.md.html">27 深度学习 困知勉行者勇：深度强化学习.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/28%20%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e6%a1%86%e6%9e%b6%e4%b8%8b%e7%9a%84%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%20%e6%9e%af%e6%9c%a8%e9%80%a2%e6%98%a5%ef%bc%9a%e6%b7%b1%e5%ba%a6%e4%bf%a1%e5%bf%b5%e7%bd%91%e7%bb%9c.md.html" id="28 深度学习框架下的神经网络 枯木逢春：深度信念网络.md.html">28 深度学习框架下的神经网络 枯木逢春：深度信念网络.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/29%20%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e6%a1%86%e6%9e%b6%e4%b8%8b%e7%9a%84%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%20%e8%a7%81%e5%be%ae%e7%9f%a5%e8%91%97%ef%bc%9a%e5%8d%b7%e7%a7%af%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c.md.html" id="29 深度学习框架下的神经网络 见微知著：卷积神经网络.md.html">29 深度学习框架下的神经网络 见微知著：卷积神经网络.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/30%20%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e6%a1%86%e6%9e%b6%e4%b8%8b%e7%9a%84%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%20%e6%98%a8%e6%97%a5%e9%87%8d%e7%8e%b0%ef%bc%9a%e5%be%aa%e7%8e%af%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c.md.html" id="30 深度学习框架下的神经网络 昨日重现：循环神经网络.md.html">30 深度学习框架下的神经网络 昨日重现：循环神经网络.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/31%20%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e6%a1%86%e6%9e%b6%e4%b8%8b%e7%9a%84%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%20%e5%b7%a6%e5%8f%b3%e4%ba%92%e6%90%8f%ef%bc%9a%e7%94%9f%e6%88%90%e5%bc%8f%e5%af%b9%e6%8a%97%e7%bd%91%e7%bb%9c.md.html" id="31 深度学习框架下的神经网络 左右互搏：生成式对抗网络.md.html">31 深度学习框架下的神经网络 左右互搏：生成式对抗网络.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/32%20%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e6%a1%86%e6%9e%b6%e4%b8%8b%e7%9a%84%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%20%e4%b8%89%e9%87%8d%e9%97%a8%ef%bc%9a%e9%95%bf%e7%9f%ad%e6%9c%9f%e8%ae%b0%e5%bf%86%e7%bd%91%e7%bb%9c.md.html" id="32 深度学习框架下的神经网络 三重门：长短期记忆网络.md.html">32 深度学习框架下的神经网络 三重门：长短期记忆网络.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/33%20%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e4%b9%8b%e5%a4%96%e7%9a%84%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%20%e4%b8%80%e5%9b%be%e8%83%9c%e5%8d%83%e8%a8%80%ef%bc%9a%e6%a6%82%e7%8e%87%e5%9b%be%e6%a8%a1%e5%9e%8b.md.html" id="33 深度学习之外的人工智能 一图胜千言：概率图模型.md.html">33 深度学习之外的人工智能 一图胜千言：概率图模型.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/34%20%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e4%b9%8b%e5%a4%96%e7%9a%84%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%20%e4%b9%8c%e5%90%88%e4%b9%8b%e4%bc%97%e7%9a%84%e9%80%86%e8%a2%ad%ef%bc%9a%e9%9b%86%e7%be%a4%e6%99%ba%e8%83%bd.md.html" id="34 深度学习之外的人工智能 乌合之众的逆袭：集群智能.md.html">34 深度学习之外的人工智能 乌合之众的逆袭：集群智能.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/35%20%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e4%b9%8b%e5%a4%96%e7%9a%84%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%20%e6%8e%88%e4%ba%ba%e4%bb%a5%e9%b1%bc%e4%b8%8d%e5%a6%82%e6%8e%88%e4%ba%ba%e4%bb%a5%e6%b8%94%ef%bc%9a%e8%bf%81%e7%a7%bb%e5%ad%a6%e4%b9%a0.md.html" id="35 深度学习之外的人工智能 授人以鱼不如授人以渔：迁移学习.md.html">35 深度学习之外的人工智能 授人以鱼不如授人以渔：迁移学习.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/36%20%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e4%b9%8b%e5%a4%96%e7%9a%84%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%20%e6%bb%b4%e6%b0%b4%e8%97%8f%e6%b5%b7%ef%bc%9a%e7%9f%a5%e8%af%86%e5%9b%be%e8%b0%b1.md.html" id="36 深度学习之外的人工智能 滴水藏海：知识图谱.md.html">36 深度学习之外的人工智能 滴水藏海：知识图谱.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/37%20%e5%ba%94%e7%94%a8%e5%9c%ba%e6%99%af%20%e4%bd%a0%e6%98%af%e6%88%91%e7%9a%84%e7%9c%bc%ef%bc%9a%e8%ae%a1%e7%ae%97%e6%9c%ba%e8%a7%86%e8%a7%89.md.html" id="37 应用场景 你是我的眼：计算机视觉.md.html">37 应用场景 你是我的眼：计算机视觉.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/38%20%e5%ba%94%e7%94%a8%e5%9c%ba%e6%99%af%20%e5%98%bf,%20Siri%ef%bc%9a%e8%af%ad%e9%9f%b3%e5%a4%84%e7%90%86.md.html" id="38 应用场景 嘿, Siri：语音处理.md.html">38 应用场景 嘿, Siri：语音处理.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/39%20%e5%ba%94%e7%94%a8%e5%9c%ba%e6%99%af%20%e5%bf%83%e6%9c%89%e7%81%b5%e7%8a%80%e4%b8%80%e7%82%b9%e9%80%9a%ef%bc%9a%e5%af%b9%e8%af%9d%e7%b3%bb%e7%bb%9f.md.html" id="39 应用场景 心有灵犀一点通：对话系统.md.html">39 应用场景 心有灵犀一点通：对话系统.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/40%20%e5%ba%94%e7%94%a8%e5%9c%ba%e6%99%af%20%e6%95%b0%e5%ad%97%e5%b7%b4%e5%88%ab%e5%a1%94%ef%bc%9a%e6%9c%ba%e5%99%a8%e7%bf%bb%e8%af%91.md.html" id="40 应用场景 数字巴别塔：机器翻译.md.html">40 应用场景 数字巴别塔：机器翻译.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/%e4%b8%80%e9%94%ae%e5%88%b0%e8%be%be%20%e4%ba%ba%e5%b7%a5%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%e5%a4%8d%e4%b9%a0%e8%af%be.md.html" id="一键到达 人工神经网络复习课.md.html">一键到达 人工神经网络复习课.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/%e4%b8%80%e9%94%ae%e5%88%b0%e8%be%be%20%e5%ba%94%e7%94%a8%e5%9c%ba%e6%99%af%e5%a4%8d%e4%b9%a0%e8%af%be.md.html" id="一键到达 应用场景复习课.md.html">一键到达 应用场景复习课.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/%e4%b8%80%e9%94%ae%e5%88%b0%e8%be%be%20%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e5%a4%8d%e4%b9%a0%e8%af%be.md.html" id="一键到达 数学基础复习课.md.html">一键到达 数学基础复习课.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/%e4%b8%80%e9%94%ae%e5%88%b0%e8%be%be%20%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e5%a4%8d%e4%b9%a0%e8%af%be.md.html" id="一键到达 机器学习复习课.md.html">一键到达 机器学习复习课.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/%e4%b8%80%e9%94%ae%e5%88%b0%e8%be%be%20%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e4%b9%8b%e5%a4%96%e7%9a%84%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%a4%8d%e4%b9%a0%e8%af%be.md.html" id="一键到达 深度学习之外的人工智能复习课.md.html">一键到达 深度学习之外的人工智能复习课.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/%e4%b8%80%e9%94%ae%e5%88%b0%e8%be%be%20%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%a4%8d%e4%b9%a0%e8%af%be.md.html" id="一键到达 深度学习复习课.md.html">一键到达 深度学习复习课.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/%e4%b8%80%e9%94%ae%e5%88%b0%e8%be%be%20%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e6%a1%86%e6%9e%b6%e4%b8%8b%e7%9a%84%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%e5%a4%8d%e4%b9%a0%e8%af%be.md.html" id="一键到达 深度学习框架下的神经网络复习课.md.html">一键到达 深度学习框架下的神经网络复习课.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/%e6%8e%a8%e8%8d%90%e9%98%85%e8%af%bb%20%e6%88%91%e4%b8%8e%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e7%9a%84%e6%95%85%e4%ba%8b.md.html" id="推荐阅读 我与人工智能的故事.md.html">推荐阅读 我与人工智能的故事.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/%e6%96%b0%e4%b9%a6%20%e3%80%8a%e8%a3%82%e5%8f%98%ef%bc%9a%e7%a7%92%e6%87%82%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e7%9a%84%e5%9f%ba%e7%a1%80%e8%af%be%e3%80%8b.md.html" id="新书 《裂变：秒懂人工智能的基础课》.md.html">新书 《裂变：秒懂人工智能的基础课》.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/%e7%9b%b4%e6%92%ad%e5%9b%9e%e9%a1%be%20%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e5%bf%85%e5%a4%87%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80.md.html" id="直播回顾 机器学习必备的数学基础.md.html">直播回顾 机器学习必备的数学基础.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/%e7%ac%ac2%e5%ad%a3%e5%9b%9e%e5%bd%92%20%e8%bf%99%e6%ac%a1%e6%88%91%e4%bb%ac%e6%9d%a5%e8%81%8a%e8%81%8a%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0.md.html" id="第2季回归 这次我们来聊聊机器学习.md.html">第2季回归 这次我们来聊聊机器学习.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/%e7%bb%93%e8%af%be%20%e6%ba%af%e6%b4%84%e4%bb%8e%e4%b9%8b%ef%bc%8c%e9%81%93%e9%98%bb%e4%b8%94%e9%95%bf.md.html" id="结课 溯洄从之，道阻且长.md.html">结课 溯洄从之，道阻且长.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/%e8%af%be%e5%a4%96%e8%b0%88%20%e2%80%9c%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be%e2%80%9d%e4%b9%8b%e4%ba%8c%e4%b8%89%e9%97%b2%e8%af%9d.md.html" id="课外谈 “人工智能基础课”之二三闲话.md.html">课外谈 “人工智能基础课”之二三闲话.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/%ef%bc%88%e8%af%be%e5%a4%96%e8%be%85%e5%af%bc%ef%bc%89%e4%ba%ba%e5%b7%a5%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%20%e6%8b%93%e5%b1%95%e9%98%85%e8%af%bb%e5%8f%82%e8%80%83%e4%b9%a6.md.html" id="（课外辅导）人工神经网络 拓展阅读参考书.md.html">（课外辅导）人工神经网络 拓展阅读参考书.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/%ef%bc%88%e8%af%be%e5%a4%96%e8%be%85%e5%af%bc%ef%bc%89%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%20%e6%8b%93%e5%b1%95%e9%98%85%e8%af%bb%e5%8f%82%e8%80%83%e4%b9%a6.md.html" id="（课外辅导）数学基础 拓展阅读参考书.md.html">（课外辅导）数学基础 拓展阅读参考书.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/%ef%bc%88%e8%af%be%e5%a4%96%e8%be%85%e5%af%bc%ef%bc%89%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%20%e6%8b%93%e5%b1%95%e9%98%85%e8%af%bb%e5%8f%82%e8%80%83%e4%b9%a6.md.html" id="（课外辅导）机器学习 拓展阅读参考书.md.html">（课外辅导）机器学习 拓展阅读参考书.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/%ef%bc%88%e8%af%be%e5%a4%96%e8%be%85%e5%af%bc%ef%bc%89%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%20%e6%8b%93%e5%b1%95%e9%98%85%e8%af%bb%e5%8f%82%e8%80%83%e4%b9%a6.md.html" id="（课外辅导）深度学习 拓展阅读参考书.md.html">（课外辅导）深度学习 拓展阅读参考书.md.html</a>
</li>
<li><a href="/assets/捐赠.md.html">捐赠</a></li>
</ul>
</div>
</div>
<div class="sidebar-toggle" onclick="sidebar_toggle()" onmouseleave="remove_inner()" onmouseover="add_inner()">
<div class="sidebar-toggle-inner"></div>
</div>
<div class="off-canvas-content">
<div class="columns">
<div class="column col-12 col-lg-12">
<div class="book-navbar">
<header class="navbar">
<section class="navbar-section">
<a onclick="open_sidebar()">
<i class="icon icon-menu"></i>
</a>
</section>
</header>
</div>
<div class="book-content" style="max-width: 960px; margin: 0 auto;
    overflow-x: auto;
    overflow-y: hidden;">
<div class="book-post">
<div align="center">因收到Google相关通知，网站将会择期关闭。<a href="https://lumendatabase.org/notices/44265620" target="_blank">相关通知内容</a><hr/></div>
<p align="center" id="tip"></p>
<h1 class="title" data-id="10 机器学习 衍化至繁：逻辑回归" id="title">10 机器学习 衍化至繁：逻辑回归</h1>
<div><p>周四我和你分享了机器学习中的朴素贝叶斯分类算法，这一算法解决的是将连续取值的输入映射为离散取值的输出的分类问题。朴素贝叶斯分类器是一类<strong>生成模型</strong>，通过构造联合概率分布<span class="math inline">\(P(X, Y)\)</span>实现分类。如果换一种思路，转而用<strong>判别模型</strong>解决分类问题的话，得到的算法就是“<strong>逻辑回归</strong>”。</p>
<p><strong>虽然顶着“回归”的名号，但逻辑回归解决的却是实打实的分类问题</strong>。之所以取了这个名字，原因在于它来源于对线性回归算法的改进。通过引入单调可微函数<span class="math inline">\(g(\\cdot)\)</span>，线性回归模型就可以推广为<span class="math inline">\(y = g ^ {-1} (\\mathbf{w} ^ T \\mathbf{x})\)</span>，进而将线性回归模型的连续预测值与分类任务的离散标记联系起来。当<span class="math inline">\(g(\\cdot)\)</span>取成对数函数的形式时，线性回归就演变为了逻辑回归。</p>
<p>在最简单的二分类问题中，分类的标记可以抽象为0和1，因而线性回归中的实值输出需要映射为二进制的结果。逻辑回归中，实现这一映射是对数几率函数，也叫Sigmoid函数</p>
<p><span class="math display">\[ y = \\dfrac{1}{1 + e ^ {-z}} = \\dfrac{1}{1 + e ^ {- (\\mathbf{w} ^ T \\mathbf{x})}} \]</span></p><p><strong>之所以选择对数几率函数，是因为它具备良好的特性</strong>。</p>
<p>首先，对数几率函数能够将线性回归从负无穷到正无穷的输出范围压缩到(0, 1)之间，无疑更加符合对二分类任务的直观感觉。</p>
<p>其次，当线性回归的结果<span class="math inline">\(z = 0\)</span>时，逻辑回归的结果<span class="math inline">\(y = 0.5\)</span>，这可以视为一个分界点：当<span class="math inline">\(z &gt; 0\)</span>时，<span class="math inline">\(y &gt; 0.5\)</span>，此时逻辑回归的结果就可以判为正例；当<span class="math inline">\(z &lt; 0\)</span>时，<span class="math inline">\(y &lt; 0.5\)</span>，逻辑回归的结果就可以判为反例。</p>
<p>显然，对数几率函数能够在线性回归和逻辑回归之间提供更好的可解释性。这种可解释性可以从数学的角度进一步诠释。</p>
<p>如果将对数几率函数的结果<span class="math inline">\(y\)</span>视为样本<span class="math inline">\(\\mathbf{x}\)</span>作为正例的可能性，则<span class="math inline">\(1 - y\)</span>就是其作为反例的可能性，两者的比值<span class="math inline">\(0 &lt; \\dfrac{y}{1 -y} &lt; +\\infty\)</span>称为几率，体现的是样本作为正例的相对可能性。如果对几率函数取对数，并将前文中的公式代入，可以得到</p>
<p><span class="math display">\[ \\ln \\dfrac{y}{1 -y} = \\mathbf{w} ^ T \\mathbf{x} + b \]</span></p><p>由此可见，当利用逻辑回归模型解决分类任务时，线性回归的结果正是以对数几率的形式出现的。</p>
<p>归根结底，逻辑回归模型由条件概率分布表示</p>
<p><span class="math display">\[ p(y = 1 | \\mathbf{x} ) = \\dfrac{e ^ {\\mathbf{w} ^ T \\mathbf{x} + b}}{1 + e ^ {\\mathbf{w} ^ T \\mathbf{x} + b}}\]</span></p><p><span class="math display">\[p(y = 0 | \\mathbf{x} ) = \\dfrac{1}{1 + e ^ {\\mathbf{w} ^ T \\mathbf{x} + b}} \]</span></p><p><strong>对于给定的实例，逻辑回归模型比较两个条件概率值的大小，并将实例划分到概率较大的分类之中</strong>。</p>
<p><strong>学习时，逻辑回归模型在给定的训练数据集上应用最大似然估计法确定模型的参数</strong>。对给定的数据集<span class="math inline">\({ (\\mathbf{x}_i, y_i)}\)</span>，逻辑回归使每个样本属于其真实标记的概率最大化，以此为依据确定<span class="math inline">\(\\mathbf{w}\)</span>的最优值。由于每个样本的输出<span class="math inline">\(y_i\)</span>都满足两点分布，且不同的样本之间相互独立，因而似然函数可以表示为</p>
<p><span class="math display">\[ L(\\mathbf{w} | \\mathbf{x}) = \\Pi_{i = 1}^N \[p(y = 1 | \\mathbf{x}_i, \\mathbf{w})\] ^ {y_i} \]</span></p><p><span class="math display">\[\\cdot \[1 - p(y = 1 | \\mathbf{x}_i, \\mathbf{w})\] ^ {1 - y_i} \]</span></p><p>利用对数操作将乘积转化为求和，就可以得到对数似然函数</p>
<p><span class="math display">\[ \\log L(\\mathbf{w} | \\mathbf{x}) = \\sum\\limits_{i = 1}^N y_i \\log \[p(y = 1 | \\mathbf{x}_i, \\mathbf{w})\] \]</span></p><p><span class="math display">\[+ (1 - y_i) \\log \[1 - p(y = 1 | \\mathbf{x}_i, \\mathbf{w})\]\]</span></p><p>由于单个样本的标记<span class="math inline">\(y_i\)</span>只能取得0或1，因而上式中的两项中只有一个有非零的取值。将每个条件概率的对数几率函数形式代入上式，经过化简可以得到</p>
<p><span class="math display">\[ \\log L(\\mathbf{w} | \\mathbf{x}) = \\sum\\limits_{i = 1}^N y_i \\cdot (\\mathbf{w} ^ T \\mathbf{x}_i) \]</span></p><p><span class="math display">\[- \\log (1 + e ^ {\\mathbf{w} ^ T \\mathbf{x}_i}) \]</span></p><p><strong>寻找以上函数的最大值就是以对数似然函数为目标函数的最优化问题，通常通过“梯度下降法”或拟“牛顿法”求解</strong>。</p>
<p>当训练数据集是从所有数据中均匀抽取且数量较大时，以上结果还有一种信息论角度的阐释方式：<strong>对数似然函数的最大化可以等效为待求模型与最大熵模型之间KL散度的最小化</strong>。这意味着最优的估计对参数做出的额外假设是最少的，这无疑与最大熵原理不谋而合。</p>
<p>从数学角度看，线性回归和逻辑回归之间的渊源来源于非线性的对数似然函数；而从特征空间的角度看，两者的区别则在于数据判定边界的变化。判定边界可以类比为棋盘上的楚河汉界，边界两侧分别对应不同类型的数据。</p>
<p>以最简单的二维平面直角坐标系为例。受模型形式的限制，利用线性回归只能得到直线形式的判定边界；逻辑回归则在线性回归的基础上，通过对数似然函数的引入使判定边界的形状不再受限于直线，而是推广为更加复杂的曲线形式，更加精细的分类也就不在话下。</p>
<p>逻辑回归与线性回归的关系称得上系出同门，与朴素贝叶斯分类的关系则是殊途同归。两者虽然都可以利用条件概率<span class="math inline">\(P(Y|X)\)</span>完成分类任务，实现的路径却截然不同。</p>
<p>朴素贝叶斯分类器是生成模型的代表，其思想是先由训练数据集估计出输入和输出的联合概率分布，再根据联合概率分布来生成符合条件的输出，<span class="math inline">\(P(Y|X)\)</span>以后验概率的形式出现。</p>
<p>逻辑回归模型则是判别模型的代表，其思想是先由训练数据集估计出输入和输出的条件概率分布，再根据条件概率分布来判定对于给定的输入应该选择哪种输出，<span class="math inline">\(P(Y|X)\)</span>以似然概率的形式出现。</p>
<p><strong>即便原理不同，逻辑回归与朴素贝叶斯分类器在特定的条件下依然可以等效</strong>。用朴素贝叶斯分类器处理二分类任务时，假设对每个<span class="math inline">\(\\mathbf{x}_i\)</span>，属性条件概率<span class="math inline">\(p(\\mathbf{x}_i | Y = y_k)\)</span>都满足正态分布，且正态分布的标准差与输出标记<span class="math inline">\(Y\)</span>无关，那么根据贝叶斯定理，后验概率就可以写成</p>
<p><span class="math display">\[ p(Y = 0 | X) =\]</span></p><p><span class="math display">\[ \\dfrac{p(Y = 0) \\cdot p(X | Y = 0)}{p(Y = 1) \\cdot p(X | Y = 1) + p(Y = 0) \\cdot p(X | Y = 0)} \]</span></p><p><span class="math display">\[ = \\dfrac{1}{1 + \\exp (\\ln \\frac{p(Y = 1) \\cdot p(X | Y = 1)}{p(Y = 0) \\cdot p(X | Y = 0)})} \]</span></p><p>根据朴素贝叶斯方法的假设，类条件概率可以表示为属性条件概率的乘积，因而令<span class="math inline">\(p(Y = 0) = p_0\)</span>并将满足正态分布的属性条件概率<span class="math inline">\(p(\\mathbf{x}_i | Y = y_k)\)</span>代入以上表达式中，经过一番计算就可以得到</p>
<p><span class="math display">\[ p(Y = 0 | X) = \]</span></p><p><span class="math display">\[\\dfrac{1}{1 + \\exp(\\ln \\frac{1 - p_0}{p_0} + \\sum\\limits_i(\\frac{\\mu_{i1} - \\mu_{i0}}{\\sigma_i^2} X_i + \\frac{\\mu_{i0} ^ 2 - \\mu_{i1} ^ 2}{2\\sigma_i^2}))} \]</span></p><p>不难看出，上式的形式和逻辑回归中条件概率<span class="math inline">\(p(y = 0 | \\mathbf{x} )\)</span>的形式是完全一致的，这表明朴素贝叶斯方法和逻辑回归模型学习到的是同一个模型。实际上，在<span class="math inline">\(p(x | Y)\)</span>的分布属于指数分布族这个更一般的假设下，类似的结论都是成立的。</p>
<p>说完了联系，再来看看区别。<strong>两者的区别在于当朴素贝叶斯分类的模型假设不成立时，逻辑回归和朴素贝叶斯方法通常会学习到不同的结果</strong>。当训练样本数接近无穷大时，逻辑回归的渐近分类准确率要优于朴素贝叶斯方法。而且逻辑回归并不完全依赖于属性之间相互独立的假设，即使给定违反这一假设的数据，逻辑回归的条件似然最大化算法也会调整其参数以实现最大化的数据拟合。相比之下，逻辑回归的偏差更小，但方差更大。</p>
<p>除此之外，<strong>两者的区别还在于收敛速度的不同</strong>。逻辑回归中参数估计的收敛速度要慢于朴素贝叶斯方法。当训练数据集的容量较大时，逻辑回归的性能优于朴素贝叶斯方法；但在训练数据稀缺时，两者的表现就会发生反转。</p>
<p>二分类任务只是特例，更通用的情形是多分类的问题，例如手写数字的识别。要让逻辑回归处理多分类问题，就要做出一些改进。</p>
<p><strong>一种改进方式是通过多次二分类实现多个类别的标记</strong>。这等效为直接将逻辑回归应用在每个类别之上，对每个类别都建立一个二分类器。如果输出的类别标记数目为<span class="math inline">\(m\)</span>，就可以得到<span class="math inline">\(m\)</span>个针对不同标记的二分类逻辑回归模型，而对一个实例的分类结果就是这<span class="math inline">\(m\)</span>个分类函数中输出值最大的那个。在这种方式中，对一个实例执行分类需要多次使用逻辑回归算法，其效率显然比较低下。</p>
<p><strong>另一种多分类的方式通过直接修改逻辑回归输出的似然概率，使之适应多分类问题，得到的模型就是Softmax回归</strong>。Softmax回归给出的是实例在每一种分类结果下出现的概率</p>
<p><span class="math display">\[ p(Y = k | x) = \\dfrac{e ^ {\\mathbf{w_k} ^ T \\mathbf{x}}}{\\sum\\limits_{k = 1}^K e ^ {\\mathbf{w_k} ^ T \\mathbf{x}}} \]</span></p><p>式中的<span class="math inline">\(\\mathbf{w_k}\)</span>代表和类别<span class="math inline">\(k\)</span>相关的权重参数。Softmax回归模型的训练与逻辑回归模型类似，都可以转化为通过梯度下降法或者拟牛顿法解决最优化问题。</p>
<p>虽然都能实现多分类的任务，但两种方式的适用范围略有区别。当分类问题的所有类别之间明显互斥，即输出结果只能属于一个类别时，Softmax分类器是更加高效的选择；当所有类别之间不存在互斥关系，可能有交叉的情况出现时，多个二分类逻辑回归模型就能够得到多个类别的标记。</p>
<p>今天我和你分享了机器学习基本算法之一的逻辑回归方法的基本原理，其要点如下：</p>
<ul>
<li>逻辑回归模型是对线性回归的改进，用于解决分类问题；</li>
<li>逻辑回归输出的是实例属于每个类别的似然概率，似然概率最大的类别就是分类结果；</li>
<li>在一定条件下，逻辑回归模型与朴素贝叶斯分类器是等价的；</li>
<li>多分类问题时可以通过多次使用二分类逻辑回归或者使用Softmax回归解决。</li>
</ul>
<p>前文对逻辑回归的分析都是在概率理论的基础上完成的。但在二分类任务中，逻辑回归的作用可以视为是在平面直角坐标系上划定一条数据分类的判定边界。那么逻辑回归的作用能不能从几何角度理解，并推广到高维空间呢？</p>
<p>欢迎发表你的观点。</p>
<p><img alt="" src="assets/d81794d22373b75dd79da8655adacdaa.jpg"/></p>
</div>
</div>
<div>
<div id="prePage" style="float: left">
</div>
<div id="nextPage" style="float: right">
</div>
</div>
</div>
</div>
</div>
<div class="copyright">
<hr/>
<p>© 2019 - 2023 <a href="/cdn-cgi/l/email-protection#6e020202575a5f5f5e592e09030f0702400d0103" target="_blank">Liangliang Lee</a>.
                    Powered by <a href="https://github.com/gin-gonic/gin" target="_blank">gin</a> and <a href="https://github.com/kaiiiz/hexo-theme-book" target="_blank">hexo-theme-book</a>.</p>
</div>
</div>
<a class="off-canvas-overlay" onclick="hide_canvas()"></a>
</div>
<script data-cfasync="false" src="/cdn-cgi/scripts/5c5dd728/cloudflare-static/email-decode.min.js"></script><script>(function(){function c(){var b=a.contentDocument||a.contentWindow.document;if(b){var d=b.createElement('script');d.innerHTML="window.__CF$cv$params={r:'935927255d5605c6',t:'MTc0NTUzNDk1Ni4wMDAwMDA='};var a=document.createElement('script');a.nonce='';a.src='/cdn-cgi/challenge-platform/scripts/jsd/main.js';document.getElementsByTagName('head')[0].appendChild(a);";b.getElementsByTagName('head')[0].appendChild(d)}}if(document.body){var a=document.createElement('iframe');a.height=1;a.width=1;a.style.position='absolute';a.style.top=0;a.style.left=0;a.style.border='none';a.style.visibility='hidden';document.body.appendChild(a);if('loading'!==document.readyState)c();else if(window.addEventListener)document.addEventListener('DOMContentLoaded',c);else{var e=document.onreadystatechange||function(){};document.onreadystatechange=function(b){e(b);'loading'!==document.readyState&&(document.onreadystatechange=e,c())}}}})();</script></body>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-NPSEEVD756"></script>
<script src="/static/index.js"></script>
</head></html>