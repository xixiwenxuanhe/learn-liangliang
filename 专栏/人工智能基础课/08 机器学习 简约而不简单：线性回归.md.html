<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<head>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<meta content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=no" name="viewport"/>
<meta content="zh-cn" http-equiv="content-language"/>
<meta content="08 机器学习 简约而不简单：线性回归" name="description"/>
<link href="/static/favicon.png" rel="icon"/>
<title>08 机器学习 简约而不简单：线性回归 </title>
<link href="/static/index.css" rel="stylesheet"/>
<link href="/static/highlight.min.css" rel="stylesheet"/>
<script src="/static/highlight.min.js"></script>
<meta content="Hexo 4.2.0" name="generator"/>
<script data-website-id="83e5d5db-9d06-40e3-b780-cbae722fdf8c" defer="" src="https://umami.lianglianglee.com/script.js"></script>
</head>
<body>
<div class="book-container">
<div class="book-sidebar">
<div class="book-brand">
<a href="/">
<img src="/static/favicon.png"/>
<span>技术文章摘抄</span>
</a>
</div>
<div class="book-menu uncollapsible">
<ul class="uncollapsible">
<li><a class="current-tab" href="/">首页</a></li>
<li><a href="../">上一级</a></li>
</ul>
<ul class="uncollapsible">
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/00%20%e5%bc%80%e7%af%87%e8%af%8d%20%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%ef%bc%9a%e6%96%b0%e6%97%b6%e4%bb%a3%e7%9a%84%e5%bf%85%e4%bf%ae%e8%af%be.md.html" id="00 开篇词 人工智能：新时代的必修课.md.html">00 开篇词 人工智能：新时代的必修课.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/01%20%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%20%e4%b9%9d%e5%b1%82%e4%b9%8b%e5%8f%b0%ef%bc%8c%e8%b5%b7%e4%ba%8e%e7%b4%af%e5%9c%9f%ef%bc%9a%e7%ba%bf%e6%80%a7%e4%bb%a3%e6%95%b0.md.html" id="01 数学基础 九层之台，起于累土：线性代数.md.html">01 数学基础 九层之台，起于累土：线性代数.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/02%20%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%20%e6%9c%88%e6%9c%89%e9%98%b4%e6%99%b4%e5%9c%86%e7%bc%ba%ef%bc%8c%e6%ad%a4%e4%ba%8b%e5%8f%a4%e9%9a%be%e5%85%a8%ef%bc%9a%e6%a6%82%e7%8e%87%e8%ae%ba.md.html" id="02 数学基础 月有阴晴圆缺，此事古难全：概率论.md.html">02 数学基础 月有阴晴圆缺，此事古难全：概率论.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/03%20%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%20%e7%aa%a5%e4%b8%80%e6%96%91%e8%80%8c%e7%9f%a5%e5%85%a8%e8%b1%b9%ef%bc%9a%e6%95%b0%e7%90%86%e7%bb%9f%e8%ae%a1.md.html" id="03 数学基础 窥一斑而知全豹：数理统计.md.html">03 数学基础 窥一斑而知全豹：数理统计.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/04%20%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%20%e4%b8%8d%e7%95%8f%e6%b5%ae%e4%ba%91%e9%81%ae%e6%9c%9b%e7%9c%bc%ef%bc%9a%e6%9c%80%e4%bc%98%e5%8c%96%e6%96%b9%e6%b3%95.md.html" id="04 数学基础 不畏浮云遮望眼：最优化方法.md.html">04 数学基础 不畏浮云遮望眼：最优化方法.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/05%20%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%20%e4%b8%87%e7%89%a9%e7%9a%86%e6%95%b0%ef%bc%8c%e4%bf%a1%e6%81%af%e4%ba%a6%e7%84%b6%ef%bc%9a%e4%bf%a1%e6%81%af%e8%ae%ba.md.html" id="05 数学基础 万物皆数，信息亦然：信息论.md.html">05 数学基础 万物皆数，信息亦然：信息论.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/06%20%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%20%e6%98%8e%e6%97%a5%e9%bb%84%e8%8a%b1%e8%bf%b9%e9%9a%be%e5%af%bb%ef%bc%9a%e5%bd%a2%e5%bc%8f%e9%80%bb%e8%be%91.md.html" id="06 数学基础 明日黄花迹难寻：形式逻辑.md.html">06 数学基础 明日黄花迹难寻：形式逻辑.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/07%20%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%20%e6%95%b0%e5%b1%b1%e6%9c%89%e8%b7%af%ef%bc%8c%e5%ad%a6%e6%b5%b7%e6%97%a0%e6%b6%af%ef%bc%9a%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e6%a6%82%e8%ae%ba.md.html" id="07 机器学习 数山有路，学海无涯：机器学习概论.md.html">07 机器学习 数山有路，学海无涯：机器学习概论.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/08%20%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%20%e7%ae%80%e7%ba%a6%e8%80%8c%e4%b8%8d%e7%ae%80%e5%8d%95%ef%bc%9a%e7%ba%bf%e6%80%a7%e5%9b%9e%e5%bd%92.md.html" id="08 机器学习 简约而不简单：线性回归.md.html">08 机器学习 简约而不简单：线性回归.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/09%20%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%20%e5%a4%a7%e9%81%93%e8%87%b3%e7%ae%80%ef%bc%9a%e6%9c%b4%e7%b4%a0%e8%b4%9d%e5%8f%b6%e6%96%af%e6%96%b9%e6%b3%95.md.html" id="09 机器学习 大道至简：朴素贝叶斯方法.md.html">09 机器学习 大道至简：朴素贝叶斯方法.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/10%20%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%20%e8%a1%8d%e5%8c%96%e8%87%b3%e7%b9%81%ef%bc%9a%e9%80%bb%e8%be%91%e5%9b%9e%e5%bd%92.md.html" id="10 机器学习 衍化至繁：逻辑回归.md.html">10 机器学习 衍化至繁：逻辑回归.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/11%20%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%20%e6%ad%a5%e6%ad%a5%e4%b8%ba%e8%90%a5%ef%bc%8c%e6%9c%89%e7%ab%a0%e5%8f%af%e5%be%aa%ef%bc%9a%e5%86%b3%e7%ad%96%e6%a0%91.md.html" id="11 机器学习 步步为营，有章可循：决策树.md.html">11 机器学习 步步为营，有章可循：决策树.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/12%20%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%20%e7%a9%b7%e5%88%99%e5%8f%98%ef%bc%8c%e5%8f%98%e5%88%99%e9%80%9a%ef%bc%9a%e6%94%af%e6%8c%81%e5%90%91%e9%87%8f%e6%9c%ba.md.html" id="12 机器学习 穷则变，变则通：支持向量机.md.html">12 机器学习 穷则变，变则通：支持向量机.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/13%20%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%20%e4%b8%89%e4%b8%aa%e8%87%ad%e7%9a%ae%e5%8c%a0%ef%bc%8c%e8%b5%9b%e8%bf%87%e8%af%b8%e8%91%9b%e4%ba%ae%ef%bc%9a%e9%9b%86%e6%88%90%e5%ad%a6%e4%b9%a0.md.html" id="13 机器学习 三个臭皮匠，赛过诸葛亮：集成学习.md.html">13 机器学习 三个臭皮匠，赛过诸葛亮：集成学习.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/14%20%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%20%e7%89%a9%e4%bb%a5%e7%b1%bb%e8%81%9a%ef%bc%8c%e4%ba%ba%e4%bb%a5%e7%be%a4%e5%88%86%ef%bc%9a%e8%81%9a%e7%b1%bb%e5%88%86%e6%9e%90.md.html" id="14 机器学习 物以类聚，人以群分：聚类分析.md.html">14 机器学习 物以类聚，人以群分：聚类分析.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/15%20%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%20%e5%a5%bd%e9%92%a2%e7%94%a8%e5%9c%a8%e5%88%80%e5%88%83%e4%b8%8a%ef%bc%9a%e9%99%8d%e7%bb%b4%e5%ad%a6%e4%b9%a0.md.html" id="15 机器学习 好钢用在刀刃上：降维学习.md.html">15 机器学习 好钢用在刀刃上：降维学习.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/16%20%e4%ba%ba%e5%b7%a5%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%20%e9%81%93%e6%b3%95%e8%87%aa%e7%84%b6%ef%bc%8c%e4%b9%85%e8%97%8f%e7%8e%84%e5%86%a5%ef%bc%9a%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%e7%9a%84%e7%94%9f%e7%90%86%e5%ad%a6%e8%83%8c%e6%99%af.md.html" id="16 人工神经网络 道法自然，久藏玄冥：神经网络的生理学背景.md.html">16 人工神经网络 道法自然，久藏玄冥：神经网络的生理学背景.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/17%20%e4%ba%ba%e5%b7%a5%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%20%e4%b8%80%e4%b8%aa%e9%9d%92%e5%b9%b4%e6%89%8d%e4%bf%8a%e7%9a%84%e6%84%8f%e5%a4%96%e6%ad%bb%e4%ba%a1%ef%bc%9a%e7%a5%9e%e7%bb%8f%e5%85%83%e4%b8%8e%e6%84%9f%e7%9f%a5%e5%99%a8.md.html" id="17 人工神经网络 一个青年才俊的意外死亡：神经元与感知器.md.html">17 人工神经网络 一个青年才俊的意外死亡：神经元与感知器.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/18%20%e4%ba%ba%e5%b7%a5%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%20%e5%b7%a6%e6%89%8b%e4%bf%a1%e5%8f%b7%ef%bc%8c%e5%8f%b3%e6%89%8b%e8%af%af%e5%b7%ae%ef%bc%9a%e5%a4%9a%e5%b1%82%e6%84%9f%e7%9f%a5%e5%99%a8.md.html" id="18 人工神经网络 左手信号，右手误差：多层感知器.md.html">18 人工神经网络 左手信号，右手误差：多层感知器.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/19%20%e4%ba%ba%e5%b7%a5%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%20%e5%90%84%e4%ba%ba%e8%87%aa%e6%89%ab%e9%97%a8%e5%89%8d%e9%9b%aa%ef%bc%9a%e5%be%84%e5%90%91%e5%9f%ba%e5%87%bd%e6%95%b0%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c.md.html" id="19 人工神经网络 各人自扫门前雪：径向基函数神经网络.md.html">19 人工神经网络 各人自扫门前雪：径向基函数神经网络.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/20%20%e4%ba%ba%e5%b7%a5%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%20%e7%9c%8b%e4%b8%8d%e8%a7%81%e7%9a%84%e6%89%8b%ef%bc%9a%e8%87%aa%e7%bb%84%e7%bb%87%e7%89%b9%e5%be%81%e6%98%a0%e5%b0%84.md.html" id="20 人工神经网络 看不见的手：自组织特征映射.md.html">20 人工神经网络 看不见的手：自组织特征映射.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/21%20%e4%ba%ba%e5%b7%a5%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%20%e6%b0%b4%e6%97%a0%e8%87%b3%e6%b8%85%ef%bc%8c%e4%ba%ba%e8%8e%ab%e8%87%b3%e5%af%9f%ef%bc%9a%e6%a8%a1%e7%b3%8a%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c.md.html" id="21 人工神经网络 水无至清，人莫至察：模糊神经网络.md.html">21 人工神经网络 水无至清，人莫至察：模糊神经网络.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/22%20%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%20%e7%a9%ba%e5%b1%b1%e9%b8%a3%e5%93%8d%ef%bc%8c%e9%9d%99%e6%b0%b4%e6%b5%81%e6%b7%b1%ef%bc%9a%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e6%a6%82%e8%bf%b0.md.html" id="22 深度学习 空山鸣响，静水流深：深度学习概述.md.html">22 深度学习 空山鸣响，静水流深：深度学习概述.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/23%20%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%20%e5%89%8d%e6%96%b9%e6%9c%89%e8%b7%af%ef%bc%8c%e6%9c%aa%e6%9d%a5%e5%8f%af%e6%9c%9f%ef%bc%9a%e6%b7%b1%e5%ba%a6%e5%89%8d%e9%a6%88%e7%bd%91%e7%bb%9c.md.html" id="23 深度学习 前方有路，未来可期：深度前馈网络.md.html">23 深度学习 前方有路，未来可期：深度前馈网络.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/24%20%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%20%e5%b0%8f%e6%a0%91%e4%b8%8d%e4%bf%ae%e4%b8%8d%e7%9b%b4%e6%ba%9c%ef%bc%9a%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e4%b8%ad%e7%9a%84%e6%ad%a3%e5%88%99%e5%8c%96.md.html" id="24 深度学习 小树不修不直溜：深度学习中的正则化.md.html">24 深度学习 小树不修不直溜：深度学习中的正则化.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/25%20%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%20%e7%8e%89%e4%b8%8d%e7%90%a2%e4%b8%8d%e6%88%90%e5%99%a8%ef%bc%9a%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e4%b8%ad%e7%9a%84%e4%bc%98%e5%8c%96.md.html" id="25 深度学习 玉不琢不成器：深度学习中的优化.md.html">25 深度学习 玉不琢不成器：深度学习中的优化.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/26%20%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%20%e7%a9%ba%e7%ab%b9%e9%87%8c%e7%9a%84%e7%a7%98%e5%af%86%ef%bc%9a%e8%87%aa%e7%bc%96%e7%a0%81%e5%99%a8.md.html" id="26 深度学习 空竹里的秘密：自编码器.md.html">26 深度学习 空竹里的秘密：自编码器.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/27%20%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%20%e5%9b%b0%e7%9f%a5%e5%8b%89%e8%a1%8c%e8%80%85%e5%8b%87%ef%bc%9a%e6%b7%b1%e5%ba%a6%e5%bc%ba%e5%8c%96%e5%ad%a6%e4%b9%a0.md.html" id="27 深度学习 困知勉行者勇：深度强化学习.md.html">27 深度学习 困知勉行者勇：深度强化学习.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/28%20%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e6%a1%86%e6%9e%b6%e4%b8%8b%e7%9a%84%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%20%e6%9e%af%e6%9c%a8%e9%80%a2%e6%98%a5%ef%bc%9a%e6%b7%b1%e5%ba%a6%e4%bf%a1%e5%bf%b5%e7%bd%91%e7%bb%9c.md.html" id="28 深度学习框架下的神经网络 枯木逢春：深度信念网络.md.html">28 深度学习框架下的神经网络 枯木逢春：深度信念网络.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/29%20%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e6%a1%86%e6%9e%b6%e4%b8%8b%e7%9a%84%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%20%e8%a7%81%e5%be%ae%e7%9f%a5%e8%91%97%ef%bc%9a%e5%8d%b7%e7%a7%af%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c.md.html" id="29 深度学习框架下的神经网络 见微知著：卷积神经网络.md.html">29 深度学习框架下的神经网络 见微知著：卷积神经网络.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/30%20%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e6%a1%86%e6%9e%b6%e4%b8%8b%e7%9a%84%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%20%e6%98%a8%e6%97%a5%e9%87%8d%e7%8e%b0%ef%bc%9a%e5%be%aa%e7%8e%af%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c.md.html" id="30 深度学习框架下的神经网络 昨日重现：循环神经网络.md.html">30 深度学习框架下的神经网络 昨日重现：循环神经网络.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/31%20%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e6%a1%86%e6%9e%b6%e4%b8%8b%e7%9a%84%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%20%e5%b7%a6%e5%8f%b3%e4%ba%92%e6%90%8f%ef%bc%9a%e7%94%9f%e6%88%90%e5%bc%8f%e5%af%b9%e6%8a%97%e7%bd%91%e7%bb%9c.md.html" id="31 深度学习框架下的神经网络 左右互搏：生成式对抗网络.md.html">31 深度学习框架下的神经网络 左右互搏：生成式对抗网络.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/32%20%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e6%a1%86%e6%9e%b6%e4%b8%8b%e7%9a%84%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%20%e4%b8%89%e9%87%8d%e9%97%a8%ef%bc%9a%e9%95%bf%e7%9f%ad%e6%9c%9f%e8%ae%b0%e5%bf%86%e7%bd%91%e7%bb%9c.md.html" id="32 深度学习框架下的神经网络 三重门：长短期记忆网络.md.html">32 深度学习框架下的神经网络 三重门：长短期记忆网络.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/33%20%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e4%b9%8b%e5%a4%96%e7%9a%84%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%20%e4%b8%80%e5%9b%be%e8%83%9c%e5%8d%83%e8%a8%80%ef%bc%9a%e6%a6%82%e7%8e%87%e5%9b%be%e6%a8%a1%e5%9e%8b.md.html" id="33 深度学习之外的人工智能 一图胜千言：概率图模型.md.html">33 深度学习之外的人工智能 一图胜千言：概率图模型.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/34%20%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e4%b9%8b%e5%a4%96%e7%9a%84%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%20%e4%b9%8c%e5%90%88%e4%b9%8b%e4%bc%97%e7%9a%84%e9%80%86%e8%a2%ad%ef%bc%9a%e9%9b%86%e7%be%a4%e6%99%ba%e8%83%bd.md.html" id="34 深度学习之外的人工智能 乌合之众的逆袭：集群智能.md.html">34 深度学习之外的人工智能 乌合之众的逆袭：集群智能.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/35%20%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e4%b9%8b%e5%a4%96%e7%9a%84%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%20%e6%8e%88%e4%ba%ba%e4%bb%a5%e9%b1%bc%e4%b8%8d%e5%a6%82%e6%8e%88%e4%ba%ba%e4%bb%a5%e6%b8%94%ef%bc%9a%e8%bf%81%e7%a7%bb%e5%ad%a6%e4%b9%a0.md.html" id="35 深度学习之外的人工智能 授人以鱼不如授人以渔：迁移学习.md.html">35 深度学习之外的人工智能 授人以鱼不如授人以渔：迁移学习.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/36%20%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e4%b9%8b%e5%a4%96%e7%9a%84%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%20%e6%bb%b4%e6%b0%b4%e8%97%8f%e6%b5%b7%ef%bc%9a%e7%9f%a5%e8%af%86%e5%9b%be%e8%b0%b1.md.html" id="36 深度学习之外的人工智能 滴水藏海：知识图谱.md.html">36 深度学习之外的人工智能 滴水藏海：知识图谱.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/37%20%e5%ba%94%e7%94%a8%e5%9c%ba%e6%99%af%20%e4%bd%a0%e6%98%af%e6%88%91%e7%9a%84%e7%9c%bc%ef%bc%9a%e8%ae%a1%e7%ae%97%e6%9c%ba%e8%a7%86%e8%a7%89.md.html" id="37 应用场景 你是我的眼：计算机视觉.md.html">37 应用场景 你是我的眼：计算机视觉.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/38%20%e5%ba%94%e7%94%a8%e5%9c%ba%e6%99%af%20%e5%98%bf,%20Siri%ef%bc%9a%e8%af%ad%e9%9f%b3%e5%a4%84%e7%90%86.md.html" id="38 应用场景 嘿, Siri：语音处理.md.html">38 应用场景 嘿, Siri：语音处理.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/39%20%e5%ba%94%e7%94%a8%e5%9c%ba%e6%99%af%20%e5%bf%83%e6%9c%89%e7%81%b5%e7%8a%80%e4%b8%80%e7%82%b9%e9%80%9a%ef%bc%9a%e5%af%b9%e8%af%9d%e7%b3%bb%e7%bb%9f.md.html" id="39 应用场景 心有灵犀一点通：对话系统.md.html">39 应用场景 心有灵犀一点通：对话系统.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/40%20%e5%ba%94%e7%94%a8%e5%9c%ba%e6%99%af%20%e6%95%b0%e5%ad%97%e5%b7%b4%e5%88%ab%e5%a1%94%ef%bc%9a%e6%9c%ba%e5%99%a8%e7%bf%bb%e8%af%91.md.html" id="40 应用场景 数字巴别塔：机器翻译.md.html">40 应用场景 数字巴别塔：机器翻译.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/%e4%b8%80%e9%94%ae%e5%88%b0%e8%be%be%20%e4%ba%ba%e5%b7%a5%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%e5%a4%8d%e4%b9%a0%e8%af%be.md.html" id="一键到达 人工神经网络复习课.md.html">一键到达 人工神经网络复习课.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/%e4%b8%80%e9%94%ae%e5%88%b0%e8%be%be%20%e5%ba%94%e7%94%a8%e5%9c%ba%e6%99%af%e5%a4%8d%e4%b9%a0%e8%af%be.md.html" id="一键到达 应用场景复习课.md.html">一键到达 应用场景复习课.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/%e4%b8%80%e9%94%ae%e5%88%b0%e8%be%be%20%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e5%a4%8d%e4%b9%a0%e8%af%be.md.html" id="一键到达 数学基础复习课.md.html">一键到达 数学基础复习课.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/%e4%b8%80%e9%94%ae%e5%88%b0%e8%be%be%20%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e5%a4%8d%e4%b9%a0%e8%af%be.md.html" id="一键到达 机器学习复习课.md.html">一键到达 机器学习复习课.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/%e4%b8%80%e9%94%ae%e5%88%b0%e8%be%be%20%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e4%b9%8b%e5%a4%96%e7%9a%84%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%a4%8d%e4%b9%a0%e8%af%be.md.html" id="一键到达 深度学习之外的人工智能复习课.md.html">一键到达 深度学习之外的人工智能复习课.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/%e4%b8%80%e9%94%ae%e5%88%b0%e8%be%be%20%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%a4%8d%e4%b9%a0%e8%af%be.md.html" id="一键到达 深度学习复习课.md.html">一键到达 深度学习复习课.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/%e4%b8%80%e9%94%ae%e5%88%b0%e8%be%be%20%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e6%a1%86%e6%9e%b6%e4%b8%8b%e7%9a%84%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%e5%a4%8d%e4%b9%a0%e8%af%be.md.html" id="一键到达 深度学习框架下的神经网络复习课.md.html">一键到达 深度学习框架下的神经网络复习课.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/%e6%8e%a8%e8%8d%90%e9%98%85%e8%af%bb%20%e6%88%91%e4%b8%8e%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e7%9a%84%e6%95%85%e4%ba%8b.md.html" id="推荐阅读 我与人工智能的故事.md.html">推荐阅读 我与人工智能的故事.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/%e6%96%b0%e4%b9%a6%20%e3%80%8a%e8%a3%82%e5%8f%98%ef%bc%9a%e7%a7%92%e6%87%82%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e7%9a%84%e5%9f%ba%e7%a1%80%e8%af%be%e3%80%8b.md.html" id="新书 《裂变：秒懂人工智能的基础课》.md.html">新书 《裂变：秒懂人工智能的基础课》.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/%e7%9b%b4%e6%92%ad%e5%9b%9e%e9%a1%be%20%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e5%bf%85%e5%a4%87%e7%9a%84%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80.md.html" id="直播回顾 机器学习必备的数学基础.md.html">直播回顾 机器学习必备的数学基础.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/%e7%ac%ac2%e5%ad%a3%e5%9b%9e%e5%bd%92%20%e8%bf%99%e6%ac%a1%e6%88%91%e4%bb%ac%e6%9d%a5%e8%81%8a%e8%81%8a%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0.md.html" id="第2季回归 这次我们来聊聊机器学习.md.html">第2季回归 这次我们来聊聊机器学习.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/%e7%bb%93%e8%af%be%20%e6%ba%af%e6%b4%84%e4%bb%8e%e4%b9%8b%ef%bc%8c%e9%81%93%e9%98%bb%e4%b8%94%e9%95%bf.md.html" id="结课 溯洄从之，道阻且长.md.html">结课 溯洄从之，道阻且长.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/%e8%af%be%e5%a4%96%e8%b0%88%20%e2%80%9c%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be%e2%80%9d%e4%b9%8b%e4%ba%8c%e4%b8%89%e9%97%b2%e8%af%9d.md.html" id="课外谈 “人工智能基础课”之二三闲话.md.html">课外谈 “人工智能基础课”之二三闲话.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/%ef%bc%88%e8%af%be%e5%a4%96%e8%be%85%e5%af%bc%ef%bc%89%e4%ba%ba%e5%b7%a5%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%20%e6%8b%93%e5%b1%95%e9%98%85%e8%af%bb%e5%8f%82%e8%80%83%e4%b9%a6.md.html" id="（课外辅导）人工神经网络 拓展阅读参考书.md.html">（课外辅导）人工神经网络 拓展阅读参考书.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/%ef%bc%88%e8%af%be%e5%a4%96%e8%be%85%e5%af%bc%ef%bc%89%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%20%e6%8b%93%e5%b1%95%e9%98%85%e8%af%bb%e5%8f%82%e8%80%83%e4%b9%a6.md.html" id="（课外辅导）数学基础 拓展阅读参考书.md.html">（课外辅导）数学基础 拓展阅读参考书.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/%ef%bc%88%e8%af%be%e5%a4%96%e8%be%85%e5%af%bc%ef%bc%89%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%20%e6%8b%93%e5%b1%95%e9%98%85%e8%af%bb%e5%8f%82%e8%80%83%e4%b9%a6.md.html" id="（课外辅导）机器学习 拓展阅读参考书.md.html">（课外辅导）机器学习 拓展阅读参考书.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%9f%ba%e7%a1%80%e8%af%be/%ef%bc%88%e8%af%be%e5%a4%96%e8%be%85%e5%af%bc%ef%bc%89%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%20%e6%8b%93%e5%b1%95%e9%98%85%e8%af%bb%e5%8f%82%e8%80%83%e4%b9%a6.md.html" id="（课外辅导）深度学习 拓展阅读参考书.md.html">（课外辅导）深度学习 拓展阅读参考书.md.html</a>
</li>
<li><a href="/assets/捐赠.md.html">捐赠</a></li>
</ul>
</div>
</div>
<div class="sidebar-toggle" onclick="sidebar_toggle()" onmouseleave="remove_inner()" onmouseover="add_inner()">
<div class="sidebar-toggle-inner"></div>
</div>
<div class="off-canvas-content">
<div class="columns">
<div class="column col-12 col-lg-12">
<div class="book-navbar">
<header class="navbar">
<section class="navbar-section">
<a onclick="open_sidebar()">
<i class="icon icon-menu"></i>
</a>
</section>
</header>
</div>
<div class="book-content" style="max-width: 960px; margin: 0 auto;
    overflow-x: auto;
    overflow-y: hidden;">
<div class="book-post">
<div align="center">因收到Google相关通知，网站将会择期关闭。<a href="https://lumendatabase.org/notices/44265620" target="_blank">相关通知内容</a><hr/></div>
<p align="center" id="tip"></p>
<h1 class="title" data-id="08 机器学习 简约而不简单：线性回归" id="title">08 机器学习 简约而不简单：线性回归</h1>
<div><p>数学中的线性模型可谓“简约而不简单”：它既能体现出重要的基本思想，又能构造出功能更加强大的非线性模型。在机器学习领域，线性回归就是这样一类基本的任务，它应用了一系列影响深远的数学工具。</p>
<p>在数理统计中，回归分析是确定多种变量间相互依赖的定量关系的方法。<strong>线性回归假设输出变量是若干输入变量的线性组合，并根据这一关系求解线性组合中的最优系数</strong>。在众多回归分析的方法里，线性回归模型最易于拟合，其估计结果的统计特性也更容易确定，因而得到广泛应用。而在机器学习中，回归问题隐含了输入变量和输出变量均可连续取值的前提，因而利用线性回归模型可以对任意输入给出对输出的估计。</p>
<p>1875年，从事遗传问题研究的英国统计学家弗朗西斯·高尔顿正在寻找父代与子代身高之间的关系。在分析了1078对父子的身高数据后，他发现这些数据的散点图大致呈直线状态，即父亲的身高和儿子的身高呈正相关关系。而在正相关关系背后还隐藏着另外一个现象：矮个子父亲的儿子更可能比父亲高；而高个子父亲的儿子更可能比父亲矮。</p>
<p>受表哥查尔斯·达尔文的影响，高尔顿将这种现象称为“<strong>回归效应</strong>”，即大自然将人类身高的分布约束在相对稳定而不产生两极分化的整体水平，并给出了历史上第一个线性回归的表达式：y = 0.516x + 33.73，式中的y和x分别代表以英寸为单位的子代和父代的身高。</p>
<p>高尔顿的思想在今天的机器学习中依然保持着旺盛的生命力。假定一个实例可以用列向量<span class="math inline">\({\\bf x} = (x_1; x_2; \\cdots, x_n)\)</span>表示，每个<span class="math inline">\(x_i\)</span>代表了实例在第i个属性上的取值，线性回归的作用就是习得一组参数<span class="math inline">\(w_i, i = 0, 1, \\cdots, n\)</span>，使预测输出可以表示为以这组参数为权重的实例属性的线性组合。如果引入常量<span class="math inline">\(x_0 = 1\)</span>，线性回归试图学习的模型就是</p>
<p><span class="math display">\[f({\\bf x}) = {\\bf w} ^ T {\\bf x} = \\sum\\limits_{i = 0}^{n} w_i \\cdot x_i \]</span></p><p>当实例只有一个属性时，输入和输出之间的关系就是二维平面上的一条直线；当实例的属性数目较多时，线性回归得到的就是n+1维空间上的一个超平面，对应一个维度等于n的线性子空间。</p>
<p>在训练集上确定系数<span class="math inline">\(w_i\)</span>时，预测输出<span class="math inline">\(f({\\bf x})\)</span>和真实输出<span class="math inline">\(y\)</span>之间的误差是关注的核心指标。在线性回归中，这一误差是以<strong>均方误差</strong>来定义的。当线性回归的模型为二维平面上的直线时，均方误差就是预测输出和真实输出之间的<strong>欧几里得距离</strong>，也就是两点间向量的<span class="math inline">\(L ^ 2\)</span>范数。而以使均方误差取得最小值为目标的模型求解方法就是<strong>最小二乘法</strong>，其表达式可以写成</p>
<p><span class="math display">\[{\\mathbf{w}}^\* = \\mathop {\\arg \\min }\\limits_{\\mathbf{w}} \\sum\\limits_{k = 1} {{{({{\\mathbf{w}}^T}{{\\mathbf{x}}_k} - {y_k})}^2}} \]</span></p><p><span class="math display">\[= \\mathop {\\arg \\min }\\limits_{\\mathbf{w}} \\sum\\limits_{k = 1} || y_k - \\mathbf{w}^T \\mathbf{x}_k ||^2 \]</span></p><p>式中每个<span class="math inline">\({\\bf x}_k\)</span>代表训练集中的一个样本。<strong>在单变量线性回归任务中，最小二乘法的作用就是找到一条直线，使所有样本到直线的欧式距离之和最小</strong>。</p>
<p>说到这里，问题就来了：凭什么使均方误差最小化的参数就是和训练样本匹配的最优模型呢？</p>
<p>这个问题可以从概率论的角度阐释。线性回归得到的是统计意义上的拟合结果，在单变量的情形下，可能每一个样本点都没有落在求得的直线上。</p>
<p>对这个现象的一种解释是回归结果可以完美匹配理想样本点的分布，但训练中使用的真实样本点是理想样本点和噪声叠加的结果，因而与回归模型之间产生了偏差，而每个样本点上噪声的取值就等于<span class="math inline">\(y_k - f(\\mathbf{x}_k)\)</span>。</p>
<p>假定影响样本点的噪声满足参数为<span class="math inline">\((0, \\sigma ^ 2)\)</span>的正态分布（还记得正态分布的概率密度公式吗？），这意味着噪声等于0的概率密度最大，幅度（无论正负）越大的噪声出现的概率越小。在这种情形下，对参数<span class="math inline">\(\\mathbf{w}\)</span>的推导就可以用<strong>最大似然的方式</strong>进行，即在已知样本数据及其分布的条件下，找到使样本数据以最大概率出现的假设。</p>
<p>单个样本<span class="math inline">\(\\mathbf{x}_k\)</span>出现的概率实际上就是噪声等于<span class="math inline">\(y_k - f(\\mathbf{x}_k)\)</span>的概率，而相互独立的所有样本同时出现的概率则是每个样本出现概率的乘积，其表达式可以写成</p>
<p><span class="math display">\[p({{\\mathbf{x}}_1},{{\\mathbf{x}}_2}, \\cdots {{\\mathbf{x}}_k}, \\cdots |{\\mathbf{w}}) =\]</span></p><p><span class="math display">\[ \\prod\\limits_k {\\frac{1}{{\\sqrt {2\\pi } \\sigma }}} \\exp \[ - \\frac{1}{{2{\\sigma ^2}}}{({y_k} - {{\\mathbf{w}}^T}{{\\mathbf{x}}_k})^2}\]\]</span></p><p>而最大似然估计的任务就是让以上表达式的取值最大化。出于计算简便的考虑，上面的乘积式可以通过取对数的方式转化成求和式，且取对数的操作并不会影响其单调性。经过一番运算后，上式的最大化就可以等效为<span class="math inline">\(\\sum\\limits_{k} (y_k - \\mathbf{w} ^ T \\mathbf{x}_k) ^ 2\)</span>的最小化。这不就是最小二乘法的结果么？</p>
<p>因此，<strong>对于单变量线性回归而言，在误差函数服从正态分布的情况下，从几何意义出发的最小二乘法与从概率意义出发的最大似然估计是等价的</strong>。</p>
<p>确定了最小二乘法的最优性，接下来的问题就是如何求解均方误差的最小值。在单变量线性回归中，其回归方程可以写成<span class="math inline">\(y = w_1x + w_0\)</span>。根据最优化理论，将这一表达式代入均方误差的表达式中，并分别对<span class="math inline">\(w_1\)</span>和<span class="math inline">\(w_0\)</span>求偏导数，令两个偏导数均等于0的取值就是线性回归的最优解，其解析式可以写成</p>
<p><span class="math display">\[ w_1 = \\dfrac{\\sum\\limits_{k = 1}^m y_k(x_k - \\frac{1}{m} \\sum\\limits_{k = 1}^m x_k)}{\\sum\\limits_{k = 1}^m x_k^2 - \\frac{1}{m} (\\sum\\limits_{k = 1}^m x_k) ^ 2}\]</span></p><p><span class="math display">\[w_0 = \\dfrac{1}{m} \\sum\\limits_{k = 1}^m (y_k - w_1x_k)\]</span></p><p><strong>单变量线性回归只是一种最简单的特例</strong>。子代的身高并非仅仅由父母的遗传基因决定，营养条件、生活环境等因素都会产生影响。当样本的描述涉及多个属性时，这类问题就被称为<strong>多元线性回归</strong>。</p>
<p>多元线性回归中的参数<span class="math inline">\(\\mathbf{w}\)</span>也可以用最小二乘法进行估计，其最优解同样用偏导数确定，但参与运算的元素从向量变成了矩阵。在理想的情况下，多元线性回归的最优参数为</p>
<p><span class="math display">\[ {\\mathbf{w}}^\* = (\\mathbf{X} ^ T \\mathbf{X}) ^ {-1} \\mathbf{X} ^ T \\mathbf{y} \]</span></p><p>式中的<span class="math inline">\(\\mathbf{X}\)</span>是由所有样本<span class="math inline">\({\\bf x} = (x_0; x_1; x_2; \\cdots, x_n)\)</span>的转置共同构成的矩阵。但这一表达式只在矩阵<span class="math inline">\((\\mathbf{X} ^ T \\mathbf{X})\)</span>的逆矩阵存在时成立。在大量复杂的实际任务中，每个样本中属性的数目甚至会超过训练集中的样本总数，此时求出的最优解<span class="math inline">\({\\mathbf{w}}^\*\)</span>就不是唯一的，解的选择将依赖于学习算法的归纳偏好。</p>
<p>但不论采用怎样的选取标准，存在多个最优解都是无法改变的事实，这也意味着过拟合的产生。更重要的是，在过拟合的情形下，微小扰动给训练数据带来的毫厘之差可能会导致训练出的模型谬以千里，模型的稳定性也就无法保证。</p>
<p>要解决过拟合问题，常见的做法是正则化，即添加额外的惩罚项。<strong>在线性回归中，正则化的方式根据其使用惩罚项的不同可以分为两种，分别是“岭回归”和“LASSO回归”</strong>。</p>
<p><strong>在机器学习中，岭回归方法又被称为“参数衰减”</strong>，于20世纪40年代由前苏联学者安德烈·季霍诺夫提出。当然，彼时机器学习尚未诞生，季霍诺夫提出这一方法的主要目的是解决矩阵求逆的稳定性问题，其思想后来被应用到正则化中，形成了今天的岭回归。</p>
<p>岭回归实现正则化的方式是在原始均方误差项的基础上添加一个待求解参数的二范数项，即最小化的对象变为<span class="math inline">\(|| y_k - \\mathbf{w}^T \\mathbf{x}_k || ^ 2 + || \\Gamma \\mathbf{w}|| ^ 2\)</span>，其中的<span class="math inline">\(\\Gamma\)</span>被称为<strong>季霍诺夫矩阵</strong>，通常可以简化为一个常数。</p>
<p>从最优化的角度看，二范数惩罚项的作用在于优先选择范数较小的<span class="math inline">\(\\mathbf{w}\)</span>，这相当于在最小均方误差之外额外添加了一重关于最优解特性的约束条件，将最优解限制在高维空间内的一个球里。岭回归的作用相当于在原始最小二乘的结果上做了缩放，虽然最优解中每个参数的贡献被削弱了，但参数的数目并没有变少。</p>
<p>LASSO回归的全称是“<strong>最小绝对缩减和选择算子</strong>”（Least Absolute Shrinkage and Selection Operator），由加拿大学者罗伯特·提布什拉尼于1996年提出。与岭回归不同的是，LASSO回归选择了待求解参数的一范数项作为惩罚项，即最小化的对象变为<span class="math inline">\(|| y_k - \\mathbf{w}^T \\mathbf{x}_k || ^ 2 + \\lambda ||\\mathbf{w}||_1\)</span>，其中的<span class="math inline">\(\\lambda\)</span>是一个常数。</p>
<p><strong>与岭回归相比，LASSO回归的特点在于稀疏性的引入</strong>。它降低了最优解<span class="math inline">\(\\mathbf{w}\)</span>的维度，也就是将一部分参数的贡献削弱为0，这就使得<span class="math inline">\(\\mathbf{w}\)</span>中元素的数目大大小于原始特征的数目。</p>
<p>这或多或少可以看作奥卡姆剃刀原理的一种实现：当主要矛盾和次要矛盾同时存在时，优先考虑的必然是主要矛盾。虽然饮食、环境、运动等因素都会影响身高的变化，但决定性因素显然只存在在染色体上。值得一提的是，<strong>引入稀疏性是简化复杂问题的一种常用方法，在数据压缩、信号处理等其他领域中亦有广泛应用</strong>。</p>
<p>从概率的角度来看，最小二乘法的解析解可以利用正态分布以及最大似然估计求得，这在前文已有说明。岭回归和LASSO回归也可以从概率的视角进行阐释：岭回归是在<span class="math inline">\(w_i\)</span>满足正态先验分布的条件下，用最大后验概率进行估计得到的结果；LASSO回归是在<span class="math inline">\(w_i\)</span>满足拉普拉斯先验分布的条件下，用最大后验概率进行估计得到的结果。</p>
<p><strong>但无论岭回归还是LASSO回归，其作用都是通过惩罚项的引入抑制过拟合现象，以训练误差的上升为代价，换取测试误差的下降</strong>。将以上两种方法的思想结合可以得到新的优化方法，在此就不做赘述了。</p>
<p>今天我和你分享了机器学习基本算法之一的线性回归的基本原理，其要点如下：</p>
<ul>
<li>线性回归假设输出变量是若干输入变量的线性组合，并根据这一关系求解线性组合中的最优系数；</li>
<li>最小二乘法可用于解决单变量线性回归问题，当误差函数服从正态分布时，它与最大似然估计等价；</li>
<li>多元线性回归问题也可以用最小二乘法求解，但极易出现过拟合现象；</li>
<li>岭回归和LASSO回归分别通过引入二范数惩罚项和一范数惩罚项抑制过拟合。</li>
</ul>
<p>在深度学习大行其道的今天，巨量的参数已经成为常态。在参数越来越多，模型越来越复杂的趋势下，线性回归还能发挥什么样的作用呢？</p>
<p>欢迎发表你的观点。</p>
<p><img alt="" src="assets/c213a86d22def0da9a92fe3092605f3d.jpg"/></p>
</div>
</div>
<div>
<div id="prePage" style="float: left">
</div>
<div id="nextPage" style="float: right">
</div>
</div>
</div>
</div>
</div>
<div class="copyright">
<hr/>
<p>© 2019 - 2023 <a href="/cdn-cgi/l/email-protection#650909095c5154545552250208040c094b060a08" target="_blank">Liangliang Lee</a>.
                    Powered by <a href="https://github.com/gin-gonic/gin" target="_blank">gin</a> and <a href="https://github.com/kaiiiz/hexo-theme-book" target="_blank">hexo-theme-book</a>.</p>
</div>
</div>
<a class="off-canvas-overlay" onclick="hide_canvas()"></a>
</div>
<script data-cfasync="false" src="/cdn-cgi/scripts/5c5dd728/cloudflare-static/email-decode.min.js"></script><script>(function(){function c(){var b=a.contentDocument||a.contentWindow.document;if(b){var d=b.createElement('script');d.innerHTML="window.__CF$cv$params={r:'9359270b7f4a9c82',t:'MTc0NTUzNDk1Mi4wMDAwMDA='};var a=document.createElement('script');a.nonce='';a.src='/cdn-cgi/challenge-platform/scripts/jsd/main.js';document.getElementsByTagName('head')[0].appendChild(a);";b.getElementsByTagName('head')[0].appendChild(d)}}if(document.body){var a=document.createElement('iframe');a.height=1;a.width=1;a.style.position='absolute';a.style.top=0;a.style.left=0;a.style.border='none';a.style.visibility='hidden';document.body.appendChild(a);if('loading'!==document.readyState)c();else if(window.addEventListener)document.addEventListener('DOMContentLoaded',c);else{var e=document.onreadystatechange||function(){};document.onreadystatechange=function(b){e(b);'loading'!==document.readyState&&(document.onreadystatechange=e,c())}}}})();</script></body>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-NPSEEVD756"></script>
<script src="/static/index.js"></script>
</head></html>