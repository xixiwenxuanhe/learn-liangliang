<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<head>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<meta content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=no" name="viewport"/>
<meta content="zh-cn" http-equiv="content-language"/>
<meta content="31 建模连续分布：高斯网络" name="description"/>
<link href="/static/favicon.png" rel="icon"/>
<title>31 建模连续分布：高斯网络 </title>
<link href="/static/index.css" rel="stylesheet"/>
<link href="/static/highlight.min.css" rel="stylesheet"/>
<script src="/static/highlight.min.js"></script>
<meta content="Hexo 4.2.0" name="generator"/>
<script data-website-id="83e5d5db-9d06-40e3-b780-cbae722fdf8c" defer="" src="https://umami.lianglianglee.com/script.js"></script>
</head>
<body>
<div class="book-container">
<div class="book-sidebar">
<div class="book-brand">
<a href="/">
<img src="/static/favicon.png"/>
<span>技术文章摘抄</span>
</a>
</div>
<div class="book-menu uncollapsible">
<ul class="uncollapsible">
<li><a class="current-tab" href="/">首页</a></li>
<li><a href="../">上一级</a></li>
</ul>
<ul class="uncollapsible">
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a040%e8%ae%b2/00%20%e5%bc%80%e7%af%87%e8%af%8d%20%e6%89%93%e9%80%9a%e4%bf%ae%e7%82%bc%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e7%9a%84%e4%bb%bb%e7%9d%a3%e4%ba%8c%e8%84%89.md.html" id="00 开篇词 打通修炼机器学习的任督二脉.md.html">00 开篇词 打通修炼机器学习的任督二脉.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a040%e8%ae%b2/01%20%e9%a2%91%e7%8e%87%e8%a7%86%e8%a7%92%e4%b8%8b%e7%9a%84%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0.md.html" id="01 频率视角下的机器学习.md.html">01 频率视角下的机器学习.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a040%e8%ae%b2/02%20%e8%b4%9d%e5%8f%b6%e6%96%af%e8%a7%86%e8%a7%92%e4%b8%8b%e7%9a%84%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0.md.html" id="02 贝叶斯视角下的机器学习.md.html">02 贝叶斯视角下的机器学习.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a040%e8%ae%b2/03%20%e5%ad%a6%e4%bb%80%e4%b9%88%e4%b8%8e%e6%80%8e%e4%b9%88%e5%ad%a6.md.html" id="03 学什么与怎么学.md.html">03 学什么与怎么学.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a040%e8%ae%b2/04%20%e8%ae%a1%e7%ae%97%e5%ad%a6%e4%b9%a0%e7%90%86%e8%ae%ba.md.html" id="04 计算学习理论.md.html">04 计算学习理论.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a040%e8%ae%b2/05%20%e6%a8%a1%e5%9e%8b%e7%9a%84%e5%88%86%e7%b1%bb%e6%96%b9%e5%bc%8f.md.html" id="05 模型的分类方式.md.html">05 模型的分类方式.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a040%e8%ae%b2/06%20%e6%a8%a1%e5%9e%8b%e7%9a%84%e8%ae%be%e8%ae%a1%e5%87%86%e5%88%99.md.html" id="06 模型的设计准则.md.html">06 模型的设计准则.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a040%e8%ae%b2/07%20%e6%a8%a1%e5%9e%8b%e7%9a%84%e9%aa%8c%e8%af%81%e6%96%b9%e6%b3%95.md.html" id="07 模型的验证方法.md.html">07 模型的验证方法.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a040%e8%ae%b2/08%20%e6%a8%a1%e5%9e%8b%e7%9a%84%e8%af%84%e4%bc%b0%e6%8c%87%e6%a0%87.md.html" id="08 模型的评估指标.md.html">08 模型的评估指标.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a040%e8%ae%b2/09%20%e5%ae%9e%e9%aa%8c%e8%ae%be%e8%ae%a1.md.html" id="09 实验设计.md.html">09 实验设计.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a040%e8%ae%b2/10%20%e7%89%b9%e5%be%81%e9%a2%84%e5%a4%84%e7%90%86.md.html" id="10 特征预处理.md.html">10 特征预处理.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a040%e8%ae%b2/11%20%e5%9f%ba%e7%a1%80%e7%ba%bf%e6%80%a7%e5%9b%9e%e5%bd%92%ef%bc%9a%e4%b8%80%e5%85%83%e4%b8%8e%e5%a4%9a%e5%85%83.md.html" id="11 基础线性回归：一元与多元.md.html">11 基础线性回归：一元与多元.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a040%e8%ae%b2/12%20%e6%ad%a3%e5%88%99%e5%8c%96%e5%a4%84%e7%90%86%ef%bc%9a%e6%94%b6%e7%bc%a9%e6%96%b9%e6%b3%95%e4%b8%8e%e8%be%b9%e9%99%85%e5%8c%96.md.html" id="12 正则化处理：收缩方法与边际化.md.html">12 正则化处理：收缩方法与边际化.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a040%e8%ae%b2/13%20%e7%ba%bf%e6%80%a7%e9%99%8d%e7%bb%b4%ef%bc%9a%e4%b8%bb%e6%88%90%e5%88%86%e7%9a%84%e4%bd%bf%e7%94%a8.md.html" id="13 线性降维：主成分的使用.md.html">13 线性降维：主成分的使用.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a040%e8%ae%b2/14%20%e9%9d%9e%e7%ba%bf%e6%80%a7%e9%99%8d%e7%bb%b4%ef%bc%9a%e6%b5%81%e5%bd%a2%e5%ad%a6%e4%b9%a0.md.html" id="14 非线性降维：流形学习.md.html">14 非线性降维：流形学习.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a040%e8%ae%b2/15%20%e4%bb%8e%e5%9b%9e%e5%bd%92%e5%88%b0%e5%88%86%e7%b1%bb%ef%bc%9a%e8%81%94%e7%b3%bb%e5%87%bd%e6%95%b0%e4%b8%8e%e9%99%8d%e7%bb%b4.md.html" id="15 从回归到分类：联系函数与降维.md.html">15 从回归到分类：联系函数与降维.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a040%e8%ae%b2/16%20%e5%bb%ba%e6%a8%a1%e9%9d%9e%e6%ad%a3%e6%80%81%e5%88%86%e5%b8%83%ef%bc%9a%e5%b9%bf%e4%b9%89%e7%ba%bf%e6%80%a7%e6%a8%a1%e5%9e%8b.md.html" id="16 建模非正态分布：广义线性模型.md.html">16 建模非正态分布：广义线性模型.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a040%e8%ae%b2/17%20%e5%87%a0%e4%bd%95%e8%a7%92%e5%ba%a6%e7%9c%8b%e5%88%86%e7%b1%bb%ef%bc%9a%e6%94%af%e6%8c%81%e5%90%91%e9%87%8f%e6%9c%ba.md.html" id="17 几何角度看分类：支持向量机.md.html">17 几何角度看分类：支持向量机.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a040%e8%ae%b2/18%20%e4%bb%8e%e5%85%a8%e5%b1%80%e5%88%b0%e5%b1%80%e9%83%a8%ef%bc%9a%e6%a0%b8%e6%8a%80%e5%b7%a7.md.html" id="18 从全局到局部：核技巧.md.html">18 从全局到局部：核技巧.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a040%e8%ae%b2/19%20%e9%9d%9e%e5%8f%82%e6%95%b0%e5%8c%96%e7%9a%84%e5%b1%80%e9%83%a8%e6%a8%a1%e5%9e%8b%ef%bc%9aK%e8%bf%91%e9%82%bb.md.html" id="19 非参数化的局部模型：K近邻.md.html">19 非参数化的局部模型：K近邻.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a040%e8%ae%b2/20%20%e5%9f%ba%e4%ba%8e%e8%b7%9d%e7%a6%bb%e7%9a%84%e5%ad%a6%e4%b9%a0%ef%bc%9a%e8%81%9a%e7%b1%bb%e4%b8%8e%e5%ba%a6%e9%87%8f%e5%ad%a6%e4%b9%a0.md.html" id="20 基于距离的学习：聚类与度量学习.md.html">20 基于距离的学习：聚类与度量学习.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a040%e8%ae%b2/21%20%e5%9f%ba%e5%87%bd%e6%95%b0%e6%89%a9%e5%b1%95%ef%bc%9a%e5%b1%9e%e6%80%a7%e7%9a%84%e9%9d%9e%e7%ba%bf%e6%80%a7%e5%8c%96.md.html" id="21 基函数扩展：属性的非线性化.md.html">21 基函数扩展：属性的非线性化.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a040%e8%ae%b2/22%20%e8%87%aa%e9%80%82%e5%ba%94%e7%9a%84%e5%9f%ba%e5%87%bd%e6%95%b0%ef%bc%9a%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c.md.html" id="22 自适应的基函数：神经网络.md.html">22 自适应的基函数：神经网络.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a040%e8%ae%b2/23%20%e5%b1%82%e6%ac%a1%e5%8c%96%e7%9a%84%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%ef%bc%9a%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0.md.html" id="23 层次化的神经网络：深度学习.md.html">23 层次化的神经网络：深度学习.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a040%e8%ae%b2/24%20%e6%b7%b1%e5%ba%a6%e7%bc%96%e8%a7%a3%e7%a0%81%ef%bc%9a%e8%a1%a8%e7%a4%ba%e5%ad%a6%e4%b9%a0.md.html" id="24 深度编解码：表示学习.md.html">24 深度编解码：表示学习.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a040%e8%ae%b2/25%20%e5%9f%ba%e4%ba%8e%e7%89%b9%e5%be%81%e7%9a%84%e5%8c%ba%e5%9f%9f%e5%88%92%e5%88%86%ef%bc%9a%e6%a0%91%e6%a8%a1%e5%9e%8b.md.html" id="25 基于特征的区域划分：树模型.md.html">25 基于特征的区域划分：树模型.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a040%e8%ae%b2/26%20%e9%9b%86%e6%88%90%e5%8c%96%e5%a4%84%e7%90%86%ef%bc%9aBoosting%e4%b8%8eBagging.md.html" id="26 集成化处理：Boosting与Bagging.md.html">26 集成化处理：Boosting与Bagging.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a040%e8%ae%b2/27%20%e4%b8%87%e8%83%bd%e6%a8%a1%e5%9e%8b%ef%bc%9a%e6%a2%af%e5%ba%a6%e6%8f%90%e5%8d%87%e4%b8%8e%e9%9a%8f%e6%9c%ba%e6%a3%ae%e6%9e%97.md.html" id="27 万能模型：梯度提升与随机森林.md.html">27 万能模型：梯度提升与随机森林.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a040%e8%ae%b2/28%20%e6%9c%80%e7%ae%80%e5%8d%95%e7%9a%84%e6%a6%82%e7%8e%87%e5%9b%be%ef%bc%9a%e6%9c%b4%e7%b4%a0%e8%b4%9d%e5%8f%b6%e6%96%af.md.html" id="28 最简单的概率图：朴素贝叶斯.md.html">28 最简单的概率图：朴素贝叶斯.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a040%e8%ae%b2/29%20%e6%9c%89%e5%90%91%e5%9b%be%e6%a8%a1%e5%9e%8b%ef%bc%9a%e8%b4%9d%e5%8f%b6%e6%96%af%e7%bd%91%e7%bb%9c.md.html" id="29 有向图模型：贝叶斯网络.md.html">29 有向图模型：贝叶斯网络.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a040%e8%ae%b2/30%20%e6%97%a0%e5%90%91%e5%9b%be%e6%a8%a1%e5%9e%8b%ef%bc%9a%e9%a9%ac%e5%b0%94%e5%8f%af%e5%a4%ab%e9%9a%8f%e6%9c%ba%e5%9c%ba.md.html" id="30 无向图模型：马尔可夫随机场.md.html">30 无向图模型：马尔可夫随机场.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a040%e8%ae%b2/31%20%e5%bb%ba%e6%a8%a1%e8%bf%9e%e7%bb%ad%e5%88%86%e5%b8%83%ef%bc%9a%e9%ab%98%e6%96%af%e7%bd%91%e7%bb%9c.md.html" id="31 建模连续分布：高斯网络.md.html">31 建模连续分布：高斯网络.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a040%e8%ae%b2/32%20%e4%bb%8e%e6%9c%89%e9%99%90%e5%88%b0%e6%97%a0%e9%99%90%ef%bc%9a%e9%ab%98%e6%96%af%e8%bf%87%e7%a8%8b.md.html" id="32 从有限到无限：高斯过程.md.html">32 从有限到无限：高斯过程.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a040%e8%ae%b2/33%20%e5%ba%8f%e5%88%97%e5%8c%96%e5%bb%ba%e6%a8%a1%ef%bc%9a%e9%9a%90%e9%a9%ac%e5%b0%94%e5%8f%af%e5%a4%ab%e6%a8%a1%e5%9e%8b.md.html" id="33 序列化建模：隐马尔可夫模型.md.html">33 序列化建模：隐马尔可夫模型.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a040%e8%ae%b2/34%20%e8%bf%9e%e7%bb%ad%e5%ba%8f%e5%88%97%e5%8c%96%e6%a8%a1%e5%9e%8b%ef%bc%9a%e7%ba%bf%e6%80%a7%e5%8a%a8%e6%80%81%e7%b3%bb%e7%bb%9f.md.html" id="34 连续序列化模型：线性动态系统.md.html">34 连续序列化模型：线性动态系统.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a040%e8%ae%b2/35%20%e7%b2%be%e7%a1%ae%e6%8e%a8%e6%96%ad%ef%bc%9a%e5%8f%98%e9%87%8f%e6%b6%88%e9%99%a4%e5%8f%8a%e5%85%b6%e6%8b%93%e5%b1%95.md.html" id="35 精确推断：变量消除及其拓展.md.html">35 精确推断：变量消除及其拓展.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a040%e8%ae%b2/36%20%e7%a1%ae%e5%ae%9a%e8%bf%91%e4%bc%bc%e6%8e%a8%e6%96%ad%ef%bc%9a%e5%8f%98%e5%88%86%e8%b4%9d%e5%8f%b6%e6%96%af.md.html" id="36 确定近似推断：变分贝叶斯.md.html">36 确定近似推断：变分贝叶斯.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a040%e8%ae%b2/37%20%e9%9a%8f%e6%9c%ba%e8%bf%91%e4%bc%bc%e6%8e%a8%e6%96%ad%ef%bc%9aMCMC.md.html" id="37 随机近似推断：MCMC.md.html">37 随机近似推断：MCMC.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a040%e8%ae%b2/38%20%e5%ae%8c%e5%a4%87%e6%95%b0%e6%8d%ae%e4%b8%8b%e7%9a%84%e5%8f%82%e6%95%b0%e5%ad%a6%e4%b9%a0%ef%bc%9a%e6%9c%89%e5%90%91%e5%9b%be%e4%b8%8e%e6%97%a0%e5%90%91%e5%9b%be.md.html" id="38 完备数据下的参数学习：有向图与无向图.md.html">38 完备数据下的参数学习：有向图与无向图.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a040%e8%ae%b2/39%20%e9%9a%90%e5%8f%98%e9%87%8f%e4%b8%8b%e7%9a%84%e5%8f%82%e6%95%b0%e5%ad%a6%e4%b9%a0%ef%bc%9aEM%e6%96%b9%e6%b3%95%e4%b8%8e%e6%b7%b7%e5%90%88%e6%a8%a1%e5%9e%8b.md.html" id="39 隐变量下的参数学习：EM方法与混合模型.md.html">39 隐变量下的参数学习：EM方法与混合模型.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a040%e8%ae%b2/40%20%e7%bb%93%e6%9e%84%e5%ad%a6%e4%b9%a0%ef%bc%9a%e5%9f%ba%e4%ba%8e%e7%ba%a6%e6%9d%9f%e4%b8%8e%e5%9f%ba%e4%ba%8e%e8%af%84%e5%88%86.md.html" id="40 结构学习：基于约束与基于评分.md.html">40 结构学习：基于约束与基于评分.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a040%e8%ae%b2/%e5%a6%82%e4%bd%95%e6%88%90%e4%b8%ba%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e5%b7%a5%e7%a8%8b%e5%b8%88%ef%bc%9f.md.html" id="如何成为机器学习工程师？.md.html">如何成为机器学习工程师？.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a040%e8%ae%b2/%e6%80%bb%e7%bb%93%e8%af%be%20%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e7%9a%84%e6%a8%a1%e5%9e%8b%e4%bd%93%e7%b3%bb.md.html" id="总结课 机器学习的模型体系.md.html">总结课 机器学习的模型体系.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a040%e8%ae%b2/%e6%80%bb%e7%bb%93%e8%af%be%20%e8%b4%9d%e5%8f%b6%e6%96%af%e5%ad%a6%e4%b9%a0%e7%9a%84%e6%a8%a1%e5%9e%8b%e4%bd%93%e7%b3%bb.md.html" id="总结课 贝叶斯学习的模型体系.md.html">总结课 贝叶斯学习的模型体系.md.html</a>
</li>
<li>
<a class="menu-item" href="/%e4%b8%93%e6%a0%8f/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a040%e8%ae%b2/%e7%bb%93%e8%af%be%20%e7%bb%88%e6%9c%89%e4%b8%80%e5%a4%a9%ef%bc%8c%e4%bd%a0%e5%b0%86%e4%b8%ba%e4%bb%8a%e5%a4%a9%e7%9a%84%e4%bb%98%e5%87%ba%e9%aa%84%e5%82%b2.md.html" id="结课 终有一天，你将为今天的付出骄傲.md.html">结课 终有一天，你将为今天的付出骄傲.md.html</a>
</li>
<li><a href="/assets/捐赠.md.html">捐赠</a></li>
</ul>
</div>
</div>
<div class="sidebar-toggle" onclick="sidebar_toggle()" onmouseleave="remove_inner()" onmouseover="add_inner()">
<div class="sidebar-toggle-inner"></div>
</div>
<div class="off-canvas-content">
<div class="columns">
<div class="column col-12 col-lg-12">
<div class="book-navbar">
<header class="navbar">
<section class="navbar-section">
<a onclick="open_sidebar()">
<i class="icon icon-menu"></i>
</a>
</section>
</header>
</div>
<div class="book-content" style="max-width: 960px; margin: 0 auto;
    overflow-x: auto;
    overflow-y: hidden;">
<div class="book-post">
<div align="center">因收到Google相关通知，网站将会择期关闭。<a href="https://lumendatabase.org/notices/44265620" target="_blank">相关通知内容</a><hr/></div>
<p align="center" id="tip"></p>
<h1 class="title" data-id="31 建模连续分布：高斯网络" id="title">31 建模连续分布：高斯网络</h1>
<div><p>无论是贝叶斯网络还是马尔可夫随机场，定义的变量都服从取值有限的离散分布，变量之间的关联则可以用有限维度的矩阵来表示。如果将随机变量的范围从离散型扩展到连续型，变量的可能取值就有无穷多个，这时变量之间的依赖关系就不能再用表格的形式来表示了，需要重新定义概率图模型中的相互作用与条件独立性。</p>
<p>考虑最简单的情形，也就是结点所表示的随机变量都服从高斯分布，<strong>由高斯型连续随机变量构成的概率图模型统称为高斯网络</strong>（Gaussian network）。</p>
<p>如果多个服从一维高斯分布的随机变量构成一个整体，那它们的联合分布就是<strong>多元高斯分布</strong>（multivariate Gaussian distribution），其数学表达式可以写成</p>
<p><span class="math display">\[ p({\\bf x}) = \\dfrac{1}{(2\\pi)^{n / 2} | \\Sigma |^{1/2}} \\exp \[-\\dfrac{1}{2} ({\\bf x} - \\boldsymbol \\mu)^ T \\Sigma^{-1} ({\\bf x} - \\boldsymbol \\mu)\] \]</span></p><p>其中<span class="math inline">\(\\boldsymbol \\mu\)</span>是这组随机变量的均值向量（mean vector），<span class="math inline">\(\\Sigma\)</span>是这组随机变量的协方差矩阵（covariance matrix），<span class="math inline">\(| \\Sigma |\)</span>是它的行列式值。</p>
<p>协方差矩阵是对称的正定（positive definite）矩阵，表示了不同变量之间的关联：如果两个变量线性无关，那么其协方差矩阵中对应的元素就等于0，这意味着两个变量满足边际独立性（marginal independency）；如果所有变量都线性无关的话，协方差矩阵就退化为对角矩阵。</p>
<p>协方差矩阵的逆矩阵<span class="math inline">\(J = \\Sigma ^ {-1}\)</span>被称为<strong>信息矩阵</strong>（information matrix），信息矩阵和均值向量的乘积则被称为<strong>势向量</strong>（potential vector）。</p>
<p>引入信息矩阵意在定义条件独立性（conditional independency）：和边际独立性不同，条件独立性不能直接在协方差矩阵中体现出来，必须通过信息矩阵加以观察。信息矩阵的元素等于0说明对应的两个变量在给定其他变量的前提下条件独立，比如<span class="math inline">\(J_{1,3} = 0\)</span>就意味着着在其他变量固定时，<span class="math inline">\(x_1\)</span>和<span class="math inline">\(x_3\)</span>条件独立。</p>
<p>在高斯分布的基础上可以进一步定义高斯线性模型。<strong>高斯线性模型</strong>（linear Gaussian model）指的是一个随机变量可以表示为一组随机变量的线性组合，这个随机变量本身的不确定性则可以用高斯分布来建模，这种关系写成数学表达式就是</p>
<p><span class="math display">\[ y = \\beta_0 + \\beta_1 x_1 + \\cdots + \\beta_k x_k + \\epsilon, \\epsilon ~{} {\\mathscr N}(0, \\sigma ^ 2) \]</span></p><p>这其实和原始线性回归的假设是完全一致的。把这种关系放到概率图模型中，那么所有的<span class="math inline">\(x_i\)</span>都可以看成结点<span class="math inline">\(y\)</span>的父结点，它们一起构成了汇连结构。从概率角度看，给定这些父结点后，子结点<span class="math inline">\(y\)</span>的条件概率就服从高斯分布，其均值是<span class="math inline">\(x_i\)</span>的线性组合，方差则是噪声<span class="math inline">\(\\epsilon\)</span>的方差。</p>
<p>上面的表达式中假设所有自变量<span class="math inline">\(x_i\)</span>都有固定的取值，如果这些自变量都是随机变量，共同服从均值为<span class="math inline">\(\\boldsymbol \\mu\)</span>，协方差矩阵为<span class="math inline">\(\\Sigma\)</span>的多维高斯分布的话，那么可以证明随机变量<span class="math inline">\(y\)</span>也是高斯随机变量，它的均值等于<span class="math inline">\(\\beta_0 + \\boldsymbol \\beta^T \\boldsymbol \\mu\)</span>，方差等于<span class="math inline">\(\\sigma ^ 2 + \\boldsymbol \\beta^T \\Sigma \\boldsymbol \\beta\)</span>，和变量<span class="math inline">\(X_i\)</span>的协方差则等于<span class="math inline">\(\\sum_{j = 1}^k \\beta_j\\Sigma_{i,j}\)</span>。</p>
<p>这样的结论告诉我们，<strong>高斯线性模型实际上定义了一个高斯贝叶斯网络</strong>（Gaussian Bayesian network），<strong>整个概率图所表示的联合分布就是一个大的多维高斯分布</strong>。</p>
<p>高斯贝叶斯网络的表示可以用下面这个例子来直观地解释，这个例子来自《概率图模型》（Probabilistic Graphical Models）的例7.3。</p>
<p>“如果一个线性高斯网络具有顺连结构<span class="math inline">\(X_1 \\rightarrow X_2 \\rightarrow X_3\)</span>，其中<span class="math inline">\(X_1\)</span>的概率密度<span class="math inline">\({\\mathscr N}(1, 4)\)</span>，已知<span class="math inline">\(X_1\)</span>时<span class="math inline">\(X_2\)</span>的条件概率密度为<span class="math inline">\({\\mathscr N}(0.5X_1 - 3.5, 4)\)</span>，已知<span class="math inline">\(X_2\)</span>时<span class="math inline">\(X_3\)</span>的条件概率密度为<span class="math inline">\({\\mathscr N}(-X_2 + 1, 3)\)</span>，试求解整个网络所表示的联合分布。“</p>
<p>在高斯形式已经确定的前提下，求解联合分布实际上就是求解所有变量的均值向量和协方差矩阵。由于<span class="math inline">\(X_2\)</span>等于<span class="math inline">\(0.5X_1 - 3.5\)</span>，将<span class="math inline">\(X_1\)</span>的均值为1代入这个线性关系，就可以求出<span class="math inline">\(X_2\)</span>的均值等于<span class="math inline">\(0.5 \\times 1 - 3.5 = -3\)</span>，同理可以求出<span class="math inline">\(X_2\)</span>的均值等于<span class="math inline">\(-(-3) + 1 = 4\)</span>。</p>
<p>求完了均值再来看协方差，协方差矩阵的对称性决定了对于3维变量来说，计算协方差矩阵需要确定6个元素。<span class="math inline">\(X_1\)</span>的方差<span class="math inline">\(\\Sigma_{11} = 4\)</span>是已知的，这部分方差将会以线性系数为比例体现在<span class="math inline">\(X_2\)</span>中，和<span class="math inline">\(X_2\)</span>自身的不确定度共同构成随机变量完整的方差，也就是<span class="math inline">\(\\Sigma_{22} = 0.5^2 \\times 4 + 4 = 5\)</span>。将<span class="math inline">\(X_2\)</span>的方差代入<span class="math inline">\(X_3\)</span>的线性关系，又可以计算出<span class="math inline">\(\\Sigma_{33} = (-1)^2 \\times 5 + 3 = 8\)</span>。这三个方差定义了变量自身的不确定性，是协方差矩阵中的对角线元素。</p>
<p>确定了对角线元素后，下一步就是确定非对角线上的元素，也就是不同变量之间的相关性。由于<span class="math inline">\(X_2\)</span>这个变量只取决于<span class="math inline">\(X_1\)</span>，其关联的强度由线性系数确定，因而两者之间的协方差就等于线性系数和<span class="math inline">\(X_1\)</span>方差的乘积<span class="math inline">\(\\Sigma_{12} = 0.5 \\times \\Sigma_{11} = 2\)</span>。这个数字的含义在于用<span class="math inline">\(X_1\)</span>的变化对<span class="math inline">\(X_2\)</span>的变化的影响。同理可以求出，<span class="math inline">\(X_2\)</span>和<span class="math inline">\(X_3\)</span>之间的协方差为<span class="math inline">\(\\Sigma_{23} = -1 \\times \\Sigma_{22} = -5\)</span>。</p>
<p>在这个顺连结构中，<span class="math inline">\(X_1\)</span>和<span class="math inline">\(X_3\)</span>之间并不存在直接的作用，而是以<span class="math inline">\(X_2\)</span>作为媒介和中转。<span class="math inline">\(X_1\)</span>对<span class="math inline">\(X_3\)</span>的作用实际上可以分成两个阶段，第一个阶段是<span class="math inline">\(X_1\)</span>的变化首先影响<span class="math inline">\(X_2\)</span>，第二个阶段是<span class="math inline">\(X_2\)</span>的变化继续影响<span class="math inline">\(X_3\)</span>。在协方差的计算中，第一个阶段体现为<span class="math inline">\(X_1\)</span>和<span class="math inline">\(X_2\)</span>之间的协方差，第二个阶段则体现为<span class="math inline">\(X_2\)</span>和<span class="math inline">\(X_3\)</span>之间的线性系数的加权作用。两者相乘形成了一个整体，也就是<span class="math inline">\(\\Sigma_{13} = \\Sigma_{12} \\cdot (-1) = -2\)</span>。由此，就可以写出联合分布的均值向量和协方差矩阵</p>
<p><img alt="" src="assets/ff89b192b5c48b1ce727c06ad3462a31.png"/></p>
<p>关于这个例子需要说明的一点是，由于协方差矩阵中所有的元素都不为0，说明这些变量两两之间都不是边际独立的。但顺连结构告诉我们，当<span class="math inline">\(X_2\)</span>确定时，<span class="math inline">\(X_1\)</span>和<span class="math inline">\(X_3\)</span>条件独立，所以它的信息矩阵中会有两个零元素。这说明在图结构中，表示同一个联合分布只需要更少的参数。</p>
<p>但淮南为橘淮北为枳，图结构的优势也可能变成劣势。想象一下汇连结构<span class="math inline">\(X_1 \\rightarrow X_2 \\leftarrow X_3\)</span>，由于汇连结构中不存在条件独立的结点，因此联合分布的信息矩阵中所有元素都是非零的。但由于<span class="math inline">\(X_1\)</span>和<span class="math inline">\(X_3\)</span>互不影响，因此协方差矩阵中反倒存在着零元素。</p>
<p>在此基础上，如果再给结点<span class="math inline">\(X_1\)</span>和<span class="math inline">\(X_3\)</span>赋予一个共同的父结点<span class="math inline">\(X_4\)</span>，让这三者形成分连结构的话，那整个网络中就既没有条件独立性，也没有边际独立性，无论是协方差矩阵还是信息矩阵中就都不会出现非零元素了。</p>
<p><strong>将多元高斯分布嵌入到无向的马尔可夫随机场中，得到的就是高斯马尔可夫随机场</strong>（Gaussian Markov random field）。在处理高斯随机场时，先要对多元高斯分布的概率密度做些处理，将指数项中的协方差逆矩阵<span class="math inline">\(\\Sigma ^ {-1}\)</span>替换为信息矩阵<span class="math inline">\(J\)</span>并展开。由于均值向量和信息矩阵都是常量，将它们去掉就可以得到概率密度的正比关系</p>
<p><span class="math display">\[ p({\\bf s}) \\propto \\exp \[-\\dfrac{1}{2} {\\bf x}^T J {\\bf x} + (J \\boldsymbol \\mu)^T {\\bf x}\] \]</span></p><p>这个式子被称为<strong>高斯分布的信息形式</strong>（information form）。由于式子中的<span class="math inline">\(\\bf x\)</span>是向量，因此展开后的结果中会包含两种多项式成分：一种成分是单个变量<span class="math inline">\(X_i\)</span>的函数，其表达式可以写成<span class="math inline">\(-J_{i, i}x_i^2 / 2 + h_ix_i\)</span>，其中<span class="math inline">\(h_i\)</span>是势向量的第<span class="math inline">\(i\)</span>个分量；另一种成分是两个变量<span class="math inline">\(X_i\)</span>和<span class="math inline">\(X_j\)</span>乘积的函数，其表达式可以写成<span class="math inline">\(-J_{i, j}x_ix_j\)</span>。</p>
<p>在高斯随机场中，这两个不同的成分具有不同的意义。只与单个变量相关的成分可以看成每个结点的势函数（node potential），同时涉及两个变量的成分则可以看成连接这两个结点的边的势函数（edge potential）。如果信息矩阵的元素<span class="math inline">\(J_{i, j} = 0\)</span>，其对应的边势也等于0，就说明这两个结点之间并没有连接的边。</p>
<p>需要说明的是，在前一篇对马尔可夫随机场的介绍中我提到了边势，但并没有涉及结点势的概念。其原因在于结点势并不是通用的概念，它只存在于具有成对马尔可夫性的网络之中。下图是一个典型的成对马尔可夫随机场，每个结点都和它所有的非邻接结点条件独立，在信息矩阵<span class="math inline">\(J\)</span>中，这些条件独立的结点组合所对应的元素就等于0。</p>
<p><img alt="" src="assets/00fb127ba9b5f370c67d7f91a5862392.png"/></p>
<p>成对马尔可夫随机场（图片来自Probabilistic Graphical Models，图4.A.1）</p>
<p>多元高斯分布定义的是成对的马尔可夫随机场，其中的每个势函数都具有二次型的形式。反过来，由于任何合法的高斯分布都具有正定的信息矩阵，所以如果一个成对随机场能够改写成多元高斯分布，那它的势函数的系数所形成的矩阵也必须得满足正定的条件。</p>
<p>对连续分布的建模能够大大拓展概率图模型的应用范围，毕竟现实中大量的观测结果都是连续变化的。<strong>虽然高斯分布并不适用于所有的连续变量，但良好的数学性质和便于计算的特点让它成为了理想条件下近似建模的首选</strong>。</p>
<p>如果一个概率图模型中的随机变量既有离散型也有连续型，这样的网络就是<strong>混合网络</strong>（hybrid network）。混合网络让人头疼的一个问题是同一个结点的父结点可能存在不同的类型，其中既有连续分布的结点，也有离散分布的结点。而在处理这些父结点不同的子结点时，需要根据情况分类讨论。</p>
<p>如果子结点是连续分布的结点，那么问题就简单了。由于离散分布的父结点取值的组合是有限的，就可以对每一种可能的取值都为子结点定义一组线性系数，将离散结点的信息编码到这组线性系数当中。</p>
<p>这样一来，子结点就可以表示成连续父结点的线性组合，其中的线性系数则由离散父结点来决定。这种模型被称为<strong>条件线性模型</strong>（conditional linear model），它本质上是一组不同参数的高斯分布所形成的混合模型（mixture model），每个分布的权重取决于这一组参数出现的概率。</p>
<p>当一个离散的子结点具有连续的父结点时，解决的方法也不复杂。最简单的办法是采用<strong>阈值模型</strong>（threshold model），当连续变量的取值大于阈值时输出1，小于阈值时输出0。更加精细的一种方式是用借鉴逻辑回归或者softmax回归的思想，计算离散的子结点关于连续的父结点的条件概率，并输出条件概率最大的结果。</p>
<p>今天我和你分享了概率图模型中对连续型随机变量的建模与表示，其要点如下：</p>
<ul>
<li><p>高斯网络采用高斯线性模型建模连续变量，其数字特征为均值向量和协方差矩阵；</p></li>
<li><p>高斯贝叶斯网络利用多元高斯分布生成独立图，利用信息矩阵计算网络中的条件概率；</p></li>
<li><p>高斯马尔可夫随机场具有成对马尔可夫性，通过高斯分布可以确定结点势和边势；</p></li>
<li><p>混合网络是同时具有离散型结点和连续型结点的概率图模型。</p></li>
</ul>
<p>在现实生活中，自然界客观存在的属性通常是连续分布的，而人为定义出来的属性则通常是离散的，那么你能想象出有哪些离散变量和连续变量共存的应用场景呢？</p>
<p>欢迎分享你的观点。</p>
<p><img alt="" src="assets/e65b416c4f6b52d0cac868901a312683.jpg"/></p>
</div>
</div>
<div>
<div id="prePage" style="float: left">
</div>
<div id="nextPage" style="float: right">
</div>
</div>
</div>
</div>
</div>
<div class="copyright">
<hr/>
<p>© 2019 - 2023 <a href="/cdn-cgi/l/email-protection#3d51515104090c0c0d0a7d5a505c5451135e5250" target="_blank">Liangliang Lee</a>.
                    Powered by <a href="https://github.com/gin-gonic/gin" target="_blank">gin</a> and <a href="https://github.com/kaiiiz/hexo-theme-book" target="_blank">hexo-theme-book</a>.</p>
</div>
</div>
<a class="off-canvas-overlay" onclick="hide_canvas()"></a>
</div>
<script data-cfasync="false" src="/cdn-cgi/scripts/5c5dd728/cloudflare-static/email-decode.min.js"></script><script>(function(){function c(){var b=a.contentDocument||a.contentWindow.document;if(b){var d=b.createElement('script');d.innerHTML="window.__CF$cv$params={r:'9359df121a9f6908',t:'MTc0NTU0MjQ4OS4wMDAwMDA='};var a=document.createElement('script');a.nonce='';a.src='/cdn-cgi/challenge-platform/scripts/jsd/main.js';document.getElementsByTagName('head')[0].appendChild(a);";b.getElementsByTagName('head')[0].appendChild(d)}}if(document.body){var a=document.createElement('iframe');a.height=1;a.width=1;a.style.position='absolute';a.style.top=0;a.style.left=0;a.style.border='none';a.style.visibility='hidden';document.body.appendChild(a);if('loading'!==document.readyState)c();else if(window.addEventListener)document.addEventListener('DOMContentLoaded',c);else{var e=document.onreadystatechange||function(){};document.onreadystatechange=function(b){e(b);'loading'!==document.readyState&&(document.onreadystatechange=e,c())}}}})();</script></body>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-NPSEEVD756"></script>
<script src="/static/index.js"></script>
</head></html>